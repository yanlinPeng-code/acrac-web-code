"""
ä¸´åºŠåœºæ™¯æ£€ç´¢æœåŠ¡
å®ç°å››é˜¶æ®µæ··åˆæ£€ç´¢ç­–ç•¥ï¼š
1. ç»“æ„åŒ–ç­›é€‰ï¼ˆå¹´é¾„/æ€§åˆ«ç­‰ç¡¬æ€§æ¡ä»¶ï¼‰
2. å‘é‡è¯­ä¹‰æ£€ç´¢ï¼ˆä¸»è¯‰+ç—…å²+è¯Šæ–­ï¼‰
3. å…³é”®è¯åŒ¹é…æ£€ç´¢
4. è§„åˆ™å¼•æ“è¿‡æ»¤ï¼ˆç¦å¿Œç—‡/ç‰¹æ®Šè€ƒè™‘ï¼‰
5. æ¨èæ’åºï¼ˆappropriateness_ratingï¼‰
"""
import asyncio
import datetime
import hashlib
import json
import math
import random
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Coroutine
import copy

from pymilvus import AnnSearchRequest, Function, FunctionType
from sqlalchemy.orm import selectinload
from sqlmodel import select, and_, or_
from sqlalchemy import func, cast, text
from sqlmodel.ext.asyncio.session import AsyncSession
from app.config.redis_config import redis_manager
from app.core.language_model.model_client_wrapper import EmbeddingClientSDK
from app.core.language_model.providers.siliconflow.embedding import Embedding
from app.model.acrac_models import ClinicalScenario, ClinicalRecommendation, ProcedureDictionary
from app.schema.IntelligentRecommendation_schemas import (RerankingStrategy, PatientInfo, ClinicalContext,
                                                          SearchStrategy
                                                          )
from app.service.rag_v1.adaptive_recommend_service import LearningThresholdStrategy, AdaptiveRecommendationEngineService
# å¯¼å…¥AIæœåŠ¡ï¼ˆæŸ¥è¯¢æ ‡å‡†åŒ–ï¼‰
from app.service.rag_v1.ai_service import AiService
from app.service.rag_v1.vector_database_service import VectorDatabaseService
from app.config.database import async_db_manager
from app.utils.helper.helper import assemble_database_results
from app.utils.logger.simple_logger import get_logger
from app.celery.tasks.dict_update_tasks import batch_persist_by_category, batch_persist_by_category_async

logger = get_logger(__name__)




class RetrievalService:
    """ä¸´åºŠåœºæ™¯æ£€ç´¢æœåŠ¡
    
    é«˜å¹¶å‘ä¼˜åŒ–ï¼šä¸ºæ¯ä¸ªå¹¶å‘æ£€ç´¢æ–¹æ³•åˆ›å»ºç‹¬ç«‹çš„sessionï¼Œé¿å…äº‹åŠ¡å†²çª
    """
    
    def __init__(self,
                 session: AsyncSession,
                 ai_service: AiService,
                 vector_service:VectorDatabaseService,
                 ):
        """
        åˆå§‹åŒ–æ£€ç´¢æœåŠ¡
        
        Args:
            session: æ•°æ®åº“ä¼šè¯ï¼ˆä¸»è¦ç”¨äºéå¹¶å‘åœºæ™¯ï¼‰
        """
        self.session = session

        
        # åˆå§‹åŒ–AIæœåŠ¡ï¼ˆä½¿ç”¨requestsè°ƒç”¨APIï¼‰
        self.ai_service =ai_service
        self.vector_service = vector_service
        self.redis_client=redis_manager.async_client
        self.adaptive_recommendation_engine_service= AdaptiveRecommendationEngineService(environment="production")

        # æ€§åˆ«æ˜ å°„
        self.gender_mapping = {
            'ç”·æ€§': [
                'ç”·', 'ç”·æ€§', 'ç”·äºº', 'ç”·å£«', 'ç”·æ‚£è€…', 'ç”·ç«¥', 'ç”·å­©', 'ç”·ç”Ÿ', 'ç”·å©´', 'ç”·é’å¹´',
                'ç”·å­', 'ç”·ç—…äºº', 'ç”·ç§‘', 'é›„æ€§', 'å…¬', 'é›„', 'male', 'm', 'man', 'boy', 'gentleman'
            ],
            'å¥³æ€§': [
                'å¥³', 'å¥³æ€§', 'å¥³äºº', 'å¥³å£«', 'å¥³æ‚£è€…', 'å¥³ç«¥', 'å¥³å­©', 'å¥³ç”Ÿ', 'å¥³å©´', 'å¥³é’å¹´',
                'å¥³å­', 'å¥³ç—…äºº', 'å¦‡ç§‘', 'é›Œæ€§', 'æ¯', 'é›Œ', 'female', 'f', 'woman', 'girl', 'lady'
            ],
            'ä¸é™': [
                'ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'ä»»ä½•', 'å‡å¯', 'ç”·å¥³', 'ç”·å¥³å‡å¯', 'ç”·å¥³çš†å¯',
                'any', 'all', 'both', 'either', 'é€šç”¨', 'common', 'general',"æˆäºº","æˆå¹´äºº"
            ]
        }

        # å¦Šå¨ çŠ¶æ€æ˜ å°„
        self.pregnancy_mapping = {
            'å¦Šå¨ æœŸ': [
                'å¦Šå¨ ', 'æ€€å­•', 'å­•å¦‡', 'å­•æœŸ', 'å¦Šå¨ æœŸ', 'å­•äº§å¦‡', 'å­•äº§æœŸ', 'å­•å‘¨', 'å­•æ—©æœŸ',
                'å­•ä¸­æœŸ', 'å­•æ™šæœŸ', 'æ—©å­•', 'ä¸­å­•', 'æ™šå­•', 'æ€€å­•æœŸ', 'pregnancy', 'pregnant',
                'gestation', 'gestational', 'prenatal', 'antenatal'
            ],
            'éå¦Šå¨ æœŸ': [
                'éå¦Šå¨ ', 'éå­•å¦‡', 'æœªæ€€å­•', 'æœªå¦Šå¨ ', 'éå­•æœŸ', 'æœªå­•', 'éå­•', 'non-pregnancy',
                'not pregnant', 'non-pregnant', 'non-gestational'
            ],
            'å“ºä¹³æœŸ': [
                'å“ºä¹³', 'å“ºä¹³æœŸ', 'æ¯ä¹³å–‚å…»', 'æ¯ä¹³', 'å“ºä¹³æœŸå¦‡å¥³', 'å“ºä¹³æ¯äº²', 'lactation',
                'breastfeeding', 'nursing', 'lactating'
            ],
            'å¤‡å­•æœŸ': [
                'å¤‡å­•', 'å¤‡å­•æœŸ', 'è®¡åˆ’æ€€å­•', 'å‡†å¤‡æ€€å­•', 'preconception', 'trying to conceive',
                'fertility', 'pre-pregnancy'
            ],
            'äº§å': [
                'äº§å', 'åˆ†å¨©å', 'ç”Ÿäº§å', 'postpartum', 'postnatal', 'after delivery',
                'puerperium', 'post-partum'
            ],
            'ä¸å­•': [
                'ä¸å­•', 'ä¸å­•ç—‡', 'ä¸è‚²', 'ä¸è‚²ç—‡', 'infertility', 'infertile', 'sterility'
            ],
            'ä¸é™': [
                'ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'ä»»ä½•', 'å‡å¯', 'any', 'all', 'both', 'either',
                'é€šç”¨', 'common', 'general'
            ]
        }

        # å¹´é¾„ç»„æ˜ å°„
        self.age_group_mapping = {
            'æ–°ç”Ÿå„¿': ['æ–°ç”Ÿå„¿', 'æ–°ç”Ÿ', 'neonate', 'newborn'],
            'å©´å„¿': ['å©´å„¿', 'å©´å¹¼å„¿', 'infant', 'baby'],
            'å„¿ç«¥': ['å„¿ç«¥', 'å°å„¿', 'å„¿ç§‘', 'child', 'pediatric', 'children'],
            'é’å°‘å¹´': ['é’å°‘å¹´', 'å°‘å¹´', 'adolescent', 'teenager'],
            'æˆäºº': ['æˆäºº', 'æˆå¹´äºº', 'adult'],
            'è€å¹´': ['è€å¹´', 'è€å¹´äºº', 'è€äºº', 'elderly', 'geriatric', 'senior'],
            'ä¸é™': ['ä¸é™', 'é€šç”¨', 'all', 'both', 'any', 'å‡å¯']
        }

        # ç§‘å®¤åˆ«åæ˜ å°„
        self.department_mapping = {
            'å¿ƒå†…ç§‘': ['å¿ƒè¡€ç®¡å†…ç§‘', 'å¿ƒè„å†…ç§‘', ' Cardiology', 'cardiology'],
            'æ¶ˆåŒ–ç§‘': ['æ¶ˆåŒ–å†…ç§‘', ' Gastroenterology', 'gastroenterology'],
            'ç¥ç»ç§‘': ['ç¥ç»å†…ç§‘', ' Neurology', 'neurology'],
            'éª¨ç§‘': ['éª¨ç§‘', ' Orthopedics', 'orthopedics'],
            'å„¿ç§‘': ['å°å„¿ç§‘', ' Pediatrics', 'pediatrics'],
            'å¦‡äº§ç§‘': ['å¦‡ç§‘', 'äº§ç§‘', ' Obstetrics', 'Gynecology', 'obstetrics', 'gynecology'],
            'æ€¥è¯Šç§‘': ['æ€¥è¯Š', ' Emergency', 'emergency'],
            'è‚¿ç˜¤ç§‘': ['è‚¿ç˜¤å†…ç§‘', ' Oncology', 'oncology']
        }

        # ç´§æ€¥ç¨‹åº¦æ˜ å°„
        self.urgency_mapping = {
            'ç´§æ€¥': ['ç´§æ€¥', 'æ€¥è¯Š', 'æ€¥ç—‡', 'æ€¥æ€§', 'urgent', 'emergency', 'critical', 'acute'],
            'ä¸­åº¦': ['ä¸­åº¦', 'ä¸­ç­‰', 'moderate', 'serious'],
            'å¸¸è§„': ['å¸¸è§„', 'æ…¢æ€§', 'å¸¸è§„æ£€æŸ¥', 'mild', 'chronic', 'routine'],
            'å¤å‘æ€§': ['å¤å‘æ€§', 'å¤å‘', 'åå¤', 'recurrent', 'relapse'],
            'äºšæ€¥æ€§': ['äºšæ€¥æ€§', 'subacute'],
            'é‡åº¦': ['é‡åº¦', 'ä¸¥é‡', 'severe'],
            'è½»å¾®': ['è½»å¾®', 'è½»åº¦', 'mild', 'minor'],
            'ç¨³å®š': ['ç¨³å®š', 'stable'],
            'ä¸ç¨³å®š': ['ä¸ç¨³å®š', 'unstable'],
            'å±åŠç”Ÿå‘½': ['å±åŠç”Ÿå‘½', 'ç”Ÿå‘½å±é™©', 'life-threatening', 'critical condition'],
            'æ‹©æœŸ': ['æ‹©æœŸ', 'elective'],
            'é¢„é˜²æ€§': ['é¢„é˜²æ€§', 'é¢„é˜²', 'preventive', 'prophylactic'],
            'ç­›æŸ¥': ['ç­›æŸ¥', 'screening'],
            'éšè®¿': ['éšè®¿', 'follow-up'],
            'åº·å¤': ['åº·å¤', 'åº·å¤æœŸ', 'rehabilitation', 'recovery'],
            'ç»ˆæœ«æœŸ': ['ç»ˆæœ«æœŸ', 'æ™šæœŸ', 'æœ«æœŸ', 'end-stage', 'terminal'],
            'å§‘æ¯æ²»ç–—': ['å§‘æ¯æ²»ç–—', 'å§‘æ¯', 'palliative'],
            'ä¸é™': ['ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'any', 'all', 'both']
        }
    
    async def _get_independent_session(self) -> AsyncSession:
        """
        ä¸ºå¹¶å‘æ£€ç´¢åˆ›å»ºç‹¬ç«‹çš„session
        
        é«˜å¹¶å‘ä¼˜åŒ–ï¼šæ¯ä¸ªæ£€ç´¢æ–¹æ³•ä½¿ç”¨ç‹¬ç«‹çš„sessionï¼Œé¿å…äº‹åŠ¡å†²çª
        ä»è¿æ¥æ± ä¸­è·å–è¿æ¥ï¼Œè‡ªåŠ¨ç®¡ç†ç”Ÿå‘½å‘¨æœŸ
        """
        return async_db_manager.async_session_factory()


    async def retrieve_clinical_scenarios(
        self,
        patient_info: PatientInfo,
        clinical_context: ClinicalContext,
        search_strategy: Optional[SearchStrategy] = None,
        need_optimize_query:Optional[bool]=False,
        top_k: int = 16,
        similarity_threshold: float = 0.6,  # ç›¸ä¼¼åº¦é˜ˆå€¼
        # reranker_model: Optional[RerankerClientSDK] = None,
        # embedding_model: Optional[EmbeddingClientSDK] = None,
        medical_dict: Optional[Dict[str, str]] = None,
    ) -> List[Dict[str, Any]]:
        """
        æ–°çš„æ··åˆæ£€ç´¢æµç¨‹ï¼ˆ2025-10ä¼˜åŒ–ç‰ˆï¼‰ï¼š
        1. LLMæŸ¥è¯¢æ ‡å‡†åŒ–ï¼ˆè½¬æ¢ä¸ºACRæ ‡å‡†æ ¼å¼ï¼‰
        2. å¹¶è¡Œæ£€ç´¢ï¼š
           2a. jiebaåˆ†è¯ + æ¨¡ç³ŠåŒ¹é…æ£€ç´¢ -> top_p -> é‡å åº¦è¯„åˆ† -> top_k
           2b. è¯­ä¹‰å‘é‡æ£€ç´¢ -> top_p -> ç›¸ä¼¼åº¦è¯„åˆ†(>0.6) -> top_k
        3. åˆå¹¶å»é‡ï¼Œæ··åˆæ‰“åˆ†ï¼ˆjieba 30% + è¯­ä¹‰ 70%ï¼‰
        4. æ’åºè¿”å›
        
        Args:
            patient_info: æ‚£è€…åŸºæœ¬ä¿¡æ¯
            clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡
            search_strategy: æ£€ç´¢ç­–ç•¥é…ç½®
            top_k: è¿”å›çš„åœºæ™¯æ•°é‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        
        Returns:
            æ’åºåçš„ä¸´åºŠåœºæ™¯åˆ—è¡¨ï¼Œæ¯ä¸ªåœºæ™¯åŒ…å«åŒ¹é…åˆ†æ•°
        """
        start_time = time.time()
        # ä½¿ç”¨é»˜è®¤ç­–ç•¥
        if search_strategy is None:
            search_strategy = SearchStrategy()
        
        # ========== é˜¶æ®µ1: LLMæŸ¥è¯¢æ ‡å‡†åŒ–ï¼ˆå¸¦ç¼“å­˜ï¼‰ ==========
        logger.info("å¼€å§‹æŸ¥è¯¢æ ‡å‡†åŒ–...")
        
        # ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŸºäºæ‚£è€…ä¿¡æ¯å’Œä¸´åºŠä¸Šä¸‹æ–‡ï¼‰
        cache_key = await self._generate_cache_key(patient_info, clinical_context)
        
        # å°è¯•ä»Redisè·å–ç¼“å­˜çš„æ ‡å‡†åŒ–æŸ¥è¯¢
        cached_query = await self._get_cached_standardized_query(cache_key)
        
        if cached_query:
            logger.info(f"ä»ç¼“å­˜è·å–æ ‡å‡†åŒ–æŸ¥è¯¢: {cached_query}")
            standardized_query = cached_query
        else:
            # if need_optimize_query:
            #     # ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨LLMè¿›è¡Œæ ‡å‡†åŒ–
            #     logger.info("ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨LLMè¿›è¡ŒæŸ¥è¯¢æ ‡å‡†åŒ–...")
            #     standardized_query = await self.ai_service.standardize_query(
            #         patient_info,
            #         clinical_context
            #     )
            #     logger.info(f"æ ‡å‡†åŒ–åçš„æŸ¥è¯¢: {standardized_query}")
            #
            #     # å°†æ ‡å‡†åŒ–ç»“æœå­˜å…¥ç¼“å­˜
            #     await self._cache_standardized_query(cache_key, standardized_query)
            #     logger.info("å·²å°†æ ‡å‡†åŒ–æŸ¥è¯¢å­˜å…¥ç¼“å­˜")
            # else:
            if patient_info.gender in self.gender_mapping["ç”·æ€§"] :
                standardized_query=f"{patient_info.age}å²,{patient_info.gender},{clinical_context.chief_complaint}"
            else:
                standardized_query=f"{patient_info.age}å²,{patient_info.gender},{patient_info.pregnancy_status},{clinical_context.chief_complaint}"
        # ========== é˜¶æ®µ2: å¹¶è¡Œæ£€ç´¢ï¼ˆä½¿ç”¨asyncio.gatherï¼‰ ==========
        top_p = top_k   # ä¸­é—´å€™é€‰é›†å¤§å°
        
        logger.info("å¼€å§‹å¹¶è¡Œæ£€ç´¢ï¼ˆjieba + è¯­ä¹‰ï¼‰...")
        # jieba_candidates=await self._jieba_fuzzy_search(
        #          standardized_query,
        #          medical_dict,
        #          top_p=top_p,
        #          top_k=top_k
        #      )
        # semantic_candidates=await  self._semantic_vector_search(
        #                 standardized_query,
        #                 patient_info,
        #                 clinical_context,
        #                 # embedding_model,
        #                 top_p=top_p,
        #                 top_k=top_k,
        #                 similarity_threshold=similarity_threshold
        #             )
        # vector_candidates=await self._vector_mmr_search(
        #                 standardized_query,
        #                 clinical_context,
        #                 # embedding_model,
        #                 top_p=top_p,
        #                 top_k=top_k,
        #                 similarity_threshold=similarity_threshold
        #             )
        # # # ä½¿ç”¨asyncio.gatherå®ç°çœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ
        jieba_candidates, semantic_candidates, vector_candidates = await asyncio.gather(
            # 2a. jiebaåˆ†è¯ + æ¨¡ç³ŠåŒ¹é…æ£€ç´¢
            self._jieba_fuzzy_search(
                standardized_query,
                medical_dict,
                top_p=top_p,
                top_k=top_k
            ),
            # 2b. è¯­ä¹‰å‘é‡æ£€ç´¢
            self._semantic_vector_search(
                standardized_query,
                patient_info,
                clinical_context,
                # embedding_model,
                top_p=top_p,
                top_k=top_k,
                similarity_threshold=similarity_threshold
            ),
            #3.åŸºäºlangchainå°è£…çš„vector_storeä½œæœ€å¤§è¾¹æ²¿æ£€ç´¢
            self._vector_mmr_search(
                standardized_query,
                clinical_context,
                # embedding_model,
                top_p=top_p,
                top_k=top_k,
                similarity_threshold=similarity_threshold
            ),
            return_exceptions=True  # æ•è·å¼‚å¸¸ï¼Œé¿å…ä¸€ä¸ªå¤±è´¥å¯¼è‡´å…¨éƒ¨å¤±è´¥
        )

        # å¤„ç†å¯èƒ½çš„å¼‚å¸¸
        if isinstance(jieba_candidates, Exception):
            logger.error(f"jiebaæ£€ç´¢å¤±è´¥: {jieba_candidates}")
            jieba_candidates = []
        else:
            logger.info(f"jiebaæ£€ç´¢è¿”å› {len(jieba_candidates)} æ¡ç»“æœ")
        
        if isinstance(semantic_candidates, Exception):
            logger.error(f"è¯­ä¹‰æ£€ç´¢å¤±è´¥: {semantic_candidates}")
            semantic_candidates = []
        else:
            logger.info(f"è¯­ä¹‰æ£€ç´¢è¿”å› {len(semantic_candidates)} æ¡ç»“æœ")
        
        if isinstance(vector_candidates, Exception):
            logger.error(f"MMRæ£€ç´¢å¤±è´¥: {vector_candidates}")
            vector_candidates = []
        else:
            logger.info(f"MMRæ£€ç´¢è¿”å› {len(vector_candidates)} æ¡ç»“æœ")
        
        # ========== é˜¶æ®µ3: åˆå¹¶å»é‡ä¸æ··åˆæ‰“åˆ† ==========
        # å¦‚æœæ‰€æœ‰æ£€ç´¢éƒ½å¤±è´¥ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
        if not jieba_candidates and not semantic_candidates and not vector_candidates:
            logger.warning("æ‰€æœ‰æ£€ç´¢æ–¹æ³•éƒ½æœªè¿”å›ç»“æœ")
            return []
        
        logger.info("å¼€å§‹åˆå¹¶å»é‡ä¸æ··åˆæ‰“åˆ†...")
        
        # ä½¿ç”¨æ–°çš„æƒé‡é…ç½®ï¼šjieba:semantic:mmr = 3:5:2
        merged_results =self._merge_and_score_v3(
            search_strategy,
            jieba_candidates,
            semantic_candidates,
            vector_candidates,  # æ·»åŠ MMRç»“æœ
            target_count=top_k
        )
        logger.info(f"åˆå¹¶åå…± {len(merged_results)} æ¡ç»“æœï¼ˆå·²å»é‡ï¼‰")
        
        # ========== é˜¶æ®µ4: æ’åºå¹¶è¿”å›top_k ==========
        merged_results.sort(key=lambda x: x['final_score'], reverse=True)
        
        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_results = [
            s for s in merged_results 
            if s.get('final_score', 0) >= similarity_threshold
        ]
        
        logger.info(f"è¿‡æ»¤åå‰©ä½™ {len(filtered_results)} æ¡ç»“æœï¼Œè¿”å›top_{top_k}")
        processing_time_ms = int((time.time() - start_time) * 1000)
        logger.info(f"ç¬¬ä¸€é˜¶æ®µå¤„ç†æ—¶é—´ï¼š{processing_time_ms}")
        return filtered_results[:top_k]

   
    async def _jieba_fuzzy_search(
            self,
            query_text: str,
            medical_dict: Optional[List] = None,
            top_p: int = 50,
            top_k: int = 10
    ) -> list[Any] | list[Exception]:
        """
        jiebaåˆ†è¯ + æ¨¡ç³ŠåŒ¹é…æ£€ç´¢ï¼ˆé«˜å¹¶å‘ä¼˜åŒ–ï¼šä½¿ç”¨ç‹¬ç«‹ sessionï¼‰
        """
        #æš‚æ—¶ä¸ä½¿ç”¨
        return []
        # 1. ä½¿ç”¨æ··åˆåˆ†è¯ï¼ˆjieba + LLMå¹¶å‘éªŒè¯ï¼‰
        keywords, new_terms = await self._hybrid_tokenize_with_llm_verification(query_text, medical_dict)
        logger.info(f"ğŸ” æ··åˆåˆ†è¯æå–åˆ° {len(keywords)} ä¸ªå…³é”®è¯: {keywords[:10]}")
        if new_terms:
            logger.info(f"âœ¨ æœ¬æ¬¡æ–°å‘ç° {len(new_terms)} ä¸ªåŒ»å­¦æœ¯è¯­: {new_terms}")
            logger.info(f"âœ… è¿™äº›æ–°è¯å·²åŠ¨æ€æ·»åŠ åˆ°jiebaå†…ç½®è¯å…¸ï¼Œåç»­åˆ†è¯ä¼šè‡ªåŠ¨ä½¿ç”¨")

        if not keywords:
            logger.warning("jiebaåˆ†è¯æœªæå–åˆ°å…³é”®è¯ï¼Œè¿”å›ç©ºç»“æœ")
            return []

        # 2. æ„å»ºSQLæ¨¡ç³ŠåŒ¹é…æ¡ä»¶ï¼ˆä½¿ç”¨LIKEï¼‰
        top_keywords = keywords
        like_conditions = [
            ClinicalScenario.description_zh.contains(keyword)
            for keyword in top_keywords
        ]

        # 3. é«˜å¹¶å‘ä¼˜åŒ–ï¼šä½¿ç”¨ç‹¬ç«‹ session æ‰§è¡Œæ¨¡ç³ŠåŒ¹é…æŸ¥è¯¢
        session = await self._get_independent_session()
        try:
            statement = (
                select(ClinicalScenario)
                .options(
                    selectinload(ClinicalScenario.panel),
                    selectinload(ClinicalScenario.topic)
                )
                .where(
                    and_(
                        ClinicalScenario.is_active == True,
                        or_(*like_conditions)
                    )
                )
                .limit(top_p)
            )

            result = await session.exec(statement)
            scenarios = result.all()
            logger.info(f"æ¨¡ç³ŠåŒ¹é…æ£€ç´¢åˆ° {len(scenarios)} æ¡åœºæ™¯")
        except Exception as e:
            logger.error(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
            return []
        finally:
            await session.close()

        if not scenarios:
            return []

        # 4. è®¡ç®—æ¯ä¸ªåœºæ™¯çš„jiebaåˆ†è¯é‡å åº¦å¾—åˆ†
        query_keywords_set = set(keywords)
        candidates_with_scores = []

        for scenario in scenarios:
            scenario_keywords = set(self._jieba_tokenize(
                scenario.description_zh or "",
                medical_dict,
                new_terms
            ))

            overlap = query_keywords_set.intersection(scenario_keywords)
            union = query_keywords_set.union(scenario_keywords)

            if len(union) > 0:
                jieba_score = len(overlap) / len(union)
            else:
                jieba_score = 0.0

            candidates_with_scores.append({
                'scenario': scenario,
                'scenario_id': scenario.id,
                'score': jieba_score,
                'matched_keywords': list(overlap),
                'source':"jieba"
            })

        logger.info(f"âœ… åˆ†è¯è¯„åˆ†å®Œæˆï¼Œå…± {len(candidates_with_scores)} ä¸ªç»“æœ")

        # 5. æ£€æŸ¥æ˜¯å¦éœ€è¦å½’ä¸€åŒ–å¹¶å¤„ç†
        if candidates_with_scores:
            max_score = max(candidate['jieba_score'] for candidate in candidates_with_scores)
            logger.info(f"ğŸ“Š å½’ä¸€åŒ–å‰æœ€å¤§åˆ†æ•°: {max_score:.4f}")

            if max_score < 0.7:
                logger.info("ğŸ“ˆ æœ€å¤§åˆ†æ•°ä½äº0.7ï¼Œè¿›è¡Œéçº¿æ€§å½’ä¸€åŒ–å¤„ç†")
                candidates_with_scores = self._normalize_scores_nonlinear(candidates_with_scores,
                                                                          method="power"
                                                                          )
            else:
                logger.info("âœ… æœ€å¤§åˆ†æ•°è¾¾åˆ°0.7ï¼Œä¿æŒåŸå§‹åˆ†æ•°")

        # 6. æŒ‰jieba_scoreæ’åº
        candidates_with_scores.sort(key=lambda x: x['jieba_score'], reverse=True)
        logger.info(f"ğŸ“Š æ’åºåå‰3ååˆ†æ•°: {[r['jieba_score'] for r in candidates_with_scores[:3]]}")

        # 7. è¿”å›top_k
        final_results = candidates_with_scores[:top_k]
        logger.info(f"âœ… è¿”å› {len(final_results)} æ¡jiebaæ£€ç´¢ç»“æœ")
        return final_results

    def _normalize_scores_nonlinear(self, candidates: List[Dict], method: str = "sigmoid") -> List[Dict]:
        """
        éçº¿æ€§å½’ä¸€åŒ–åˆ†æ•°åˆ°0.5~0.95èŒƒå›´

        Args:
            candidates: åŒ…å«jieba_scoreçš„å€™é€‰åˆ—è¡¨
            method: å½’ä¸€åŒ–æ–¹æ³•ï¼Œå¯é€‰ "sigmoid", "power", "log", "exponential"

        Returns:
            å½’ä¸€åŒ–åçš„å€™é€‰åˆ—è¡¨
        """

        if not candidates:
            return candidates

        # æå–åŸå§‹åˆ†æ•°
        scores = [candidate['jieba_score'] for candidate in candidates]
        min_score = min(scores)
        max_score = max(scores)

        logger.info(f"ğŸ“ˆ {method}å½’ä¸€åŒ–å‰åˆ†æ•°èŒƒå›´: [{min_score:.4f}, {max_score:.4f}]")

        # å¦‚æœæ‰€æœ‰åˆ†æ•°ç›¸åŒï¼Œç›´æ¥è®¾ç½®åˆ°ä¸­é—´å€¼
        if abs(max_score - min_score) < 1e-6:
            for candidate in candidates:
                candidate['jieba_score'] = 0.8
            logger.info("ğŸ“Š æ‰€æœ‰åˆ†æ•°ç›¸åŒï¼Œè®¾ç½®ä¸ºä¸­é—´å€¼0.725")
            return candidates

        for candidate in candidates:
            # å…ˆçº¿æ€§å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
            x = (candidate['jieba_score'] - min_score) / (max_score - min_score)

            if method == "sigmoid":
                # Sigmoidå‡½æ•°å½’ä¸€åŒ– - å¼ºåŒ–ä¸­é—´åŒºåŸŸ
                normalized_score = self._sigmoid_normalize(x)
            elif method == "power":
                # å¹‚å‡½æ•°å½’ä¸€åŒ– - å¯ä»¥å¼ºåŒ–é«˜åˆ†æˆ–ä½åˆ†åŒºåŸŸ
                normalized_score = self._power_normalize(x, power=0.6)
            elif method == "log":
                # å¯¹æ•°å½’ä¸€åŒ– - å‹ç¼©é«˜åˆ†åŒºåŸŸï¼Œæ‹‰ä¼¸ä½åˆ†åŒºåŸŸ
                normalized_score = self._log_normalize(x)
            elif method == "exponential":
                # æŒ‡æ•°å½’ä¸€åŒ– - æ‹‰ä¼¸é«˜åˆ†åŒºåŸŸï¼Œå‹ç¼©ä½åˆ†åŒºåŸŸ
                normalized_score = self._exponential_normalize(x)
            elif method == "tanh":
                # åŒæ›²æ­£åˆ‡å½’ä¸€åŒ– - æ¸©å’Œçš„éçº¿æ€§
                normalized_score = self._tanh_normalize(x)
            else:
                # é»˜è®¤ä½¿ç”¨çº¿æ€§å½’ä¸€åŒ–
                normalized_score = 0.5 + 0.45 * x

            candidate['jieba_score'] = normalized_score

        # éªŒè¯å½’ä¸€åŒ–ç»“æœ
        normalized_scores = [candidate['jieba_score'] for candidate in candidates]
        logger.info(f"ğŸ“ˆ {method}å½’ä¸€åŒ–ååˆ†æ•°èŒƒå›´: [{min(normalized_scores):.4f}, {max(normalized_scores):.4f}]")

        return candidates

    def _sigmoid_normalize(self, x: float) -> float:
        """Sigmoidå‡½æ•°å½’ä¸€åŒ– - å¼ºåŒ–ä¸­é—´åŒºåŸŸ"""
        # å°†è¾“å…¥è°ƒæ•´åˆ°æ›´é€‚åˆsigmoidçš„èŒƒå›´
        x_scaled = (x - 0.5) * 6  # è°ƒæ•´ç¼©æ”¾å› å­æ¥æ§åˆ¶æ›²çº¿é™¡å³­ç¨‹åº¦
        sigmoid = 1 / (1 + math.exp(-x_scaled))
        # æ˜ å°„åˆ°0.5-0.95èŒƒå›´
        return 0.5 + 0.45 * sigmoid

    def _power_normalize(self, x: float, power: float = 0.7) -> float:
        """å¹‚å‡½æ•°å½’ä¸€åŒ– - power<1å¼ºåŒ–é«˜åˆ†ï¼Œpower>1å¼ºåŒ–ä½åˆ†"""
        powered = x ** power
        return 0.5 + 0.45 * powered

    def _log_normalize(self, x: float) -> float:
        """å¯¹æ•°å½’ä¸€åŒ– - å‹ç¼©é«˜åˆ†åŒºåŸŸ"""
        # é¿å…log(0)
        if x < 0.001:
            x = 0.001
        log_norm = math.log(x + 1) / math.log(2)  # log2(x+1) å½’ä¸€åŒ–åˆ°0-1
        return 0.5 + 0.45 * log_norm

    def _exponential_normalize(self, x: float) -> float:
        """æŒ‡æ•°å½’ä¸€åŒ– - æ‹‰ä¼¸é«˜åˆ†åŒºåŸŸ"""
        exp_norm = (math.exp(x) - 1) / (math.e - 1)
        return 0.5 + 0.45 * exp_norm

    def _tanh_normalize(self, x: float) -> float:
        """åŒæ›²æ­£åˆ‡å½’ä¸€åŒ– - æ¸©å’Œçš„éçº¿æ€§"""
        x_scaled = (x - 0.5) * 3  # è°ƒæ•´ç¼©æ”¾å› å­
        tanh_norm = (math.tanh(x_scaled) + 1) / 2
        return 0.5 + 0.45 * tanh_norm
    def _normalize_scores_by_linear(self, candidates: List[Dict]) -> List[Dict]:
        """
        å½’ä¸€åŒ–åˆ†æ•°åˆ°0.5~0.95èŒƒå›´

        Args:
            candidates: åŒ…å«jieba_scoreçš„å€™é€‰åˆ—è¡¨

        Returns:
            å½’ä¸€åŒ–åçš„å€™é€‰åˆ—è¡¨
        """
        if not candidates:
            return candidates

        # æå–åŸå§‹åˆ†æ•°
        scores = [candidate['jieba_score'] for candidate in candidates]
        min_score = min(scores)
        max_score = max(scores)

        logger.info(f"ğŸ“ˆ å½’ä¸€åŒ–å‰åˆ†æ•°èŒƒå›´: [{min_score:.4f}, {max_score:.4f}]")

        # å¦‚æœæ‰€æœ‰åˆ†æ•°ç›¸åŒï¼Œç›´æ¥è®¾ç½®åˆ°ä¸­é—´å€¼
        if abs(max_score - min_score) < 1e-6:
            for candidate in candidates:
                candidate['jieba_score'] = 0.725  # 0.5~0.95çš„ä¸­é—´å€¼
            logger.info("ğŸ“Š æ‰€æœ‰åˆ†æ•°ç›¸åŒï¼Œè®¾ç½®ä¸ºä¸­é—´å€¼0.725")
            return candidates

        # çº¿æ€§å½’ä¸€åŒ–åˆ°0.5~0.95èŒƒå›´
        # å…¬å¼: normalized = 0.5 + 0.45 * (åŸå§‹åˆ†æ•° - æœ€å°å€¼) / (æœ€å¤§å€¼ - æœ€å°å€¼)
        for candidate in candidates:
            normalized_score = 0.5 + 0.45 * (candidate['jieba_score'] - min_score) / (max_score - min_score)
            candidate['jieba_score'] = normalized_score

        # éªŒè¯å½’ä¸€åŒ–ç»“æœ
        normalized_scores = [candidate['jieba_score'] for candidate in candidates]
        logger.info(f"ğŸ“ˆ å½’ä¸€åŒ–ååˆ†æ•°èŒƒå›´: [{min(normalized_scores):.4f}, {max(normalized_scores):.4f}]")

        return candidates
    
    async def _semantic_vector_search(
        self,
        query_text: str,
        patient_info: PatientInfo,
        clinical_context: ClinicalContext,
        # embedding_model: EmbeddingClientSDK,
        top_p: int = 50,
        top_k: int = 10,
        similarity_threshold: float = 0.6
    ) -> List[Dict[str, Any]]:
        # 1. å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¸¦ç¼“å­˜ï¼‰
        if not await self.vector_service.milvus_vector_store():
            logger.warning("å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
            return []

        # 2. é«˜å¹¶å‘ä¼˜åŒ–ï¼šä½¿ç”¨ç‹¬ç«‹ session æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
        try:
            vector_store = await self.vector_service.milvus_vector_store()
            documents = await vector_store.asimilarity_search_with_relevance_scores(query=query_text, k=top_p)
            logger.info(f"æŸ¥è¯¢æˆåŠŸï¼Œå…±æŸ¥åˆ°ï¼š{len(documents)}æ¡æ•°æ®")
        except Exception as e:
            logger.info(f"æŸ¥è¯¢å¤±è´¥è¯·ç¨åé‡è¯•ï¼š{e}")
            return []

        # è¿‡æ»¤: åªä¿ç•™æŒ‡å®šç§‘å®¤çš„æ–‡æ¡£
        new_documents = [(document, score) for document, score in documents
                         if str(document.metadata.get("panel_name", "")) == str(clinical_context.department)]

        # æ–‡æ¡£è¡¥å……é€»è¾‘
        if len(new_documents) < top_p:
            logger.info(f"è¿‡æ»¤åæ–‡æ¡£æ•°é‡ {len(new_documents)} ä¸è¶³ {top_p}ï¼Œå¼€å§‹è¡¥å……æ–‡æ¡£")

            # è·å–æœªè¢«è¿‡æ»¤çš„æ–‡æ¡£ï¼ˆå…¶ä»–ç§‘å®¤çš„æ–‡æ¡£ï¼‰
            other_documents = [(document, score) for document, score in documents
                               if str(document.metadata.get("panel_name", "")) != str(clinical_context.department)]

            # æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°é™åºæ’åºå…¶ä»–æ–‡æ¡£
            other_documents_sorted = sorted(other_documents, key=lambda x: x[1], reverse=True)

            # è®¡ç®—éœ€è¦è¡¥å……çš„æ•°é‡
            need_supplement_count = top_p - len(new_documents)

            # è¡¥å……æ–‡æ¡£
            supplement_documents = other_documents_sorted[:need_supplement_count]
            new_documents.extend(supplement_documents)

            logger.info(f"è¡¥å……äº† {len(supplement_documents)} ä¸ªæ–‡æ¡£ï¼Œç°åœ¨å…±æœ‰ {len(new_documents)} ä¸ªæ–‡æ¡£")

        # å¦‚æœç»è¿‡è¿‡æ»¤å’Œè¡¥å……å new_documents ä»ç„¶ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨åŸå§‹ documents
        if not new_documents:
            logger.warning("è¿‡æ»¤åæ— æ–‡æ¡£ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢ç»“æœ")
            new_documents = documents

        # å¤„ç†æ–‡æ¡£IDæ˜ å°„
        id_to_doc_score = {}  # {id: (doc, score)}
        for doc, score in new_documents:
            # ä»metadataä¸­è·å–scenario_id
            try:
                id = int(doc.metadata.get('id') or doc.id or doc.get('id'))
                id_to_doc_score[id] = (doc, score)
            except (ValueError, TypeError, AttributeError) as e:
                logger.warning(f"æ–‡æ¡£IDè§£æå¤±è´¥ï¼Œè·³è¿‡: {doc.metadata}, é”™è¯¯: {e}")
                continue

        if not id_to_doc_score:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„IDå¯ä¾›æŸ¥è¯¢")
            return []

        # 3.2 é«˜å¹¶å‘ä¼˜åŒ–ï¼šä½¿ç”¨ç‹¬ç«‹ session æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰scenarioå¯¹è±¡
        scenario_ids = list(id_to_doc_score.keys())

        session = await self._get_independent_session()
        try:
            statement = (
                select(ClinicalScenario)
                .options(selectinload(ClinicalScenario.topic),
                         selectinload(ClinicalScenario.panel)
                         )
                .where(
                    ClinicalScenario.id.in_(scenario_ids)
                ))
            result = await session.exec(statement)
            scenarios = result.all()

            logger.info(f"æ‰¹é‡æŸ¥è¯¢åˆ° {len(scenarios)} ä¸ªscenarioå¯¹è±¡")
        finally:
            await session.close()  # ç¡®ä¿å…³é—­ session

        # 3.3 æ„å»º id -> scenario æ˜ å°„
        id_to_scenario = {scenario.id: scenario for scenario in scenarios}

        # 3.4 ç»„è£…å€™é€‰ç»“æœ
        candidates = []
        for id, (doc, score) in id_to_doc_score.items():
            scenario = id_to_scenario.get(id)
            if not scenario:
                logger.warning(f"æœªæ‰¾åˆ°scenario: {id}")
                continue

            # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
            if score >= similarity_threshold:
                candidates.append({
                    'scenario': scenario,
                    'scenario_id': scenario.id,
                    'score': score,
                    'document_content': doc.page_content,
                    'source':"semantic"
                    # ä¿å­˜åŸå§‹æ–‡æ¡£å†…å®¹
                })

        # æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°æ’åºå¹¶è¿”å›å‰top_kä¸ªç»“æœ
        candidates_sorted = sorted(candidates, key=lambda x: x['score'], reverse=True)
        return candidates_sorted[:top_k]






































    def _merge_and_score_v3(
            self,
            search_strategy: SearchStrategy,
            jieba_candidates: List[Dict[str, Any]],
            semantic_candidates: List[Dict[str, Any]],
            mmr_candidates: List[Dict[str, Any]] = None,
            target_count: int = 16
    ) -> List[Dict[str, Any]]:
        """
        Fine-grained hierarchical merging strategy

        Strategy:
        1. First level: All three methods match (all retained)
        2. Second Level: Two methods match (using different weights based on combination type)
        3. Third Level: Single method match (average allocation of slots based on category)

        Return Logic:
        - All of the first level are retained
        - Ranked by weighted score at level 2
        - If the total is less than target_count, supplement from level 3
        - Level 3 allocates spots with priority semantic>mmr>jieba

        Args:
            jieba_candidates: jieba search results
            semantic_candidates: semantic search results
            mmr_candidates: MMR search results
            target_count: target return count (default 16)

        Returns:
            The merged result list
        """
        if mmr_candidates is None:
            mmr_candidates = []
        if jieba_candidates is None:
            jieba_candidates = []
        if semantic_candidates is None:
            semantic_candidates = []

        # Build ID to candidate mapping
        jieba_dict = {item['scenario_id']: item for item in jieba_candidates}
        semantic_dict = {item['scenario_id']: item for item in semantic_candidates}
        mmr_dict = {item['scenario_id']: item for item in mmr_candidates}

        all_ids = set(jieba_dict.keys()) | set(semantic_dict.keys()) | set(mmr_dict.keys())

        # Hierarchical processing
        level_1 = []  # Matched by all three methods
        level_2_js = []  # jieba + semantic
        level_2_jm = []  # jieba + mmr
        level_2_ms = []  # mmr + semantic
        level_3_j = []  # only jieba
        level_3_s = []  # Only semantic
        level_3_m = []  # Only mmr

        for scenario_id in all_ids:
            sources = []
            if scenario_id in jieba_dict:
                sources.append('jieba')
            if scenario_id in semantic_dict:
                sources.append('semantic')
            if scenario_id in mmr_dict:
                sources.append('mmr')

            # Building merged data with unified field names
            merged_data = {
                'scenario_id': scenario_id,
                'scenario': None,
                'jieba_score': 0.0,
                'semantic_score': 0.0,
                'mmr_score': 0.0,
                'document_content': '',
                'matched_keywords': [],
                'source': 'merged'
            }

            # Merge data from all available sources
            if scenario_id in jieba_dict:
                jieba_item = jieba_dict[scenario_id]
                merged_data['jieba_score'] = jieba_item['score']
                merged_data['scenario'] = jieba_item['scenario']
                if 'matched_keywords' in jieba_item:
                    merged_data['matched_keywords'] = jieba_item['matched_keywords']

            if scenario_id in semantic_dict:
                semantic_item = semantic_dict[scenario_id]
                merged_data['semantic_score'] = semantic_item['score']
                merged_data['scenario'] = semantic_item['scenario']
                if 'document_content' in semantic_item:
                    merged_data['document_content'] = semantic_item['document_content']

            if scenario_id in mmr_dict:
                mmr_item = mmr_dict[scenario_id]
                merged_data['mmr_score'] = mmr_item['score']
                merged_data['scenario'] = mmr_item['scenario']
                if 'document_content' in mmr_item and not merged_data['document_content']:
                    merged_data['document_content'] = mmr_item['document_content']

            # Categorize based on the number of matching methods
            if len(sources) == 3:
                # Level 1: All three methods match, use fixed weights
                jieba_score_standard = search_strategy.keyword_weight * merged_data[
                    'jieba_score'] if search_strategy.keyword_weight else 0.2 * merged_data['jieba_score']
                semantic_score_standard = search_strategy.vector_weight * merged_data[
                    'semantic_score'] if search_strategy.vector_weight else 0.5 * merged_data['semantic_score']
                mmr_score_standard = search_strategy.diversity_weight * merged_data[
                    'mmr_score'] if search_strategy.diversity_weight else 0.3 * merged_data['mmr_score']

                final_score = (
                        jieba_score_standard +
                        semantic_score_standard +
                        mmr_score_standard
                )
                merged_data['final_score'] = final_score
                merged_data['match_level'] = 1
                level_1.append(merged_data)

            elif len(sources) == 2:
                # Second level: Two methods match, use different weights based on different combinations
                if 'jieba' in sources and 'semantic' in sources:
                    final_score = (
                            0.4 * merged_data['jieba_score'] +
                            0.6 * merged_data['semantic_score']
                    )
                    merged_data['final_score'] = final_score
                    merged_data['match_level'] = 2
                    merged_data['combo_type'] = 'jieba+semantic'
                    level_2_js.append(merged_data)

                elif 'jieba' in sources and 'mmr' in sources:
                    final_score = (
                            0.4 * merged_data['jieba_score'] +
                            0.6 * merged_data['mmr_score']
                    )
                    merged_data['final_score'] = final_score
                    merged_data['match_level'] = 2
                    merged_data['combo_type'] = 'jieba+mmr'
                    level_2_jm.append(merged_data)

                elif 'mmr' in sources and 'semantic' in sources:
                    final_score = (
                            0.5 * merged_data['mmr_score'] +
                            0.5 * merged_data['semantic_score']
                    )
                    merged_data['final_score'] = final_score
                    merged_data['match_level'] = 2
                    merged_data['combo_type'] = 'mmr+semantic'
                    level_2_ms.append(merged_data)

            else:
                # Third level: Single method matching
                merged_data['match_level'] = 3
                if 'jieba' in sources:
                    merged_data['final_score'] = merged_data['jieba_score']
                    merged_data['combo_type'] = 'jieba_only'
                    level_3_j.append(merged_data)
                elif 'semantic' in sources:
                    merged_data['final_score'] = merged_data['semantic_score']
                    merged_data['combo_type'] = 'semantic_only'
                    level_3_s.append(merged_data)
                else:  # 'mmr'
                    merged_data['final_score'] = merged_data['mmr_score']
                    merged_data['combo_type'] = 'mmr_only'
                    level_3_m.append(merged_data)

        # Sorting within levels
        level_1.sort(key=lambda x: x['final_score'], reverse=True)
        level_2_js.sort(key=lambda x: x['final_score'], reverse=True)
        level_2_jm.sort(key=lambda x: x['final_score'], reverse=True)
        level_2_ms.sort(key=lambda x: x['final_score'], reverse=True)
        level_3_j.sort(key=lambda x: x['final_score'], reverse=True)
        level_3_s.sort(key=lambda x: x['final_score'], reverse=True)
        level_3_m.sort(key=lambda x: x['final_score'], reverse=True)

        # Merge Level 2
        level_2_all = level_2_js + level_2_jm + level_2_ms
        level_2_all.sort(key=lambda x: x['final_score'], reverse=True)

        # Statistics Information
        logger.info(
            f"Tiered statistics: First tier ({len(level_1)}), Second tier(js:{len(level_2_js)}, jm:{len(level_2_jm)}, ms:{len(level_2_ms)}), "
            f"Level 3 (j:{len(level_3_j)}, s:{len(level_3_s)}, m:{len(level_3_m)})"
        )

        # Execute return strategy
        return self._level_based_selection(
            level_1, level_2_all, level_3_j, level_3_s, level_3_m, target_count
        )

    def _level_based_selection(
            self, level_1, level_2, level_3_j, level_3_s, level_3_m, target_count
    ):
        """
        Tiered selection strategy
        """
        results = []

        # First tier: Keep all
        results.extend(level_1)
        logger.info(f"First level selected {len(level_1)} results")

        # If the first level already meets the requirements, return directly
        if len(results) >= target_count:
            logger.info(f"First-level results have met the target count {target_count}, returning directly")
            return results[:target_count]

        # Second level: Add all (already sorted by score)
        results.extend(level_2)
        logger.info(f"Selected {len(level_2)} results at level 2")

        # If level 1 + level 2 already meet the requirement, return
        current_count = len(results)
        if current_count >= target_count:
            logger.info(
                f"First level + second level results have met the target count {target_count}, returning directly")
            return results[:target_count]

        # Third level: Number of items needed to supplement
        needed_from_level_3 = target_count - current_count
        logger.info(f"Need to supplement {needed_from_level_3} results from level 3")

        # Level 3 allocation strategy
        level_3_selected = self._select_from_level_3(
            level_3_j, level_3_s, level_3_m, needed_from_level_3
        )
        results.extend(level_3_selected)

        # Final statistics
        final_count = len(results)
        level_1_count = len(level_1)
        level_2_count = len(level_2)
        level_3_count = len(level_3_selected)

        logger.info(
            f"Final result distribution: Level 1 ({level_1_count}), Level 2 ({level_2_count}), "
            f"Level 3 ({level_3_count}), Total ({final_count})"
        )

        return results[:target_count]

    def _select_from_level_3(self, level_3_j, level_3_s, level_3_m, needed_count):
        """
        Selection from Level 3 Results - Improved Round-Robin Selection Strategy

        Strategy:
        1. Select in a rotating loop according to the priority order of semantic -> mmr -> jieba
        2. In each loop, select the result with the highest score from the current category
        3. Until the required number is reached or all categories are exhausted
        """
        if needed_count <= 0:
            return []

        selected = []

        # Create copies of each category to avoid modifying the original data
        j_list = level_3_j.copy()
        s_list = level_3_s.copy()
        m_list = level_3_m.copy()

        # Priority order: semantic -> mmr -> jieba
        priority_order = [
            ('semantic', s_list),
            ('mmr', m_list),
            ('jieba', j_list)
        ]

        # Select in a loop until the required count is met or all lists are empty
        while needed_count > 0 and any(lst for _, lst in priority_order):
            # Take the first item (with the highest score) from each non-empty list in turn according to priority order
            for source_type, source_list in priority_order:
                if needed_count <= 0:
                    break

                if source_list:  # If there are still candidates in the current category
                    # Select the candidate with the highest score in the current category
                    candidate = source_list.pop(0)
                    selected.append(candidate)
                    needed_count -= 1

                    logger.debug(
                        f"Selecting from {source_type}: {candidate['scenario_id']} (score: {candidate['final_score']:.4f})"
                    )

        # Record the final assignment
        final_j_count = len(level_3_j) - len(j_list)
        final_s_count = len(level_3_s) - len(s_list)
        final_m_count = len(level_3_m) - len(m_list)

        logger.info(
            f"Third-level loop assignment completed: semantic({final_s_count}), mmr({final_m_count}), jieba({final_j_count}), "
            f"Total ({len(selected)})"
        )

        return selected



    def _build_merged_data(self, scenario_id, jieba_dict, semantic_dict, mmr_dict):
        """æ„å»ºåˆå¹¶æ•°æ®"""
        data = {
            'scenario_id': scenario_id,
            'jieba_score': 0,
            'semantic_score': 0,
            'mmr_score': 0,
            'matched_keywords': [],
            'sources': []
        }

        # åˆå¹¶jiebaæ•°æ®
        if scenario_id in jieba_dict:
            item = jieba_dict[scenario_id]
            data['scenario'] = item['scenario']
            data['jieba_score'] = item.get('score', 0)
            data['matched_keywords'] = item.get('matched_keywords', [])
            data['sources'].append('jieba')

        # åˆå¹¶è¯­ä¹‰æ•°æ®
        if scenario_id in semantic_dict:
            item = semantic_dict[scenario_id]
            data['scenario'] = item['scenario']  # ä¼šè¦†ç›–ï¼Œä½†scenarioåº”è¯¥ç›¸åŒ
            data['semantic_score'] = item.get('score', 0)
            data['sources'].append('semantic')

        # åˆå¹¶MMRæ•°æ®
        if scenario_id in mmr_dict:
            item = mmr_dict[scenario_id]
            data['scenario'] = item['scenario']  # ä¼šè¦†ç›–ï¼Œä½†scenarioåº”è¯¥ç›¸åŒ
            data['mmr_score'] = item.get('score', 0)
            data['sources'].append('mmr')
            if 'document_content' in item:
                data['document_content'] = item['document_content']

        return data

    def _select_by_level_strategy(self, level_1, level_2, level_3_jieba, level_3_semantic, level_3_mmr, max_results=15):
        """
        åˆ†çº§è¿”å›ç­–ç•¥ï¼š
        1. ç¬¬ä¸€çº§å…¨éƒ¨ä¿ç•™
        2. ç¬¬äºŒçº§å–å‰6ä¸ªï¼ˆä¸è¶³åˆ™å…¨å–ï¼‰
        3. å‰©ä½™åé¢åˆ†é…ç»™ç¬¬ä¸‰çº§ï¼Œå„æ–¹æ³•åˆ†åˆ«å–å‰4ä¸ª
        """
        results = []

        # ç¬¬ä¸€çº§ï¼šå…¨éƒ¨ä¿ç•™ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        results.extend(level_1)
        remaining_slots = max_results - len(results)

        if remaining_slots <= 0:
            logger.info("ç¬¬ä¸€çº§ç»“æœå·²æ»¡é¢ï¼Œç›´æ¥è¿”å›")
            return results[:max_results]

        # ç¬¬äºŒçº§ï¼šå–å‰min(6, remaining_slots/2)ä¸ª
        level_2_slots = min(6, remaining_slots // 2)
        level_2_selected = level_2[:level_2_slots]
        results.extend(level_2_selected)
        remaining_slots = max_results - len(results)

        if remaining_slots <= 0:
            logger.info("ç¬¬ä¸€çº§+ç¬¬äºŒçº§ç»“æœå·²æ»¡é¢")
            return results[:max_results]

        # ç¬¬ä¸‰çº§ï¼šå„æ–¹æ³•åˆ†åˆ«å–å‰4ä¸ªï¼ŒæŒ‰åˆ†æ•°æ’åº
        level_3_all = []

        # å„æ–¹æ³•åˆ†åˆ«é€‰å–
        jieba_selected = level_3_jieba[:4]
        semantic_selected = level_3_semantic[:4]
        mmr_selected = level_3_mmr[:4]

        level_3_all.extend(jieba_selected)
        level_3_all.extend(semantic_selected)
        level_3_all.extend(mmr_selected)

        # æŒ‰åˆ†æ•°æ’åºå¹¶é€‰å–å‰©ä½™åé¢
        level_3_all.sort(key=lambda x: x['final_score'], reverse=True)
        level_3_selected = level_3_all[:remaining_slots]
        results.extend(level_3_selected)

        # æœ€ç»ˆç»Ÿè®¡
        final_count = len(results)
        logger.info(
            f"æœ€ç»ˆç»“æœ: ç¬¬ä¸€çº§({len(level_1)}), ç¬¬äºŒçº§({len(level_2_selected)}), "
            f"ç¬¬ä¸‰çº§({len(level_3_selected)}), æ€»è®¡({final_count})"
        )

        return results[:max_results]
    # def _select_from_level_3(self, level_3_j, level_3_s, level_3_m, needed_count):
    #     """
    #     ä»ç¬¬ä¸‰çº§é€‰æ‹©ç»“æœ
    #
    #     ç­–ç•¥ï¼š
    #     1. å¦‚æœéœ€è¦çš„æ•°é‡ <= 9ï¼ŒæŒ‰ semantic > mmr > jieba ä¼˜å…ˆçº§åˆ†é…
    #     2. å¦‚æœéœ€è¦çš„æ•°é‡ > 9ï¼Œæ¯ç±»å¹³å‡åˆ†é…ï¼ˆå„å– needed_count/3ï¼‰
    #     """
    #     if needed_count <= 0:
    #         return []
    #
    #     selected = []
    #
    #     # å¦‚æœéœ€æ±‚æ•°é‡è¾ƒå°‘ï¼ŒæŒ‰ä¼˜å…ˆçº§åˆ†é…
    #     if needed_count <= 9:
    #         # è®¡ç®—æ¯ç±»åº”è¯¥åˆ†é…çš„åé¢
    #         semantic_slots = min((needed_count + 2) // 3, len(level_3_s))  # å‘ä¸Šå–æ•´
    #         mmr_slots = min((needed_count + 1) // 3, len(level_3_m))  # ä¸­é—´å€¼
    #         jieba_slots = min(needed_count // 3, len(level_3_j))  # å‘ä¸‹å–æ•´
    #
    #         # æŒ‰ä¼˜å…ˆçº§è°ƒæ•´ï¼šsemantic > mmr > jieba
    #         remaining_slots = needed_count - (semantic_slots + mmr_slots + jieba_slots)
    #         while remaining_slots > 0:
    #             if len(level_3_s) > semantic_slots:
    #                 semantic_slots += 1
    #             elif len(level_3_m) > mmr_slots:
    #                 mmr_slots += 1
    #             elif len(level_3_j) > jieba_slots:
    #                 jieba_slots += 1
    #             else:
    #                 break
    #             remaining_slots -= 1
    #     else:
    #         # éœ€æ±‚æ•°é‡è¾ƒå¤šï¼Œå¹³å‡åˆ†é…
    #         slots_per_type = (needed_count + 2) // 3  # å‘ä¸Šå–æ•´
    #         semantic_slots = min(slots_per_type, len(level_3_s))
    #         mmr_slots = min(slots_per_type, len(level_3_m))
    #         jieba_slots = min(slots_per_type, len(level_3_j))
    #
    #         # å¦‚æœè¿˜æœ‰å‰©ä½™åé¢ï¼ŒæŒ‰ä¼˜å…ˆçº§åˆ†é…
    #         current_total = semantic_slots + mmr_slots + jieba_slots
    #         remaining_slots = needed_count - current_total
    #
    #         priority_order = [('semantic', level_3_s), ('mmr', level_3_m), ('jieba', level_3_j)]
    #         for source_type, source_list in priority_order:
    #             if remaining_slots <= 0:
    #                 break
    #             if source_type == 'semantic' and len(level_3_s) > semantic_slots:
    #                 semantic_slots += 1
    #                 remaining_slots -= 1
    #             elif source_type == 'mmr' and len(level_3_m) > mmr_slots:
    #                 mmr_slots += 1
    #                 remaining_slots -= 1
    #             elif source_type == 'jieba' and len(level_3_j) > jieba_slots:
    #                 jieba_slots += 1
    #                 remaining_slots -= 1
    #
    #     # é€‰å–ç»“æœ
    #     selected.extend(level_3_s[:semantic_slots])
    #     selected.extend(level_3_m[:mmr_slots])
    #     selected.extend(level_3_j[:jieba_slots])
    #
    #     logger.info(
    #         f"ç¬¬ä¸‰çº§åˆ†é…: semantic({semantic_slots}), mmr({mmr_slots}), jieba({jieba_slots})"
    #     )
    #
    #     return selected
    # def _merge_and_score(
    #     self,
    #     jieba_candidates: List[Dict[str, Any]],
    #     semantic_candidates: List[Dict[str, Any]],
    #     mmr_candidates: List[Dict[str, Any]] = None,
    #     jieba_weight: float = 0.3,
    #     semantic_weight: float = 0.5,
    #     mmr_weight: float = 0.2
    # ) -> List[Dict[str, Any]]:
    #     """
    #     åˆå¹¶ä¸‰ä¸ªæ£€ç´¢ç»“æœï¼Œå»é‡å¹¶è®¡ç®—æ··åˆå¾—åˆ†
    #
    #     å…¬å¼ï¼šfinal_score = jieba_weight * jieba_score + semantic_weight * semantic_score + mmr_weight * mmr_score
    #
    #     Args:
    #         jieba_candidates: jiebaæ£€ç´¢ç»“æœ
    #         semantic_candidates: è¯­ä¹‰æ£€ç´¢ç»“æœ
    #         mmr_candidates: MMRæ£€ç´¢ç»“æœï¼ˆå¯é€‰ï¼‰
    #         jieba_weight: jiebaåˆ†æ•°æƒé‡ï¼ˆé»˜è®¤30%ï¼‰
    #         semantic_weight: è¯­ä¹‰åˆ†æ•°æƒé‡ï¼ˆé»˜è®¤50%ï¼‰
    #         mmr_weight: MMRåˆ†æ•°æƒé‡ï¼ˆé»˜è®¤20%ï¼‰
    #
    #     Returns:
    #         åˆå¹¶åçš„ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«final_scoreå­—æ®µ
    #     """
    #     # å¦‚æœæ²¡æœ‰æä¾›MMRç»“æœï¼Œåˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
    #     if mmr_candidates is None:
    #         mmr_candidates = []
    #
    #     # ä½¿ç”¨scenario_idä½œä¸ºkeyè¿›è¡Œåˆå¹¶ï¼ˆå»é‡ï¼‰
    #     merged_dict = {}
    #
    #     # 1. å¤„ç†jiebaç»“æœ
    #     for item in jieba_candidates:
    #         scenario_id = item['scenario_id']
    #         merged_dict[scenario_id] = {
    #             'scenario': item['scenario'],
    #             'scenario_id': scenario_id,
    #             'jieba_score': item.get('jieba_score', 0),
    #             'semantic_score': 0,  # é»˜è®¤0
    #             'mmr_score': 0,  # é»˜è®¤0
    #             'matched_keywords': item.get('matched_keywords', []),
    #             'sources': ['jieba']  # è®°å½•æ¥æº
    #         }
    #
    #     # 2. å¤„ç†è¯­ä¹‰ç»“æœï¼ˆåˆå¹¶æˆ–æ–°å¢ï¼‰
    #     for item in semantic_candidates:
    #         scenario_id = item['scenario_id']
    #         if scenario_id in merged_dict:
    #             # å·²å­˜åœ¨ï¼Œæ›´æ–°semantic_score
    #             merged_dict[scenario_id]['semantic_score'] = item.get('semantic_score', 0)
    #             merged_dict[scenario_id]['sources'].append('semantic')
    #         else:
    #             # ä¸å­˜åœ¨ï¼Œæ–°å¢
    #             merged_dict[scenario_id] = {
    #                 'scenario': item['scenario'],
    #                 'scenario_id': scenario_id,
    #                 'jieba_score': 0,  # é»˜è®¤0
    #                 'semantic_score': item.get('semantic_score', 0),
    #                 'mmr_score': 0,  # é»˜è®¤0
    #                 'matched_keywords': [],
    #                 'sources': ['semantic']
    #             }
    #
    #     # 3. å¤„ç†MMRç»“æœï¼ˆåˆå¹¶æˆ–æ–°å¢ï¼‰
    #     for item in mmr_candidates:
    #         scenario_id = item['scenario_id']
    #         if scenario_id in merged_dict:
    #             # å·²å­˜åœ¨ï¼Œæ›´æ–°mmr_score
    #             merged_dict[scenario_id]['mmr_score'] = item.get('mmr_score', 0)
    #             merged_dict[scenario_id]['sources'].append('mmr')
    #             # ä¿å­˜MMRçš„æ–‡æ¡£å†…å®¹
    #             if 'document_content' in item:
    #                 merged_dict[scenario_id]['document_content'] = item['document_content']
    #         else:
    #             # ä¸å­˜åœ¨ï¼Œæ–°å¢
    #             merged_dict[scenario_id] = {
    #                 'scenario': item['scenario'],
    #                 'scenario_id': scenario_id,
    #                 'jieba_score': 0,  # é»˜è®¤0
    #                 'semantic_score': 0,  # é»˜è®¤0
    #                 'mmr_score': item.get('mmr_score', 0),
    #                 'matched_keywords': [],
    #                 'document_content': item.get('document_content', ''),
    #                 'sources': ['mmr']
    #             }
    #
    #     # 4. è®¡ç®—æ··åˆå¾—åˆ†
    #     merged_results = []
    #     for scenario_id, data in merged_dict.items():
    #         # åŠ æƒè®¡ç®—æœ€ç»ˆå¾—åˆ†
    #         final_score = (
    #             jieba_weight * data['jieba_score'] +
    #             semantic_weight * data['semantic_score'] +
    #             mmr_weight * data['mmr_score']
    #         )
    #         data['final_score'] = final_score
    #
    #         # è®°å½•å„é¡¹å¾—åˆ†çš„è´¡çŒ®
    #         data['score_breakdown'] = {
    #             'jieba': jieba_weight * data['jieba_score'],
    #             'semantic': semantic_weight * data['semantic_score'],
    #             'mmr': mmr_weight * data['mmr_score']
    #         }
    #
    #         merged_results.append(data)
    #
    #     # 5. è®°å½•åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
    #     logger.info(
    #         f"åˆå¹¶ç»“æœ: jieba={len(jieba_candidates)}, "
    #         f"semantic={len(semantic_candidates)}, "
    #         f"mmr={len(mmr_candidates)}, "
    #         f"merged={len(merged_results)} (å»é‡å)"
    #     )
    #     logger.info(
    #         f"æƒé‡é…ç½®: jieba={jieba_weight:.1%}, "
    #         f"semantic={semantic_weight:.1%}, "
    #         f"mmr={mmr_weight:.1%}"
    #     )
    #
    #     m=merged_results.sort(key=lambda x: x['final_score'], reverse=True)
    #     return m[:15]
    #
    async def _build_structured_filters(
        self, 
        patient_info: PatientInfo, 
        clinical_context: ClinicalContext
    ) -> List[Any]:
        """
        æ„å»ºç»“æ„åŒ–è¿‡æ»¤æ¡ä»¶
        
        åŸºäºæ‚£è€…çš„ç¡¬æ€§æ¡ä»¶ï¼ˆå¹´é¾„ã€æ€§åˆ«ã€å¦Šå¨ çŠ¶æ€ã€ç´§æ€¥ç¨‹åº¦ï¼‰è¿›è¡Œç­›é€‰
        """
        filters = []
        
        # å¹´é¾„è¿‡æ»¤
        if patient_info.age is not None:
            # åŒ¹é…å¹´é¾„ç»„ï¼ˆå¦‚"40å²ä»¥ä¸Š"ã€"18-65å²"ç­‰ï¼‰
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è°ƒæ•´é€»è¾‘
            filters.append(
                or_(
                    ClinicalScenario.age_group.is_(None),
                    ClinicalScenario.age_group.like(f"%{patient_info.age}%")
                )
            )
        
        # æ€§åˆ«è¿‡æ»¤
        if patient_info.gender:
            filters.append(
                or_(
                    ClinicalScenario.gender.is_(None),
                    ClinicalScenario.gender == patient_info.gender,
                    ClinicalScenario.gender == "ä¸é™"
                )
            )
        
        # å¦Šå¨ çŠ¶æ€è¿‡æ»¤
        if patient_info.pregnancy_status:
            filters.append(
                or_(
                    ClinicalScenario.pregnancy_status.is_(None),
                    ClinicalScenario.pregnancy_status == patient_info.pregnancy_status
                )
            )
        
        # ç´§æ€¥ç¨‹åº¦è¿‡æ»¤
        if clinical_context.urgency_level:
            filters.append(
                or_(
                    ClinicalScenario.urgency_level.is_(None),
                    ClinicalScenario.urgency_level == clinical_context.urgency_level
                )
            )
        
        # æ¿€æ´»çŠ¶æ€
        filters.append(ClinicalScenario.is_active == True)
        
        return filters
    
    # async def _vector_semantic_search(
    #     self,
    #     patient_info: PatientInfo,
    #     clinical_context: ClinicalContext,
    #     embedding_model: Optional[Embedding],
    #     top_k: int = 30,
    # ) -> List[Dict[str, Any]]:
    #     """
    #     å‘é‡è¯­ä¹‰æ£€ç´¢ï¼ˆåŸºäºç»“æ„åŒ–æ ¼å¼ï¼‰
    #
    #     æ„å»ºæŸ¥è¯¢æ–‡æœ¬æ ¼å¼ï¼š
    #     ä¸»è¯‰: xxx
    #     æ—¢å¾€ç—…å²: xxx
    #     ç°ç—…å²: xxx
    #     è¯Šæ–­: xxx
    #     æ‚£è€…äººç¾¤: xxx
    #     å¹´é¾„ç»„: xxx
    #     æ€§åˆ«: xxx
    #     å¦Šå¨ çŠ¶æ€: xxx
    #     ç´§æ€¥ç¨‹åº¦: xxx
    #     """
    #     # æ„å»ºç»“æ„åŒ–æŸ¥è¯¢æ–‡æœ¬ï¼ˆåŒ¹é…æ•°æ®åº“ä¸­çš„embeddingæ ¼å¼ï¼‰
    #     query_parts = []
    #
    #     # æ·»åŠ ä¸´åºŠä¸Šä¸‹æ–‡ä¿¡æ¯
    #     if clinical_context.chief_complaint:
    #         query_parts.append(f"ä¸»è¯‰: {clinical_context.chief_complaint}")
    #
    #     if clinical_context.medical_history:
    #         query_parts.append(f"æ—¢å¾€ç—…å²: {clinical_context.medical_history}")
    #
    #     if clinical_context.present_illness:
    #         query_parts.append(f"ç°ç—…å²: {clinical_context.present_illness}")
    #
    #     if clinical_context.diagnosis:
    #         query_parts.append(f"è¯Šæ–­: {clinical_context.diagnosis}")
    #
    #     # æ·»åŠ æ‚£è€…ä¿¡æ¯ï¼ˆå¢å¼ºè¯­ä¹‰åŒ¹é…ï¼‰
    #     if patient_info.age:
    #         query_parts.append(f"å¹´é¾„: {patient_info.age}å²")
    #
    #     if patient_info.gender:
    #         query_parts.append(f"æ€§åˆ«: {patient_info.gender}")
    #
    #     if patient_info.pregnancy_status:
    #         query_parts.append(f"å¦Šå¨ çŠ¶æ€: {patient_info.pregnancy_status}")
    #
    #     if clinical_context.urgency_level:
    #         query_parts.append(f"ç´§æ€¥ç¨‹åº¦: {clinical_context.urgency_level}")
    #
    #     if clinical_context.symptom_severity:
    #         query_parts.append(f"ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦: {clinical_context.symptom_severity}")
    #
    #     # ç”¨æ¢è¡Œç¬¦è¿æ¥ï¼Œæ¨¡æ‹Ÿæ•°æ®åº“ä¸­çš„embeddingæ ¼å¼
    #     query_text = "\n".join(query_parts)
    #
    #     # ä½¿ç”¨åµŒå…¥æ¨¡å‹ç”ŸæˆæŸ¥è¯¢å‘é‡
    #     if not embedding_model:
    #         # å¦‚æœæ²¡æœ‰åµŒå…¥æ¨¡å‹ï¼Œä½¿ç”¨æ–‡æœ¬åŒ¹é…é™çº§æ–¹æ¡ˆ
    #         return await self._text_based_search(clinical_context, top_k)
    #
    #     try:
    #         query_embedding = await self._get_embedding(embedding_model, query_text)
    #     except Exception as e:
    #         print(f"å‘é‡åŒ–å¤±è´¥ï¼Œé™çº§åˆ°æ–‡æœ¬æ£€ç´¢: {e}")
    #         return await self._text_based_search(clinical_context, top_k)
    #
    #     # æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
    #     # ä½¿ç”¨pgvectorçš„ä½™å¼¦è·ç¦»å‡½æ•°ï¼Œéœ€è¦å°†Python listè½¬æ¢ä¸ºvectorç±»å‹
    #
    #     query_vector_str = "[" + ",".join(map(str, query_embedding)) + "]"
    #
    #     statement = (
    #         select(
    #             ClinicalScenario,
    #             func.cosine_distance(  # æˆ–è€…ä½¿ç”¨ cosine_distance, inner_product
    #                 ClinicalScenario.embedding,  # å‡è®¾å­—æ®µå·²å®šä¹‰ä¸ºvectorç±»å‹
    #                 text(f"'{query_vector_str}'")
    #             ).label('distance')
    #         )
    #         .where(ClinicalScenario.is_active == True)
    #         .order_by(text('distance'))
    #         .limit(top_k)
    #     )
    #
    #     result = await self.session.exec(statement)
    #     rows = result.all()
    #
    #     # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ŒåŒ…å«ç›¸ä¼¼åº¦åˆ†æ•°
    #     candidates = []
    #     for scenario, distance in rows:
    #         # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šç›¸ä¼¼ï¼‰
    #         similarity_score = 1 - distance
    #         candidates.append({
    #             'scenario': scenario,
    #             'vector_similarity': max(0, similarity_score),
    #             'scenario_id': scenario.semantic_id
    #         })
    #
    #     return candidates
    
    def _apply_structured_filter(
        self,
        candidates: List[Dict[str, Any]],
        patient_info: PatientInfo,
        clinical_context: ClinicalContext
    ) -> List[Dict[str, Any]]:
        """
        åº”ç”¨ç»“æ„åŒ–ç­›é€‰ï¼ˆåœ¨å‘é‡æ£€ç´¢ç»“æœä¸Šè¿›è¡Œè¿‡æ»¤ï¼‰
        
        åŸºäºæ‚£è€…çš„ç¡¬æ€§æ¡ä»¶ï¼ˆå¹´é¾„ã€æ€§åˆ«ã€å¦Šå¨ çŠ¶æ€ã€ç´§æ€¥ç¨‹åº¦ï¼‰è¿›è¡Œç­›é€‰
        """
        filtered = []
        
        for candidate in candidates:
            scenario = candidate['scenario']
            should_include = True
            
            # å¹´é¾„è¿‡æ»¤
            if patient_info.age is not None and scenario.age_group:
                # ç®€å•åŒ¹é…é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚ä¼˜åŒ–
                if not self._match_age_group(patient_info.age, scenario.age_group):
                    should_include = False
            
            # æ€§åˆ«è¿‡æ»¤
            if patient_info.gender and scenario.gender:
                if scenario.gender not in [patient_info.gender, "ä¸é™", None]:
                    should_include = False
            
            # å¦Šå¨ çŠ¶æ€è¿‡æ»¤
            if patient_info.pregnancy_status and scenario.pregnancy_status:
                if scenario.pregnancy_status != patient_info.pregnancy_status:
                    should_include = False
            
            # ç´§æ€¥ç¨‹åº¦è¿‡æ»¤
            if clinical_context.urgency_level and scenario.urgency_level:
                if scenario.urgency_level != clinical_context.urgency_level:
                    should_include = False
            
            if should_include:
                filtered.append(candidate)
        
        return filtered
    
    def _match_age_group(self, age: int, age_group: str) -> bool:
        """
        åŒ¹é…å¹´é¾„ç»„
        
        çº¯CPUè®¡ç®—ï¼ˆæ­£åˆ™åŒ¹é…ï¼‰ï¼Œä¿æŒåŒæ­¥æ–¹æ³•
        
        ç¤ºä¾‹ï¼š
        - "40å²ä»¥ä¸Š" -> age >= 40
        - "18-65å²" -> 18 <= age <= 65
        - "å„¿ç«¥" -> age < 18
        """
        import re
        
        # åŒ¹é… "XXå²ä»¥ä¸Š"
        match = re.search(r'(\d+)å²ä»¥ä¸Š', age_group)
        if match:
            threshold = int(match.group(1))
            return age >= threshold
        
        # åŒ¹é… "XX-YYå²"
        match = re.search(r'(\d+)-(\d+)å²', age_group)
        if match:
            min_age = int(match.group(1))
            max_age = int(match.group(2))
            return min_age <= age <= max_age
        
        # åŒ¹é… "XXå²ä»¥ä¸‹"
        match = re.search(r'(\d+)å²ä»¥ä¸‹', age_group)
        if match:
            threshold = int(match.group(1))
            return age <= threshold
        
        # ç‰¹æ®Šæƒ…å†µ
        if "å„¿ç«¥" in age_group or "å°å„¿" in age_group:
            return age < 18
        if "è€å¹´" in age_group:
            return age >= 65
        if "æˆäºº" in age_group:
            return 18 <= age < 65
        
        # é»˜è®¤é€šè¿‡
        return True
    
    # async def _text_based_search(
    #     self,
    #     clinical_context: ClinicalContext,
    #     top_k: int = 30
    # ) -> List[Dict[str, Any]]:
    #     """
    #     åŸºäºæ–‡æœ¬çš„é™çº§æ£€ç´¢æ–¹æ¡ˆï¼ˆå½“å‘é‡æ£€ç´¢ä¸å¯ç”¨æ—¶ï¼‰
    #     """
    #     # æå–å…³é”®è¯
    #     keywords = self._extract_keywords(clinical_context)
    #
    #     # æ„å»ºæ–‡æœ¬åŒ¹é…æ¡ä»¶
    #     text_conditions = [ClinicalScenario.is_active == True]
    #
    #     for keyword in keywords:
    #         text_conditions.append(
    #             or_(
    #                 ClinicalScenario.description_zh.contains(keyword),
    #                 ClinicalScenario.clinical_context.contains(keyword),
    #                 ClinicalScenario.symptom_category.contains(keyword)
    #             )
    #         )
    #
    #     statement = (
    #         select(ClinicalScenario)
    #         .where(and_(*text_conditions))
    #         .limit(top_k)
    #     )
    #
    #     result = await self.session.exec(statement)
    #     scenarios = result.all()
    #
    #     # è¿”å›å€™é€‰åœºæ™¯ï¼ˆä½¿ç”¨é»˜è®¤ç›¸ä¼¼åº¦ï¼‰
    #     candidates = []
    #     for scenario in scenarios:
    #         candidates.append({
    #             'scenario': scenario,
    #             'vector_similarity': 0.5,  # é»˜è®¤ä¸­ç­‰ç›¸ä¼¼åº¦
    #             'scenario_id': scenario.semantic_id
    #         })
    #
    #     return candidates
    
    async def _calculate_keyword_scores(
        self,
        clinical_context: ClinicalContext,
        candidates: List[Dict[str, Any]]
    ) -> Dict[str, float]:
        """
        è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°
        
        æå–ä¸´åºŠä¸Šä¸‹æ–‡ä¸­çš„å…³é”®è¯ï¼Œè®¡ç®—æ¯ä¸ªå€™é€‰åœºæ™¯çš„å…³é”®è¯åŒ¹é…åº¦
        """
        # æå–æŸ¥è¯¢å…³é”®è¯
        query_keywords = self._extract_keywords(clinical_context)
        
        keyword_scores = {}
        
        for candidate in candidates:
            scenario = candidate['scenario']
            scenario_id = candidate['scenario_id']
            
            # æå–åœºæ™¯ä¸­çš„æ–‡æœ¬å†…å®¹
            scenario_text = " ".join([
                scenario.description_zh or "",
                scenario.clinical_context or "",
                scenario.symptom_category or "",
                scenario.patient_population or ""
            ])
            
            # è®¡ç®—å…³é”®è¯é‡å åº¦
            matched_keywords = sum(
                1 for keyword in query_keywords 
                if keyword in scenario_text
            )
            
            # å½’ä¸€åŒ–åˆ†æ•°ï¼ˆ0-1ï¼‰
            if query_keywords:
                keyword_scores[scenario_id] = matched_keywords / len(query_keywords)
            else:
                keyword_scores[scenario_id] = 0.0
        
        return keyword_scores
    
    async def _apply_contraindication_filter(
        self,
        candidates: List[Dict[str, Any]],
        patient_info: PatientInfo
    ) -> List[Dict[str, Any]]:
        """
        åº”ç”¨ç¦å¿Œç—‡å’Œç‰¹æ®Šè€ƒè™‘è¿‡æ»¤
        
        æ ¹æ®æ‚£è€…çš„è¿‡æ•å²ã€åˆå¹¶ç—‡ç­‰ä¿¡æ¯ï¼Œè¿‡æ»¤æ‰æœ‰ç¦å¿Œç—‡çš„åœºæ™¯
        """
        filtered = []
        
        for candidate in candidates:
            scenario = candidate['scenario']
            
            # æ£€æŸ¥ç¦å¿Œç—‡ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´ï¼‰
            # ç¤ºä¾‹ï¼šå¦‚æœæ‚£è€…æœ‰æŸç§è¿‡æ•ï¼Œæ’é™¤ç›¸å…³åœºæ™¯
            has_contraindication = False
            
            # å¦‚æœæ‚£è€…æ˜¯å­•å¦‡ï¼Œæ£€æŸ¥å¦Šå¨ å®‰å…¨æ€§
            if patient_info.pregnancy_status in ['pregnant', 'lactating']:
                if scenario.pregnancy_status and 'ç¦å¿Œ' in scenario.pregnancy_status:
                    has_contraindication = True
            
            # æ£€æŸ¥æ‚£è€…è¿‡æ•å²
            if patient_info.allergies:
                # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´å¤æ‚çš„ç¦å¿Œç—‡é€»è¾‘
                pass
            
            if not has_contraindication:
                filtered.append(candidate)
        
        return filtered
    
    # async def _hybrid_scoring(
    #     self,
    #     candidates: List[Dict[str, Any]],
    #     keyword_scores: Dict[str, float],
    #     search_strategy: SearchStrategy
    # ) -> List[Dict[str, Any]]:
    #     """
    #     æ··åˆæ‰“åˆ†ï¼šç»“åˆå‘é‡ç›¸ä¼¼åº¦ã€å…³é”®è¯åŒ¹é…ã€è§„åˆ™åŒ¹é…
    #
    #     åŠ æƒå…¬å¼ï¼š
    #     final_score = vector_weight * vector_sim + keyword_weight * keyword_score + rule_weight * rule_score
    #     """
    #     scored = []
    #
    #     for candidate in candidates:
    #         scenario_id = candidate['scenario_id']
    #         vector_sim = candidate.get('vector_similarity', 0)
    #         keyword_score = keyword_scores.get(scenario_id, 0)
    #
    #         # è§„åˆ™åˆ†æ•°ï¼ˆå¯ä»¥åŸºäºåœºæ™¯çš„å…¶ä»–å±æ€§è®¡ç®—ï¼‰
    #         rule_score = self._calculate_rule_score(candidate['scenario'])
    #
    #         # åŠ æƒèåˆ
    #         final_score = (
    #             search_strategy.vector_weight * vector_sim +
    #             search_strategy.keyword_weight * keyword_score +
    #             search_strategy.rule_weight * rule_score
    #         )
    #
    #         candidate['keyword_score'] = keyword_score
    #         candidate['rule_score'] = rule_score
    #         candidate['final_score'] = final_score
    #
    #         scored.append(candidate)
    #
    #     # æŒ‰æœ€ç»ˆåˆ†æ•°é™åºæ’åº
    #     scored.sort(key=lambda x: x['final_score'], reverse=True)
    #
    #     return scored
    
    def _calculate_rule_score(self, scenario: ClinicalScenario) -> float:
        """
        è®¡ç®—è§„åˆ™åŒ¹é…åˆ†æ•°
        
        çº¯CPUè®¡ç®—ï¼ˆç®€å•ç®—æœ¯ï¼‰ï¼Œä¿æŒåŒæ­¥æ–¹æ³•
        åŸºäºåœºæ™¯çš„å…¶ä»–å±æ€§ï¼ˆå¦‚é£é™©ç­‰çº§ã€ç—‡çŠ¶åˆ†ç±»ç­‰ï¼‰è®¡ç®—åˆ†æ•°
        """
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # æ ¹æ®é£é™©ç­‰çº§è°ƒæ•´
        if scenario.risk_level:
            if scenario.risk_level == "ä½é£é™©":
                score += 0.2
            elif scenario.risk_level == "ä¸­é£é™©":
                score += 0.1
        
        # å¦‚æœæœ‰ä¸´åºŠä¸Šä¸‹æ–‡ï¼Œç•¥å¾®æå‡åˆ†æ•°
        if scenario.clinical_context:
            score += 0.1
        
        return min(score, 1.0)  # é™åˆ¶åœ¨0-1èŒƒå›´
    
    async def _rerank_scenarios(
        self,
        clinical_context: ClinicalContext,
        scenarios: List[Dict[str, Any]],
        reranker_model: Any
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨é‡æ’åºæ¨¡å‹å¯¹å€™é€‰åœºæ™¯é‡æ–°æ’åº
        """
        if not reranker_model or not scenarios:
            return scenarios
        
        # æ„å»ºæŸ¥è¯¢æ–‡æœ¬
        query_text = f"{clinical_context.chief_complaint} {clinical_context.diagnosis or ''}"
        
        # å‡†å¤‡æ–‡æ¡£åˆ—è¡¨
        documents = [
            s['scenario'].description_zh for s in scenarios
        ]
        
        try:
            # è°ƒç”¨é‡æ’åºæ¨¡å‹
            rerank_scores = await self._get_rerank_scores(reranker_model,query_text, documents)
            
            # æ›´æ–°åˆ†æ•°
            for i, scenario in enumerate(scenarios):
                if i < len(rerank_scores):
                    scenario['rerank_score'] = rerank_scores[i]
                    # æ··åˆåŸå§‹åˆ†æ•°å’Œé‡æ’åºåˆ†æ•°
                    scenario['final_score'] = (
                        0.7 * scenario['final_score'] + 
                        0.3 * rerank_scores[i]
                    )
            
            # é‡æ–°æ’åº
            scenarios.sort(key=lambda x: x['final_score'], reverse=True)
        except Exception as e:
            print(f"é‡æ’åºå¤±è´¥: {e}")
        
        return scenarios
    
    async def _get_embedding(self,embedding_model:EmbeddingClientSDK, text: str) -> List[float]:
        """è°ƒç”¨åµŒå…¥æ¨¡å‹ç”Ÿæˆå‘é‡"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„åµŒå…¥æ¨¡å‹æ¥å£å®ç°
        # ç¤ºä¾‹å®ç°ï¼š
        if hasattr(embedding_model, 'aembed_query'):
            result = await embedding_model.aembed_query(text)
            return result

        elif hasattr(embedding_model,"aembedding"):
            return await embedding_model.aembedding(text)
        else:
            raise NotImplementedError("åµŒå…¥æ¨¡å‹æ¥å£æœªå®ç°")
    
    async def _get_rerank_scores(self, reranker_model: Any,query: str, documents: List[str]) -> List[float]:
        """è°ƒç”¨é‡æ’åºæ¨¡å‹è®¡ç®—åˆ†æ•°"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„é‡æ’åºæ¨¡å‹æ¥å£å®ç°
        if hasattr(reranker_model, 'rerank'):
            result = await reranker_model.rerank(query, documents)
            return result
        elif hasattr(reranker_model, '__call__'):
            result = await reranker_model(query, documents)
            return result
        else:
            raise NotImplementedError("é‡æ’åºæ¨¡å‹æ¥å£æœªå®ç°")
    
    async def _extract_keywords(self, clinical_context: ClinicalContext, medical_dict: list = None) -> List[str]:
        """
        ä»ä¸´åºŠä¸Šä¸‹æ–‡ä¸­æå–å…³é”®è¯
        
        ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯ï¼Œæå–åŒ»å­¦å…³é”®è¯
        æ³¨æ„ï¼šæ­¤æ–¹æ³•é€šè¿‡çº¿ç¨‹æ± æ‰§è¡ŒCPUå¯†é›†å‹çš„jiebaåˆ†è¯ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        """
        if medical_dict is None:
            medical_dict = {}
        
        # æ”¶é›†éœ€è¦åˆ†è¯çš„æ–‡æœ¬
        texts_to_tokenize = []
        if clinical_context.chief_complaint:
            texts_to_tokenize.append(clinical_context.chief_complaint)
        if clinical_context.diagnosis:
            texts_to_tokenize.append(clinical_context.diagnosis)
        if clinical_context.present_illness:
            texts_to_tokenize.append(clinical_context.present_illness[:200])
        if clinical_context.medical_history:
            texts_to_tokenize.append(clinical_context.medical_history[:200])
        
        # åœ¨çº¿ç¨‹æ± ä¸­å¹¶å‘æ‰§è¡Œæ‰€æœ‰åˆ†è¯ä»»åŠ¡ï¼ˆCPUå¯†é›†å‹ï¼‰
        tasks = [
            asyncio.get_event_loop().run_in_executor(
                None,
                self._jieba_tokenize,
                text,
                medical_dict,
                None
            )
            for text in texts_to_tokenize
        ]
        
        # ç­‰å¾…æ‰€æœ‰åˆ†è¯ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks) if tasks else []
        
        # åˆå¹¶æ‰€æœ‰å…³é”®è¯
        keywords = []
        for result in results:
            keywords.extend(result)
        
        # å»é‡å¹¶è¿‡æ»¤
        keywords = list(set(keywords))
        
        # æŒ‰å…³é”®è¯é•¿åº¦æ’åºï¼Œä¼˜å…ˆä¿ç•™é•¿è¯ï¼ˆåŒ»å­¦æœ¯è¯­é€šå¸¸è¾ƒé•¿ï¼‰
        keywords.sort(key=len, reverse=True)
        
        # é™åˆ¶å…³é”®è¯æ•°é‡ï¼Œé¿å…è¿‡å¤šå™ªéŸ³
        return keywords[:50]
    
    def _jieba_tokenize(self, text: str,medical_dict:list,new_item:list=None) -> List[str]:
        """
        ä½¿ç”¨jiebaè¿›è¡Œä¸­æ–‡åˆ†è¯å’Œå…³é”®è¯æå–
        
        ç‰¹æ€§ï¼š
        - è‡ªåŠ¨åŠ è½½å¤–éƒ¨åŒ»å­¦è¯å…¸ï¼ˆdictç›®å½•ä¸‹çš„æ–‡ä»¶ï¼‰
        - å†…ç½®200+åŒ»å­¦æœ¯è¯­ä½œä¸ºè¡¥å……
        - TextRank + TF-IDFåŒç®—æ³•æå–å…³é”®è¯
        - æ™ºèƒ½åœç”¨è¯è¿‡æ»¤
        - ä¼˜å…ˆçº§æ’åºï¼ˆåŒ»å­¦æœ¯è¯­>é•¿è¯>çŸ­è¯ï¼‰
        """
        # project_root = Path(__file__).parent.parent.parent.parent
        # dict_dir = project_root / "dict"

        import jieba
        import jieba.analyse
        # jieba.analyse.set_stop_words(dict_dir / "stops.txt")
        # å†…ç½®åŒ»å­¦æœ¯è¯­ä½œä¸ºè¡¥å……ï¼ˆä»¥é˜²å¤–éƒ¨è¯å…¸åŠ è½½å¤±è´¥ï¼‰
        # è¿™äº›æœ¯è¯­ä¼šä¸å¤–éƒ¨è¯å…¸åˆå¹¶ä½¿ç”¨
        builtin_medical_terms = [
            'å† å¿ƒç—…', 'æ€¥æ€§å† è„‰ç»¼åˆå¾', 'å¿ƒè‚Œæ¢—æ­»', 'å¿ƒç»ç—›', 'é«˜è¡€å‹',
            'ç³–å°¿ç—…', 'è„‘å’ä¸­', 'è‚ºæ “å¡', 'ä¸»åŠ¨è„‰å¤¹å±‚', 'å¿ƒåŠ›è¡°ç«­',
            'è‚ºç‚', 'æ”¯æ°”ç®¡ç‚', 'å“®å–˜', 'æ…¢é˜»è‚º', 'è‚ºç»“æ ¸',
            'é˜‘å°¾ç‚', 'èƒ†å›Šç‚', 'èƒ°è…ºç‚', 'è‚ æ¢—é˜»', 'æ¶ˆåŒ–é“å‡ºè¡€',
            'è‚¾ç»“çŸ³', 'å°¿è·¯æ„ŸæŸ“', 'è‚¾åŠŸèƒ½ä¸å…¨', 'è‚¾ç‚',
            'éª¨æŠ˜', 'è„±ä½', 'éŸ§å¸¦æŸä¼¤', 'è½¯ç»„ç»‡æŒ«ä¼¤',
            'ç”²çŠ¶è…ºåŠŸèƒ½äº¢è¿›', 'ç”²çŠ¶è…ºåŠŸèƒ½å‡é€€', 'ç”²çŠ¶è…ºç»“èŠ‚',
            'å¦Šå¨ é«˜è¡€å‹', 'å¦Šå¨ ç³–å°¿ç—…', 'å®«å¤–å­•', 'å…ˆå…†æµäº§',
            'å‹æ¦¨æ€§ç–¼ç—›', 'å‘¼å¸å›°éš¾', 'å’³å—½å’³ç—°', 'èƒ¸é—·æ°”çŸ­',
            'è…¹ç—›è…¹æ³»', 'æ¶å¿ƒå‘•å', 'å¤´ç—›å¤´æ™•', 'å‘çƒ­ç•å¯’',
            'CT', 'MRI', 'è¶…å£°', 'Xçº¿', 'å¿ƒç”µå›¾', 'å† çŠ¶åŠ¨è„‰é€ å½±',
            "éå¦Šå¨ ", "éå¦Šå¨ æœŸ", "éå¦Šå¨ çŠ¶æ€"
        ]
        if new_item:
           builtin_medical_terms.extend(new_item)
        
        # è¡¥å……æ·»åŠ å†…ç½®è¯æ±‡ï¼ˆå¤–éƒ¨è¯å…¸å·²åœ¨åˆå§‹åŒ–æ—¶åŠ è½½ï¼‰
        for term in set(builtin_medical_terms):
            jieba.add_word(term, freq=10000, tag='medical')
        
        # æ–¹æ³•1: ä½¿ç”¨TextRankç®—æ³•æå–å…³é”®è¯ï¼ˆæ¨èï¼‰
        keywords_textrank = jieba.analyse.textrank(
            text,
            topK=20,  # æå–å‰20ä¸ªå…³é”®è¯
            withWeight=False,
            allowPOS=('n', 'nr', 'nt', 'nz', 'v', 'a',
                      "f","ns","ad","q",'u','s','vd','r','xc','t',
                      'vn'

                      ),
            # åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯
        )
        
        # æ–¹æ³•2: ä½¿ç”¨TF-IDFç®—æ³•æå–å…³é”®è¯ï¼ˆä½œä¸ºè¡¥å……ï¼‰
        keywords_tfidf = jieba.analyse.extract_tags(
            text,
            topK=15,
            withWeight=False
        )

        all_words=set(builtin_medical_terms)
        for suggest in all_words:
             jieba.suggest_freq(suggest,True)
        # æ–¹æ³•3: åŸºç¡€åˆ†è¯ï¼ˆä¿ç•™æ‰€æœ‰åŒ»å­¦ç›¸å…³è¯ï¼‰
        words = jieba.lcut(text, cut_all=False)
        
        # åœç”¨è¯åˆ—è¡¨ï¼ˆæ‰©å±•ç‰ˆï¼‰
        stop_words = {
            # é€šç”¨åœç”¨è¯
            'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª',
            'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½',
            'è‡ªå·±', 'è¿™', 'é‚£', 'é‡Œ', 'å•Š', 'å—', 'å‘¢', 'å§', 'å“¦', 'å—¯', 'å“ˆ',
            # ä¸´åºŠå¸¸è§è™šè¯
            'æ‚£è€…', 'ç—…äºº', 'ç—…å²', 'å¹´', 'å²', 'æ¬¡', 'å¤©', 'å°æ—¶', 'åˆ†é’Ÿ',
            'ä¸»è¯‰', 'ç°ç—…å²', 'æ—¢å¾€å²', 'è¯Šæ–­', 'ç—‡çŠ¶', 'è¡¨ç°'
        }
        
        # è¿‡æ»¤åœç”¨è¯å’Œå•å­—
        words_filtered = [
            w for w in words
            if w not in stop_words and len(w) >= 2  # ä¿ç•™é•¿åº¦>=2çš„è¯
        ]

        
        # åˆå¹¶ä¸‰ç§æ–¹æ³•çš„ç»“æœ
        all_keywords = list(set(keywords_textrank + keywords_tfidf + words_filtered))
        
        # è·å–æ‰€æœ‰å·²åŠ è½½çš„åŒ»å­¦æœ¯è¯­ï¼ˆå¤–éƒ¨è¯å…¸ + å†…ç½®è¯å…¸ï¼‰
        all_medical_terms = set(builtin_medical_terms)
        try:
            all_medical_terms.update(medical_dict)
        except:
            pass  # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨å†…ç½®è¯å…¸å³å¯
        
        # ä¼˜å…ˆçº§æ’åºï¼šåŒ»å­¦æœ¯è¯­ > é•¿è¯ > å…¶ä»–
        medical_keywords = [w for w in all_keywords if w in all_medical_terms]
        long_keywords = [w for w in all_keywords if len(w) >= 3 and w not in medical_keywords]
        other_keywords = [w for w in all_keywords if len(w) == 2 and w not in medical_keywords]
        
        return medical_keywords + long_keywords + other_keywords
    
    async def _get_cached_keywords(self, text: str) -> Optional[Dict[str, List[str]]]:
        """å°è¯•ä»Redisç¼“å­˜è¯»å–å…³é”®è¯ï¼Œé¿å…é‡å¤è§¦å‘LLMè°ƒç”¨"""
        if not text or not self.redis_client:
            return None
        cache_key = f"medical_keywords:{hashlib.md5(text.encode('utf-8')).hexdigest()}"
        try:
            cached_value = await self.redis_client.get(cache_key)
        except Exception as exc:
            logger.warning(f"è·å–å…³é”®è¯ç¼“å­˜å¤±è´¥: {exc}")
            return None
        if not cached_value:
            return None
        if isinstance(cached_value, bytes):
            try:
                cached_value = cached_value.decode('utf-8')
            except Exception as exc:
                logger.warning(f"å…³é”®è¯ç¼“å­˜è§£ç å¤±è´¥: {exc}")
                return None
        try:
            cached_data = json.loads(cached_value)
        except json.JSONDecodeError as exc:
            logger.warning(f"å…³é”®è¯ç¼“å­˜JSONè§£æå¤±è´¥: {exc}")
            return None
        return {
            'keywords': cached_data.get('keywords') or [],
            'new_terms': cached_data.get('new_terms') or []
        }

    async def _cache_keywords(
        self,
        text: str,
        keywords: List[str],
        new_terms: List[str],
        ttl: int = 12 * 60 * 60,
    ) -> None:
        """å°†å…³é”®è¯ç»“æœå†™å…¥Redisç¼“å­˜"""
        if not keywords or not self.redis_client:
            return
        cache_key = f"medical_keywords:{hashlib.md5(text.encode('utf-8')).hexdigest()}"
        payload = json.dumps({'keywords': keywords, 'new_terms': new_terms}, ensure_ascii=False)
        try:
            await self.redis_client.set(cache_key, payload, ex=ttl)
        except Exception as exc:
            logger.warning(f"å†™å…¥å…³é”®è¯ç¼“å­˜å¤±è´¥: {exc}")

    async def _hybrid_tokenize_with_llm_verification(
        self,
        text: str,
        medical_dict: list
    ) -> tuple[List[str], List[str]]:
        """Run jieba and LLM keyword extraction in parallel and update the dictionary dynamically."""
        import jieba

        cached_keywords = await self._get_cached_keywords(text)
        if cached_keywords and cached_keywords["keywords"]:
            cached_new_terms = cached_keywords.get("new_terms") or []
            if cached_new_terms:
                for term in cached_new_terms:
                    if len(term) >= 2:
                        jieba.add_word(term, freq=10000, tag="medical_dynamic")
                logger.info("keywords cache hit; restored %s new terms", len(cached_new_terms))
            logger.info("reusing %s cached keywords", len(cached_keywords["keywords"]))
            return cached_keywords["keywords"], cached_new_terms

        logger.info("starting parallel jieba + LLM keyword extraction")
        jieba_task = asyncio.get_event_loop().run_in_executor(
            None,
            self._jieba_tokenize,
            text,
            medical_dict,
            None
        )
        llm_task = self.ai_service.extract_medical_keywords_by_llm(text, top_k=20)
        try:
            jieba_keywords, llm_keywords = await asyncio.gather(
                jieba_task,
                llm_task,
                return_exceptions=True
            )
            if isinstance(jieba_keywords, Exception):
                logger.error("jieba keyword extraction failed: %s", jieba_keywords)
                jieba_keywords = []
            if isinstance(llm_keywords, Exception):
                logger.error("LLM keyword extraction failed: %s", llm_keywords)
                llm_keywords = []

            jieba_set = set(jieba_keywords)
            llm_set = set(llm_keywords)
            new_terms = list(llm_set - jieba_set)

            if new_terms:
                logger.info("LLM discovered %s new medical terms", len(new_terms))
                for term in new_terms:
                    if len(term) >= 2:
                        jieba.add_word(term, freq=10000, tag="medical_dynamic")
                        logger.debug("added dynamic term: %s", term)
            else:
                logger.info("jieba and LLM keywords are identical; dictionary unchanged")

            merged_keywords = list(jieba_set | llm_set)
            merged_keywords.sort(key=len, reverse=True)

            logger.info(
                "merged keywords=%s (jieba=%s, llm=%s, new=%s)",
                len(merged_keywords),
                len(jieba_keywords),
                len(llm_keywords),
                len(new_terms)
            )

            await self._cache_keywords(text, merged_keywords, new_terms)
            return merged_keywords, new_terms

        except Exception as exc:
            logger.error("hybrid tokenization failed: %s", exc)
            fallback_keywords = self._jieba_tokenize(text, medical_dict, None)
            await self._cache_keywords(text, fallback_keywords, [])
            return fallback_keywords, []
    async def _async_persist_new_terms(self, new_terms: List[str]):
        """
        å¼‚æ­¥æŒä¹…åŒ–æ–°å‘ç°çš„åŒ»å­¦æœ¯è¯­åˆ°è¯å…¸æ–‡ä»¶
        
        ä½¿ç”¨Celeryå¼‚æ­¥ä»»åŠ¡åœ¨åå°æ‰§è¡Œï¼Œå®Œå…¨ä¸é˜»å¡ä¸»æµç¨‹
        
        Args:
            new_terms: æ–°å‘ç°çš„åŒ»å­¦æœ¯è¯­åˆ—è¡¨
        """
        try:
            # è§¦å‘Celeryå¼‚æ­¥ä»»åŠ¡
            task = batch_persist_by_category_async.delay(new_terms)
            logger.info(f"âœ… å·²è§¦å‘Celeryä»»åŠ¡ï¼šID={task.id}, å¾…æŒä¹…åŒ– {len(new_terms)} ä¸ªæ–°æœ¯è¯­")
        except Exception as e:
            logger.error(f"âŒ Celeryä»»åŠ¡è§¦å‘å¤±è´¥ï¼Œé™çº§ä¸ºçº¿ç¨‹æ± æ‰§è¡Œ: {e}")
            # é™çº§æ–¹æ¡ˆï¼šå¦‚æœCeleryä¸å¯ç”¨ï¼Œä½¿ç”¨çº¿ç¨‹æ± 
            await asyncio.get_event_loop().run_in_executor(
                None,
                batch_persist_by_category,
                new_terms
            )
    
    def _simple_tokenize(self, text: str) -> List[str]:
        """
        ç®€å•åˆ†è¯ï¼ˆé™çº§æ–¹æ¡ˆï¼Œå½“jiebaä¸å¯ç”¨æ—¶ï¼‰
        
        çº¯CPUè®¡ç®—ï¼Œä¿æŒåŒæ­¥æ–¹æ³•
        å·²åºŸå¼ƒï¼Œä¿ç•™ä½œä¸ºåå¤‡æ–¹æ¡ˆ
        """
        import re
        # æå–ä¸­æ–‡è¯æ±‡ï¼ˆ2-4ä¸ªå­—ï¼‰
        words = re.findall(r'[\u4e00-\u9fa5]{2,4}', text)
        
        # åœç”¨è¯è¿‡æ»¤ï¼ˆç®€åŒ–ç‰ˆï¼‰
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
        words = [w for w in words if w not in stop_words]
        
        return words

    async def get_scenario_recommendations(
            self,
            scenario_id: str,
            top_k: int = 10,
            min_rating: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šä¸´åºŠåœºæ™¯çš„æ¨èé¡¹ç›®

        Args:
            scenario_id: ä¸´åºŠåœºæ™¯ID
            top_k: è¿”å›çš„æ¨èæ•°é‡
            min_rating: æœ€ä½é€‚å®œæ€§è¯„åˆ†

        Returns:
            æ¨èé¡¹ç›®åˆ—è¡¨ï¼ŒæŒ‰appropriateness_ratingé™åºæ’åº
        """
        session = await self._get_independent_session()
        try:
            # æ„å»ºæŸ¥è¯¢
            statement = (
                select(ClinicalRecommendation, ProcedureDictionary)
                .join(ProcedureDictionary, ClinicalRecommendation.procedure_id == ProcedureDictionary.semantic_id)
                .where(
                    and_(
                        ClinicalRecommendation.scenario_id == scenario_id,
                        ClinicalRecommendation.is_active == True,
                        ProcedureDictionary.is_active == True
                    )
                )
            )

            if min_rating is not None:
                statement = statement.where(ClinicalRecommendation.appropriateness_rating >= min_rating)

            statement = statement.order_by(ClinicalRecommendation.appropriateness_rating.desc())
            statement = statement.limit(top_k)

            result = await session.exec(statement)
            rows = result.all()

            recommendations_list = []
            for recommendation, procedure in rows:
                recommendations_list.append({
                    "recommendation": recommendation,
                    "procedure": procedure
                })

            return recommendations_list

        except Exception as e:
            logger.error(f"è·å–åœºæ™¯ {scenario_id} æ¨èé¡¹ç›®å¤±è´¥: {e}")
            # å¯ä»¥é€‰æ‹©è¿”å›ç©ºåˆ—è¡¨æˆ–é‡æ–°æŠ›å‡ºå¼‚å¸¸
            return []
        finally:
            await session.close()

    async def _vector_mmr_search(
            self,
            standardized_query: str,
            clinical_context: ClinicalContext,
            top_p: int = 50,
            top_k: int = 10,
            similarity_threshold: float = 0.6
    ) -> List[Dict[str, Any]]:
        """
        åŸºäºLangChainçš„æœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼ˆMMRï¼‰æ£€ç´¢

        MMRç®—æ³•èƒ½å¤Ÿåœ¨ä¿è¯ç›¸å…³æ€§çš„åŒæ—¶ï¼Œå¢åŠ ç»“æœçš„å¤šæ ·æ€§

        Args:
            standardized_query: æ ‡å‡†åŒ–åçš„æŸ¥è¯¢æ–‡æœ¬
            top_p: åˆå§‹è·å–æ•°é‡ï¼ˆfetch_kï¼‰
            top_k: æœ€ç»ˆè¿”å›æ•°é‡
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            å€™é€‰åœºæ™¯åˆ—è¡¨ï¼ŒåŒ…å«mmr_scoreå­—æ®µ
        """
        try:
            # å°è¯•ä»ç¼“å­˜è·å– embedding å‘é‡
            query_embedding = await self.vector_service.embeddings_service.cache_backed_embeddings.aembed_query(
                text=standardized_query)
        except Exception as e:
            logger.error(f"å‘é‡åŒ–å¤±è´¥: {e}")
            return []

        try:
            # 1. è·å– vector store å’Œ client
            vector_store = await self.vector_service.milvus_vector_store()
            aclient = await self.vector_service.get_milvus_client()

            # 2. å¹¶å‘æ‰§è¡ŒMMRæœç´¢å’Œæ··åˆæœç´¢
            async def execute_mmr_search():
                """æ‰§è¡ŒMMRæœç´¢å¹¶è¿‡æ»¤ç»“æœ"""
                mmr_results = await vector_store.amax_marginal_relevance_search_by_vector(
                    query_embedding,
                    fetch_k=top_p,
                    k=top_k * 4
                )

                # æŒ‰ç§‘å®¤è¿‡æ»¤MMRç»“æœ
                new_documents = [document for document in mmr_results
                                 if str(document.metadata.get("panel_name", "")) == str(clinical_context.department)]

                # è¡¥å……æ–‡æ¡£é€»è¾‘
                if len(new_documents) < top_p:
                    logger.info(f"è¿‡æ»¤åæ–‡æ¡£æ•°é‡ {len(new_documents)} ä¸è¶³ {top_p}ï¼Œå¼€å§‹è¡¥å……æ–‡æ¡£")

                    other_documents = [document for document in mmr_results
                                       if
                                       str(document.metadata.get("panel_name", "")) != str(clinical_context.department)]

                    need_supplement_count = top_p - len(new_documents)
                    supplement_documents = other_documents[:need_supplement_count]
                    new_documents.extend(supplement_documents)
                    logger.info(f"è¡¥å……äº† {len(supplement_documents)} ä¸ªæ–‡æ¡£ï¼Œç°åœ¨å…±æœ‰ {len(new_documents)} ä¸ªæ–‡æ¡£")

                # å¦‚æœç»è¿‡è¿‡æ»¤å’Œè¡¥å……å new_documents ä»ç„¶ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨åŸå§‹ documents
                if not new_documents:
                    logger.warning("è¿‡æ»¤åæ— æ–‡æ¡£ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢ç»“æœ")
                    new_documents = mmr_results

                return new_documents

            async def execute_hybrid_search():
                """æ‰§è¡Œæ··åˆæœç´¢"""
                # æ„å»ºæ··åˆæœç´¢è¯·æ±‚
                search_param_1 = {
                    "data": [query_embedding],
                    "anns_field": "text_dense",
                    "param": {"nprobe": 10},
                    "limit": top_k * 2
                }
                request_1 = AnnSearchRequest(**search_param_1)

                search_param_2 = {
                    "data": [standardized_query],
                    "anns_field": "text_sparse",
                    "param": {"drop_ratio_search": 0.2},
                    "limit": top_k * 2
                }
                request_2 = AnnSearchRequest(**search_param_2)
                reqs = [request_1, request_2]

                ranker = Function(
                    name="rrf",
                    input_field_names=[],
                    function_type=FunctionType.RERANK,
                    params={
                        "reranker": "rrf",
                        "k": 100
                    }
                )

                hybrid_results = await aclient.hybrid_search(
                    collection_name="scenarios",
                    reqs=reqs,
                    ranker=ranker,
                    limit=top_k,
                    output_fields=["panel_name", "topic_name", "text", "id"]
                )

                return hybrid_results

            # å¹¶å‘æ‰§è¡Œä¸¤ä¸ªæœç´¢ä»»åŠ¡
            mmr_task = execute_mmr_search()
            hybrid_task = execute_hybrid_search()

            new_documents, hybrid_results = await asyncio.gather(mmr_task, hybrid_task)

            # 3. å¤„ç†æ··åˆæœç´¢ç»“æœ
            hybrid_hits = []
            not_existed_hybrid_hits = []

            if hybrid_results:
                for hits in hybrid_results:
                    for hit in hits:
                        if hasattr(hit, 'distance') and hit["panel_name"] == clinical_context.department:
                            hybrid_hits.append({
                                "id": int(hit.id),
                                "distance": hit.distance,
                                "entity": hit.entity
                            })
                        else:
                            not_existed_hybrid_hits.append({
                                "id": int(hit.id),
                                "distance": hit.distance,
                                "entity": hit.entity
                            })

            # è¡¥å……æ··åˆæœç´¢ç»“æœ
            need_supply = top_k - len(hybrid_hits)
            hybrid_hits.extend(not_existed_hybrid_hits[:need_supply])

            # 4. åˆå¹¶ç»“æœå¹¶å»é‡
            # ä»MMRç»“æœä¸­æå–ID
            mmr_ids = set()
            for doc in new_documents:
                try:
                    doc_id = int(doc.metadata.get("id"))  # ç¡®ä¿IDæ˜¯æ•´æ•°
                    mmr_ids.add(doc_id)
                except (ValueError, AttributeError) as e:
                    logger.warning(f"æ— æ•ˆçš„MMRæ–‡æ¡£ID: {doc.id}, é”™è¯¯: {e}")
                    continue

            # ä»æ··åˆæœç´¢ç»“æœä¸­æå–IDï¼ˆå·²ç»æŒ‰ç§‘å®¤è¿‡æ»¤ï¼‰
            hybrid_ids = {hit["id"] for hit in hybrid_hits}

            # åˆå¹¶æ‰€æœ‰å”¯ä¸€ID
            all_scenario_ids = mmr_ids.union(hybrid_ids)

            if not all_scenario_ids:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å€™é€‰åœºæ™¯")
                return []

            # 5. æ‰¹é‡æŸ¥è¯¢scenarioå¯¹è±¡
            session = await self._get_independent_session()
            try:
                statement = (
                    select(ClinicalScenario)
                    .options(
                        selectinload(ClinicalScenario.topic),
                        selectinload(ClinicalScenario.panel)
                    )
                    .where(ClinicalScenario.id.in_(list(all_scenario_ids))))
                result = await session.exec(statement)
                scenarios = result.all()
                logger.info(f"æ‰¹é‡æŸ¥è¯¢åˆ° {len(scenarios)} ä¸ªscenarioå¯¹è±¡")
            finally:
                await session.close()

            # 6. æ„å»ºå€™é€‰ç»“æœå¹¶è®¡ç®—åˆ†æ•°
            id_to_scenario = {scenario.id: scenario for scenario in scenarios}

            # åˆ›å»ºè·ç¦»åˆ°åˆ†æ•°çš„æ˜ å°„ï¼ˆæ··åˆæœç´¢ï¼‰
            hybrid_scores = {}
            for hit in hybrid_hits:
                # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
                similarity_score = max(0.0, 1.0 - hit["distance"])
                hybrid_scores[hit["id"]] = similarity_score

            candidates = []

            # å¤„ç†MMRç»“æœ
            for doc in new_documents:
                try:
                    doc_id = int(doc.metadata.get("id", 0))
                    scenario = id_to_scenario.get(doc_id)
                    if not scenario:
                        continue

                    # ä¼˜å…ˆä½¿ç”¨æ··åˆæœç´¢çš„åˆ†æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                    if doc_id in hybrid_scores:
                        mmr_score = hybrid_scores[doc_id]
                    else:
                        # å¯¹äºåªæœ‰MMRçš„ç»“æœï¼Œä½¿ç”¨è¾ƒé«˜çš„é»˜è®¤åˆ†æ•°
                        mmr_score = random.uniform(0.9, 0.95)

                    if mmr_score >= similarity_threshold:
                        candidates.append({
                            'scenario': scenario,
                            'scenario_id': scenario.id,
                            'score': mmr_score,
                            'document_content': doc.page_content,
                            'source': 'hybrid'
                        })
                except (ValueError, AttributeError) as e:
                    logger.warning(f"å¤„ç†MMRæ–‡æ¡£å¤±è´¥: {e}")
                    continue

            # 7. æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›top_k
            candidates.sort(key=lambda x: x['score'], reverse=True)
            final_candidates = candidates[:top_k]

            logger.info(f"æœ€ç»ˆè¿”å› {len(final_candidates)} ä¸ªå€™é€‰åœºæ™¯")
            return final_candidates

        except Exception as e:
            logger.error(f"å‘é‡æœç´¢å¤±è´¥: {e}")
            return []
    
    # ========== ç¼“å­˜ç›¸å…³æ–¹æ³• ==========
    
    async def _generate_cache_key(self, patient_info: PatientInfo, clinical_context: ClinicalContext) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŸºäºæ‚£è€…ä¿¡æ¯å’Œä¸´åºŠä¸Šä¸‹æ–‡ï¼‰
        
        ä½¿ç”¨ MD5 å“ˆå¸Œç¡®ä¿é”®çš„å”¤ä¸€æ€§å’Œç®€æ´æ€§
        
        Args:
            patient_info: æ‚£è€…ä¿¡æ¯
            clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡
            
        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        # æ„å»ºç”¨äºç”Ÿæˆé”®çš„æ•°æ®ç»“æ„
        cache_data = {
            'patient': {
                'age': patient_info.age,
                'gender': patient_info.gender,
                'pregnancy_status': patient_info.pregnancy_status,
                'allergies': sorted(patient_info.allergies) if patient_info.allergies else None,
                'comorbidities': sorted(patient_info.comorbidities) if patient_info.comorbidities else None,
                'physical_examination': patient_info.physical_examination,
            },
            'clinical': {
                'department': clinical_context.department,
                'chief_complaint': clinical_context.chief_complaint,
                'medical_history': clinical_context.medical_history,
                'present_illness': clinical_context.present_illness,
                'diagnosis': clinical_context.diagnosis,
                'symptom_duration': clinical_context.symptom_duration,
                'symptom_severity': clinical_context.symptom_severity,
            }
        }
        
        # å°†æ•°æ®åºåˆ—åŒ–ä¸ºJSONå­—ç¬¦ä¸²ï¼ˆæ’åºé”®ä»¥ç¡®ä¿ä¸€è‡´æ€§ï¼‰
        cache_str = json.dumps(cache_data, sort_keys=True, ensure_ascii=False)
        
        # ç”ŸæˆMD5å“ˆå¸Œ
        cache_hash = hashlib.md5(cache_str.encode('utf-8')).hexdigest()
        
        # æ·»åŠ å‰ç¼€ï¼Œæ–¹ä¾¿ç®¡ç†
        cache_key = f"query_standardization:{cache_hash}"
        
        return cache_key
    
    async def _get_cached_standardized_query(self, cache_key: str) -> Optional[str]:
        """
        ä»Redisè·å–ç¼“å­˜çš„æ ‡å‡†åŒ–æŸ¥è¯¢
        
        Args:
            cache_key: ç¼“å­˜é”®
            
        Returns:
            æ ‡å‡†åŒ–æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œå¦‚æœæœªå‘½ä¸­åˆ™è¿”å›None
        """
        try:
            cached_value = await self.redis_client.get(cache_key)
            if cached_value:
                # Redis è¿”å›çš„æ˜¯ bytesï¼Œéœ€è¦è§£ç 
                if isinstance(cached_value, bytes):
                    return cached_value.decode('utf-8')
                return cached_value
            return None
        except Exception as e:
            logger.error(f"ä»ç¼“å­˜è·å–æ ‡å‡†åŒ–æŸ¥è¯¢å¤±è´¥: {e}")
            return None
    
    async def _cache_standardized_query(self, cache_key: str, standardized_query: str, ttl: int = 86400):
        """
        å°†æ ‡å‡†åŒ–æŸ¥è¯¢å­˜å…¥Redisç¼“å­˜
        
        Args:
            cache_key: ç¼“å­˜é”®
            standardized_query: æ ‡å‡†åŒ–æŸ¥è¯¢å­—ç¬¦ä¸²
            ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤24å°æ—¶
        """
        try:
            await self.redis_client.set(cache_key, standardized_query, ex=ttl)
            logger.debug(f"æ ‡å‡†åŒ–æŸ¥è¯¢å·²ç¼“å­˜ï¼Œé”®: {cache_key}, TTL: {ttl}ç§’")
        except Exception as e:
            logger.error(f"å­˜å‚¨æ ‡å‡†åŒ–æŸ¥è¯¢åˆ°ç¼“å­˜å¤±è´¥: {e}")
    
    # ========== Embedding ç¼“å­˜ç›¸å…³æ–¹æ³• ==========
    
    async def _get_embedding_with_cache(
        self, 
        embedding_model: EmbeddingClientSDK|None,
        text: str
    ) -> List[float]:
        """
        è·å–æ–‡æœ¬çš„ embedding å‘é‡ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        å·¥ä½œæµç¨‹ï¼š
        1. ç”Ÿæˆç¼“å­˜é”®ï¼ˆåŸºäºæ–‡æœ¬å†…å®¹ï¼‰
        2. å°è¯•ä»Redisè·å–ç¼“å­˜çš„å‘é‡
        3. å¦‚æœç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨æ¨¡å‹ç”Ÿæˆå‘é‡
        4. å°†æ–°ç”Ÿæˆçš„å‘é‡å­˜å…¥ç¼“å­˜
        
        Args:
            embedding_model: åµŒå…¥æ¨¡å‹
            text: è¦å‘é‡åŒ–çš„æ–‡æœ¬
            
        Returns:
            embedding å‘é‡åˆ—è¡¨
        """
        # 1. ç”Ÿæˆç¼“å­˜é”®
        cache_key = await self._generate_embedding_cache_key(text)
        
        # 2. å°è¯•ä»ç¼“å­˜è·å–
        cached_embedding = await self._get_cached_embedding(cache_key)
        
        if cached_embedding is not None:
            logger.info(f"ä»ç¼“å­˜è·å– embedding å‘é‡ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
            return cached_embedding
        
        # 3. ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨æ¨¡å‹ç”Ÿæˆ
        logger.info(f"ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨æ¨¡å‹ç”Ÿæˆ embeddingï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
        embedding = await self._get_embedding(embedding_model, text)
        
        # 4. å°†æ–°ç”Ÿæˆçš„å‘é‡å­˜å…¥ç¼“å­˜
        await self._cache_embedding(cache_key, embedding)
        logger.info("å·²å°† embedding å‘é‡å­˜å…¥ç¼“å­˜")
        
        return embedding
    
    async def _generate_embedding_cache_key(self, text: str) -> str:
        """
        ç”Ÿæˆ embedding ç¼“å­˜é”®
        
        ä½¿ç”¨ MD5 å“ˆå¸Œæ–‡æœ¬å†…å®¹ç”Ÿæˆå”¯ä¸€é”®
        
        Args:
            text: è¦å‘é‡åŒ–çš„æ–‡æœ¬
            
        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        # å¯¹æ–‡æœ¬è¿›è¡Œ MD5 å“ˆå¸Œ
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
        
        # æ·»åŠ å‰ç¼€ï¼Œæ–¹ä¾¿ç®¡ç†
        cache_key = f"embedding:{text_hash}"
        
        return cache_key
    
    async def _get_cached_embedding(self, cache_key: str) -> Optional[List[float]]:
        """
        ä»Redisè·å–ç¼“å­˜çš„ embedding å‘é‡
        
        Args:
            cache_key: ç¼“å­˜é”®
            
        Returns:
            embedding å‘é‡åˆ—è¡¨ï¼Œå¦‚æœæœªå‘½ä¸­åˆ™è¿”å›None
        """
        try:
            cached_value = await self.redis_client.get(cache_key)
            if cached_value:
                # Redis è¿”å›çš„æ˜¯ bytesï¼Œéœ€è¦è§£ç å¹¶è§£æä¸ºåˆ—è¡¨
                if isinstance(cached_value, bytes):
                    cached_value = cached_value.decode('utf-8')
                
                # å°† JSON å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
                embedding = json.loads(cached_value)
                return embedding
            return None
        except Exception as e:
            logger.error(f"ä»ç¼“å­˜è·å– embedding å¤±è´¥: {e}")
            return None
    
    async def _cache_embedding(self, cache_key: str, embedding: List[float], ttl: int = 604800):
        """
        å°† embedding å‘é‡å­˜å…¥Redisç¼“å­˜
        
        Args:
            cache_key: ç¼“å­˜é”®
            embedding: embedding å‘é‡åˆ—è¡¨
            ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤7å¤©
        """
        try:
            # å°†åˆ—è¡¨è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
            embedding_json = json.dumps(embedding)
            
            await self.redis_client.set(cache_key, embedding_json, ex=ttl)
            logger.debug(f"embedding å‘é‡å·²ç¼“å­˜ï¼Œé”®: {cache_key}, ç»´åº¦: {len(embedding)}, TTL: {ttl}ç§’")
        except Exception as e:
            logger.error(f"å­˜å‚¨ embedding åˆ°ç¼“å­˜å¤±è´¥: {e}")
    
    # ========== LLMæ™ºèƒ½åœºæ™¯é€‰æ‹©ç›¸å…³æ–¹æ³• ==========
    
    async def llm_rank_scenarios(
        self,
        scenarios: List[Dict[str, Any]],
        patient_info: PatientInfo,
        clinical_context: ClinicalContext,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨LLMæ ¹æ®æ‚£è€…ä¿¡æ¯æ™ºèƒ½é€‰æ‹©æœ€åŒ¹é…çš„ä¸´åºŠåœºæ™¯
        
        Args:
            scenarios: å€™é€‰åœºæ™¯åˆ—è¡¨ï¼ˆæ¥è‡ªæ··åˆæ£€ç´¢ï¼‰
            patient_info: æ‚£è€…åŸºæœ¬ä¿¡æ¯
            clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡
            top_k: è¿”å›çš„åœºæ™¯æ•°é‡
            
        Returns:
            LLMé€‰æ‹©çš„åœºæ™¯åˆ—è¡¨ï¼ŒåŒ…å«llm_reasoningå’Œllm_rankå­—æ®µ
        """
        if not scenarios:
            logger.warning("è¾“å…¥åœºæ™¯ä¸ºç©ºï¼ŒLLMé€‰æ‹©è·³è¿‡")
            return []

        try:
            # 1. æ„å»ºåœºæ™¯åˆ—è¡¨æ–‡æœ¬


            # 2. æ„å»ºæ‚£è€…ä¿¡æ¯æ–‡æœ¬
            patient_text = f"""æ‚£è€…ä¿¡æ¯:
                            - å¹´é¾„: {patient_info.age}å²
                            - æ€§åˆ«: {patient_info.gender}
                            - å¦Šå¨ çŠ¶æ€: {patient_info.pregnancy_status or 'éå¦Šå¨ æœŸ'}
                            - è¿‡æ•å²: {', '.join(patient_info.allergies) if patient_info.allergies else 'æ— '}
                            - åˆå¹¶ç—‡: {', '.join(patient_info.comorbidities) if patient_info.comorbidities else 'æ— '}
                            - æ£€æŸ¥æŠ¥å‘Š: {patient_info.physical_examination or 'æ— '}
                            ä¸´åºŠä¿¡æ¯:
                            - ç§‘å®¤: {clinical_context.department}
                            - ä¸»è¯‰: {clinical_context.chief_complaint}
                            - æ—¢å¾€ç—…å²: {clinical_context.medical_history or 'æ— '}
                            - ç°ç—…å²: {clinical_context.present_illness or 'æ— '}
                            - ä¸»è¯Šæ–­ç»“æœ: {clinical_context.diagnosis or 'å¾…è¯Šæ–­'}
                            - ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦: {clinical_context.symptom_severity or 'æœªçŸ¥'}
                            - ç—‡çŠ¶æŒç»­æ—¶é—´: {clinical_context.symptom_duration or 'æœªçŸ¥'}
                           """
            patient_token=self.adaptive_recommendation_engine_service.estimate_tokens_with_tiktoken(patient_text)
            available_tokens = self.adaptive_recommendation_engine_service.strategy.threshold_config["token_threshold"]-400 - patient_token -300
            scenario_texts = []
            total_scenarios_token = 0
            included_scenarios = 0

            for idx, item in enumerate(scenarios, 1):
                scenario = item['scenario']
                scenario_text = f"""åœºæ™¯{idx}:
                                    - ID: {scenario.id}
                                    - ç§‘å®¤: {scenario.panel.name_zh if hasattr(scenario, 'panel') and scenario.panel else 'æœªçŸ¥'}
                                    - ä¸»é¢˜: {scenario.topic.name_zh if hasattr(scenario, 'topic') and scenario.topic else 'æœªçŸ¥'}
                                    - æè¿°: {scenario.description_zh}
                                    - é€‚ç”¨äººç¾¤: {scenario.patient_population or 'ä¸é™'}
                                    - å¹´é¾„ç»„: {scenario.age_group or 'ä¸é™'}
                                    - æ€§åˆ«: {scenario.gender or 'ä¸é™'}
                                    - å¦Šå¨ çŠ¶æ€: {scenario.pregnancy_status or 'ä¸é™'}
                                    - ç´§æ€¥ç¨‹åº¦: {scenario.urgency_level or 'ä¸é™'}
                                    - ç—‡çŠ¶åˆ†ç±»: {scenario.symptom_category or 'æœªçŸ¥'}
                                    """

                scenario_token = self.adaptive_recommendation_engine_service.estimate_tokens_with_tiktoken(
                    scenario_text)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰è¶³å¤Ÿçš„tokenç©ºé—´
                if total_scenarios_token + scenario_token <= available_tokens:
                    scenario_texts.append(scenario_text)
                    total_scenarios_token += scenario_token
                    included_scenarios += 1
                else:
                    logger.warning(
                        f"Tokené™åˆ¶ï¼ŒåªåŒ…å«å‰{included_scenarios}ä¸ªåœºæ™¯ï¼Œè·³è¿‡å{len(scenarios) - included_scenarios}ä¸ªåœºæ™¯")
                    break

            # 5. å¦‚æœtokenä»ç„¶è¶…é™ï¼Œå°è¯•ç®€åŒ–åœºæ™¯æè¿°
            if total_scenarios_token > available_tokens and scenario_texts:
                # ç®€åŒ–æœ€åä¸€ä¸ªåœºæ™¯çš„æè¿°
                last_scenario = scenarios[included_scenarios - 1]
                scenario = last_scenario['scenario']
                simplified_text = f"""åœºæ™¯{included_scenarios}:
                                    - ID: {scenario.id}
                                    - ç§‘å®¤: {scenario.panel.name_zh if hasattr(scenario, 'panel') and scenario.panel else 'æœªçŸ¥'}
                                    - ä¸»é¢˜: {scenario.topic.name_zh if hasattr(scenario, 'topic') and scenario.topic else 'æœªçŸ¥'}
                                    - æè¿°: {scenario.description_zh[:100]}...  # æˆªæ–­æè¿°
                                    """
                simplified_token = self.adaptive_recommendation_engine_service.estimate_tokens_with_tiktoken(
                    simplified_text)

                if total_scenarios_token - scenario_token + simplified_token <= available_tokens:
                    scenario_texts[-1] = simplified_text
                    total_scenarios_token = total_scenarios_token - scenario_token + simplified_token
                else:
                    # å¦‚æœç®€åŒ–åä»ç„¶è¶…é™ï¼Œç§»é™¤æœ€åä¸€ä¸ªåœºæ™¯
                    scenario_texts.pop()
                    included_scenarios -= 1
                    logger.warning(f"ç§»é™¤æœ€åä¸€ä¸ªåœºæ™¯ä»¥ç¬¦åˆtokené™åˆ¶ï¼Œæœ€ç»ˆåŒ…å«{included_scenarios}ä¸ªåœºæ™¯")

            # 3. æ„å»ºPrompt
            prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿï¼Œéœ€è¦æ ¹æ®æ‚£è€…æƒ…å†µä»ä»¥ä¸‹ä¸´åºŠåœºæ™¯ä¸­é€‰æ‹©æœ€åŒ¹é…çš„{top_k}ä¸ªåœºæ™¯ã€‚

                        {patient_text}
                        
                        å¯é€‰ä¸´åºŠåœºæ™¯:
                        {''.join(scenario_texts)}
                        
                        è¯·ç»¼åˆè€ƒè™‘ä»¥ä¸‹å› ç´ è¿›è¡Œé€‰æ‹©ï¼š
                        1. æ‚£è€…å¹´é¾„ã€æ€§åˆ«ã€å¦Šå¨ çŠ¶æ€æ˜¯å¦ç¬¦åˆåœºæ™¯è¦æ±‚
                        2. ä¸»è¯‰ä¸åœºæ™¯æè¿°çš„åŒ¹é…åº¦ï¼ˆè¯­ä¹‰ç›¸å…³æ€§ï¼‰
                        3. ç§‘å®¤æ˜¯å¦å¯¹åº”
                        4. ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦ä¸åœºæ™¯çš„ç´§æ€¥ç¨‹åº¦åŒ¹é…
                        5. æ˜¯å¦å­˜åœ¨ç¦å¿Œç—‡ï¼ˆå¦‚å­•å¦‡é¿å…è¾å°„æ£€æŸ¥ç›¸å…³åœºæ™¯ï¼‰
                        
                        è¯·ç›´æ¥è¾“å‡ºé€‰æ‹©çš„åœºæ™¯IDåˆ—è¡¨ï¼ˆæ•°å­—IDï¼Œä¸æ˜¯è¯­ä¹‰IDï¼‰ï¼Œæ ¼å¼ä¸ºJSONï¼Œè¿™æ˜¯ä¸€ä¸ªä¾‹å­ï¼š
                        {{"selected_scenario_ids": [1, 5, 8], "reasoning": "è¿™é‡Œå¡«å†™ä½ é€‰æ‹©çš„åŸå› "}}
                        
                        è¦æ±‚ï¼š
                        - è¾“å‡ºå¿…é¡»æ˜¯å®Œæ•´çš„ã€å¯è§£æçš„JSONæ ¼å¼
                        - æ ¹æ®å®é™…ç”¨æˆ·æƒ…å†µå’Œä¸´åºŠåœºæ™¯ä¸¥è°¨çš„é€‰æ‹©{top_k}ä¸ªåœºæ™¯ï¼ˆä¸ºäº†ä¸“ä¸šæ€§ï¼Œå¯ä»¥é€‰æ‹©çš„æ¯”top_kå°ï¼Œä½†ä¸èƒ½ä¸º0ä¸ªï¼‰
                        - æŒ‰åŒ¹é…åº¦ä»é«˜åˆ°ä½æ’åº
                        - ä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæ–‡å­—ï¼Œåªè¾“å‡ºJSONæ ¼å¼ç»“æœ
                        """

            # 4. è°ƒç”¨LLMï¼ˆä½¿ç”¨ai_serviceï¼‰
            response = await self.ai_service._call_llm(prompt)

            try:
                # ... æ„å»ºpromptå’Œè°ƒç”¨LLMçš„ä»£ç ä¿æŒä¸å˜ ...

                # 5. è§£æLLMè¿”å›çš„JSON - å¢å¼ºå¥å£®æ€§
                import re
                import json

                def robust_json_parse(response: str) -> Dict[str, Any]:
                    """å¢å¼ºçš„JSONè§£æï¼Œå¤„ç†ä¸å®Œæ•´çš„JSONå“åº”"""
                    # æ–¹æ³•1: å°è¯•ç›´æ¥è§£æ
                    try:
                        return json.loads(response.strip())
                    except json.JSONDecodeError:
                        pass

                    # æ–¹æ³•2: æå–JSONå¯¹è±¡éƒ¨åˆ†
                    json_match = re.search(r'\{.*\}', response, re.DOTALL)
                    if json_match:
                        try:
                            json_str = json_match.group()
                            return json.loads(json_str)
                        except json.JSONDecodeError:
                            pass

                    # æ–¹æ³•3: ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                    # ä¿®å¤æœªé—­åˆçš„å­—ç¬¦ä¸²
                    json_str = response.strip()
                    if '"reasoning": "' in json_str and not json_str.endswith('"}'):
                        # æŸ¥æ‰¾reasoningå­—æ®µçš„å¼€å§‹ä½ç½®
                        reasoning_start = json_str.find('"reasoning": "') + len('"reasoning": "')
                        # ä»reasoningå¼€å§‹åˆ°ç»“å°¾éƒ½æ˜¯reasoningçš„å†…å®¹
                        reasoning_content = json_str[reasoning_start:]
                        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦å¹¶é—­åˆå­—ç¬¦ä¸²
                        reasoning_content_escaped = reasoning_content.replace('"', '\\"')
                        fixed_json = json_str[:reasoning_start] + reasoning_content_escaped + '"}'
                        try:
                            return json.loads(fixed_json)
                        except json.JSONDecodeError:
                            pass

                    # æ–¹æ³•4: æœ€åå°è¯•ï¼Œæ„å»ºæœ€å°æœ‰æ•ˆJSON
                    try:
                        # æå–selected_scenario_ids
                        ids_match = re.search(r'"selected_scenario_ids":\s*\[([^\]]+)\]', response)
                        if ids_match:
                            ids_str = ids_match.group(1)
                            ids = [int(id_str.strip()) for id_str in ids_str.split(',')]
                            reasoning_match = re.search(r'"reasoning":\s*"([^"]*)', response)
                            reasoning = reasoning_match.group(1) if reasoning_match else "è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨ç†"
                            return {
                                "selected_scenario_ids": ids[:top_k],
                                "reasoning": reasoning
                            }
                    except:
                        pass

                    raise json.JSONDecodeError("æ— æ³•è§£æLLMå“åº”", response, 0)

                # ä½¿ç”¨å¢å¼ºçš„JSONè§£æ
                try:
                    result = robust_json_parse(response)
                    selected_ids = result.get('selected_scenario_ids', [])
                    reasoning = result.get('reasoning', 'LLMè¿”å›æ ¼å¼ä¸å®Œæ•´')

                    if not selected_ids:
                        logger.warning("LLMæœªè¿”å›é€‰æ‹©çš„åœºæ™¯ID")
                        return []

                    # 6. æ ¹æ®IDç­›é€‰åœºæ™¯
                    selected_scenarios = []
                    id_to_item = {item['scenario'].id: item for item in scenarios}

                    for rank, scenario_id in enumerate(selected_ids, 1):
                        if scenario_id in id_to_item:
                            item = id_to_item[scenario_id]
                            item['llm_reasoning'] = reasoning
                            item['llm_rank'] = rank
                            item['selection_source_by_llm'] = 'LLM'
                            selected_scenarios.append(item)
                        else:
                            logger.warning(f"LLMè¿”å›çš„åœºæ™¯ID {scenario_id} ä¸åœ¨å€™é€‰åˆ—è¡¨ä¸­")

                    logger.info(f"âœ… LLMé€‰æ‹©äº†{len(selected_scenarios)}ä¸ªåœºæ™¯: {selected_ids}")
                    logger.info(f"ğŸ“ LLMæ¨ç†: {reasoning}")

                    return selected_scenarios[:top_k]

                except Exception as parse_error:
                    logger.error(f"âŒ LLMå“åº”è§£æå¤±è´¥: {str(parse_error)}")
                    logger.error(f"åŸå§‹å“åº”: {response}")
                    return []

            except Exception as e:
                logger.error(f"âŒ LLMåœºæ™¯é€‰æ‹©å¤±è´¥: {str(e)}")
                return []
        except Exception as e:
             logger.info(f"ranankerå¤±è´¥{str(e)}")

    
    async def rule_rank_scenarios(
        self,
        scenarios: List[Dict[str, Any]],
        patient_info: PatientInfo,
        clinical_context: ClinicalContext,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ä¼ ç»Ÿå¤šç»´åº¦æ‰“åˆ†æ’åºï¼ˆä¿åº•æ–¹æ¡ˆï¼‰
        
        Args:
            scenarios: å€™é€‰åœºæ™¯åˆ—è¡¨
            patient_info: æ‚£è€…åŸºæœ¬ä¿¡æ¯
            clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡
            top_k: è¿”å›çš„åœºæ™¯æ•°é‡
            
        Returns:
            è§„åˆ™æ’åºçš„åœºæ™¯åˆ—è¡¨
        """
        if not scenarios:
            return []
        
        scored_scenarios = []
        for item in scenarios:
            scenario = item['scenario']

            # 1. è¯­ä¹‰ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆæ¥è‡ªå‘é‡æ£€ç´¢ï¼‰
            semantic_score = item.get('semantic_score')

            # 2. å…³é”®è¯åŒ¹é…å¾—åˆ†ï¼ˆæ¥è‡ªjiebaæ£€ç´¢ï¼‰
            keyword_score = item.get('jieba_score')

            # 3. ç»“æ„åŒ–åŒ¹é…
            structure_score = self._calculate_structure_match(scenario, patient_info)

            # 4. ä¸´åºŠä¼˜å…ˆçº§
            priority_score = self._calculate_priority(scenario, clinical_context)

            # 5. MMRå¤šæ ·æ€§
            diversity_score = item.get('mmr_score')

            # ä¿®æ­£æ¡ä»¶åˆ¤æ–­é€»è¾‘
            if structure_score != 0 and priority_score != 0:
                # ä¸¤ä¸ªéƒ½ä¸ä¸º0çš„æƒ…å†µ
                if semantic_score and diversity_score:
                    final_score = (
                            0.3 * semantic_score +
                            0.2 * structure_score +
                            0.2 * priority_score +
                            0.3 * diversity_score
                    )
                else:
                    final_score = semantic_score if semantic_score else diversity_score
            elif structure_score != 0:
                # åªæœ‰structure_scoreä¸ä¸º0
                if semantic_score and diversity_score:
                    final_score = (
                            0.35 * semantic_score +
                            0.3 * structure_score +
                            0.35 * diversity_score
                    )
                else:
                    final_score = semantic_score if semantic_score else diversity_score
            elif priority_score != 0:
                # åªæœ‰priority_scoreä¸ä¸º0
                if semantic_score and diversity_score:
                    final_score = (
                            0.35 * semantic_score +
                            0.3 * priority_score +
                            0.35 * diversity_score
                    )
                else:
                    final_score = semantic_score if semantic_score else diversity_score
            else:
                # ä¸¤ä¸ªéƒ½ä¸º0çš„æƒ…å†µ
                if semantic_score and diversity_score:
                    final_score = (
                            0.5 * semantic_score +
                            0.5 * diversity_score
                    )
                else:
                    final_score = semantic_score if semantic_score else diversity_score



            item['rule_score'] = final_score
            item['selection_source_by_rule'] = 'Rule'
            item['score_breakdown'] = {
                'semantic_score': semantic_score,
                'keyword_score': keyword_score,
                'structure_score': structure_score,
                'priority_score': priority_score,
                'diversity_score': diversity_score
            }
            scored_scenarios.append(item)


        scored_scenarios.sort(key=lambda  x:x["rule_score"],reverse=True)
        return scored_scenarios

    
    def _calculate_structure_match(
        self, 
        scenario: ClinicalScenario, 
        patient_info: PatientInfo
    ) -> float:
        """
        è®¡ç®—ç»“æ„åŒ–åŒ¹é…å¾—åˆ†
        
        Args:
            scenario: ä¸´åºŠåœºæ™¯
            patient_info: æ‚£è€…ä¿¡æ¯
            
        Returns:
            ç»“æ„åŒ–åŒ¹é…å¾—åˆ† (0-1)
        """
        score = 0
        count = 0

        # å¹´é¾„åŒ¹é…ï¼ˆæ”¯æŒåˆ«åå’ŒèŒƒå›´è§£æï¼‰
        if patient_info.age or scenario.age_group:
            age_match_score = self._match_age(patient_info.age, scenario)
            score += age_match_score
            if age_match_score!=0:
               count += 1

        # æ€§åˆ«åŒ¹é…ï¼ˆæ”¯æŒåˆ«åï¼‰
        if scenario.gender or patient_info.gender:
            gender_match_score = self._match_gender(patient_info.gender,scenario.gender, scenario)
            score += gender_match_score
            if gender_match_score!=0:
               count += 1

        # å¦Šå¨ çŠ¶æ€åŒ¹é…ï¼ˆæ”¯æŒåˆ«åï¼‰
        if scenario.pregnancy_status or patient_info.pregnancy_status:
            pregnancy_match_score = self._match_pregnancy_status(
                patient_info.pregnancy_status, scenario.pregnancy_status,scenario
            )
            score += pregnancy_match_score
            if pregnancy_match_score!=0:
               count += 1
        if score==0:
            return score
        return score / count if count > 0 else 0

    def _match_age(self, patient_age: int, scenario) -> float:
        """
        å¹´é¾„åŒ¹é…ï¼ˆæ”¯æŒèŒƒå›´è§£æå’Œåˆ«åï¼‰

        Args:
            patient_age: æ‚£è€…å¹´é¾„
            scenario: ä¸´åºŠåœºæ™¯å¯¹è±¡

        Returns:
            åŒ¹é…å¾—åˆ† (0-1)
        """
        import re
        import jieba

        if not scenario:
            return 0

        # é¦–å…ˆå°è¯•ä½¿ç”¨age_group
        age_group = scenario.age_group
        description_zh = scenario.description_zh or ""

        # å¦‚æœage_groupä¸ºç©ºï¼Œåˆ™ä»description_zhä¸­æå–å¹´é¾„ä¿¡æ¯
        if not age_group and description_zh:
            age_group = self._extract_age_from_description(description_zh)

        # æ ‡å‡†åŒ–å¹´é¾„ç»„æè¿°
        normalized_group = (age_group or "").lower().replace(' ', '').replace('å²', '')
        normalized_desc = description_zh.lower().replace(' ', '').replace('å²', '')

        # æ£€æŸ¥"ä¸é™"
        if any(unlimited in normalized_group for unlimited in ['ä¸é™', 'é€šç”¨', 'all', 'both', 'any']) or \
                any(unlimited in normalized_desc for unlimited in ['ä¸é™', 'é€šç”¨', 'all', 'both', 'any']):
            return 1.0

        # è§£ææ•°å­—èŒƒå›´ï¼ˆä»age_groupæˆ–descriptionä¸­ï¼‰
        range_pattern = r'(\d+)[-~è‡³](\d+)'
        matches = []

        if age_group:
            matches.extend(re.findall(range_pattern, age_group))
        if description_zh and not matches:  # å¦‚æœage_groupä¸­æ²¡æœ‰æ‰¾åˆ°èŒƒå›´ï¼Œå†ä»descriptionä¸­æ‰¾
            matches.extend(re.findall(range_pattern, description_zh))

        if matches:
            for min_age, max_age in matches:
                if int(min_age) <= patient_age <= int(max_age):
                    return 1.0
            # ä¸åœ¨èŒƒå›´å†…ï¼Œæ£€æŸ¥æ˜¯å¦æ¥è¿‘è¾¹ç•Œ
            for min_age, max_age in matches:
                min_age_int, max_age_int = int(min_age), int(max_age)
                if abs(patient_age - min_age_int) <= 2 or abs(patient_age - max_age_int) <= 2:
                    return 0.7  # æ¥è¿‘è¾¹ç•Œï¼Œç»™è¾ƒé«˜åˆ†æ•°
            return 0.3  # ä¸åœ¨èŒƒå›´å†…ï¼Œç»™éƒ¨åˆ†åˆ†æ•°

        # åŸºäºå…³é”®è¯çš„åŒ¹é…ï¼ˆåŒæ—¶æ£€æŸ¥age_groupå’Œdescriptionï¼‰
        search_text = normalized_group + normalized_desc

        # å®Œæ•´çš„å¹´é¾„æ˜ å°„
        age_mapping = {
            'èƒå„¿': ['èƒå„¿', 'fetus', 'fetal'],
            'æ–°ç”Ÿå„¿': ['æ–°ç”Ÿå„¿', 'æ–°ç”Ÿ', 'neonate', 'newborn', 'å‡ºç”Ÿ', 'åˆšå‡ºç”Ÿ'],
            'å©´å„¿': ['å©´å„¿', 'å©´å¹¼å„¿', 'infant', 'baby', 'å©´å­©'],
            'å¹¼å„¿': ['å¹¼å„¿', 'toddler', 'å¹¼ç«¥'],
            'å­¦é¾„å‰': ['å­¦é¾„å‰', 'preschool'],
            'å„¿ç«¥': ['å„¿ç«¥', 'å°å„¿', 'å„¿ç§‘', 'child', 'children', 'kid'],
            'å­¦é¾„æœŸ': ['å­¦é¾„æœŸ', 'å­¦é¾„å„¿ç«¥', 'school-age'],
            'é’å°‘å¹´': ['é’å°‘å¹´', 'å°‘å¹´', 'adolescent', 'teenager', 'é’æ˜¥æœŸ', 'puberty'],
            'é’å¹´': ['é’å¹´', 'young adult', 'young'],
            'æˆäºº': ['æˆäºº', 'æˆå¹´', 'adult', 'grown-up'],
            'ä¸­å¹´': ['ä¸­å¹´', 'middle-aged', 'midlife'],
            'è€å¹´': ['è€å¹´', 'è€äºº', 'elderly', 'aged', 'senior', 'geriatric', 'è€å¹´äºº', 'é«˜é¾„'],
            'ä¸é™': ['ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'any', 'all', 'both']
        }

        # å®šä¹‰å„å¹´é¾„æ®µçš„å¹´é¾„èŒƒå›´
        age_ranges = {
            'èƒå„¿': (0, 0),  # ç‰¹æ®Šå¤„ç†
            'æ–°ç”Ÿå„¿': (0, 1),  # 0-1ä¸ªæœˆ
            'å©´å„¿': (0, 2),  # 0-2å²
            'å¹¼å„¿': (2, 5),  # 2-5å²
            'å­¦é¾„å‰': (3, 6),  # 3-6å²
            'å„¿ç«¥': (6, 12),  # 6-12å²
            'å­¦é¾„æœŸ': (6, 12),  # 6-12å²
            'é’å°‘å¹´': (12, 18),  # 12-18å²
            'é’å¹´': (18, 40),  # 18-40å²
            'æˆäºº': (18, 65),  # 18-65å²
            'ä¸­å¹´': (40, 65),  # 40-65å²
            'è€å¹´': (65, 150)  # 65å²ä»¥ä¸Š
        }

        # æ£€æŸ¥æ¯ä¸ªå¹´é¾„æ®µçš„å…³é”®è¯
        for age_group_name, keywords in age_mapping.items():
            if any(keyword in search_text for keyword in keywords):
                if age_group_name == 'ä¸é™':
                    return 1.0
                elif age_group_name == 'èƒå„¿':
                    # èƒå„¿æ˜¯ç‰¹æ®Šæƒ…å†µï¼Œé€šå¸¸æ— æ³•åŒ¹é…å®é™…å¹´é¾„
                    return 0.5
                elif age_group_name in age_ranges:
                    min_age, max_age = age_ranges[age_group_name]
                    if min_age <= patient_age <= max_age:
                        return 1.0
                    else:
                        # ä¸åœ¨èŒƒå›´å†…ï¼Œæ£€æŸ¥æ˜¯å¦æ¥è¿‘è¾¹ç•Œ
                        if abs(patient_age - min_age) <= 2 or abs(patient_age - max_age) <= 2:
                            return 0.7
                        else:
                            return 0.3

        return 0  # é»˜è®¤åˆ†æ•°

    def _extract_age_from_description(self, description_zh: str) -> str:
        """
        ä»åœºæ™¯æè¿°ä¸­æå–å¹´é¾„ä¿¡æ¯

        Args:
            description_zh: ä¸­æ–‡æè¿°

        Returns:
            æå–çš„å¹´é¾„ä¿¡æ¯å­—ç¬¦ä¸²
        """
        import re
        import jieba

        if not description_zh:
            return ""

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ˜æ˜¾çš„å¹´é¾„èŒƒå›´
        range_pattern = r'(\d+)[-~è‡³](\d+)å²?'
        range_matches = re.findall(range_pattern, description_zh)
        if range_matches:
            for min_age, max_age in range_matches:
                return f"{min_age}-{max_age}å²"

        # å®Œæ•´çš„å¹´é¾„æ˜ å°„
        age_mapping = {
            'èƒå„¿': ['èƒå„¿', 'fetus', 'fetal'],
            'æ–°ç”Ÿå„¿': ['æ–°ç”Ÿå„¿', 'æ–°ç”Ÿ', 'neonate', 'newborn', 'å‡ºç”Ÿ', 'åˆšå‡ºç”Ÿ'],
            'å©´å„¿': ['å©´å„¿', 'å©´å¹¼å„¿', 'infant', 'baby', 'å©´å­©'],
            'å¹¼å„¿': ['å¹¼å„¿', 'toddler', 'å¹¼ç«¥'],
            'å­¦é¾„å‰': ['å­¦é¾„å‰', 'preschool'],
            'å„¿ç«¥': ['å„¿ç«¥', 'å°å„¿', 'å„¿ç§‘', 'child', 'children', 'kid'],
            'å­¦é¾„æœŸ': ['å­¦é¾„æœŸ', 'å­¦é¾„å„¿ç«¥', 'school-age'],
            'é’å°‘å¹´': ['é’å°‘å¹´', 'å°‘å¹´', 'adolescent', 'teenager', 'é’æ˜¥æœŸ', 'puberty'],
            'é’å¹´': ['é’å¹´', 'young adult', 'young'],
            'æˆäºº': ['æˆäºº', 'æˆå¹´', 'adult', 'grown-up'],
            'ä¸­å¹´': ['ä¸­å¹´', 'middle-aged', 'midlife'],
            'è€å¹´': ['è€å¹´', 'è€äºº', 'elderly', 'aged', 'senior', 'geriatric', 'è€å¹´äºº', 'é«˜é¾„'],
            'ä¸é™': ['ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'any', 'all', 'both']
        }

        # ä½¿ç”¨jiebaåˆ†è¯å¹¶æŸ¥æ‰¾å¹´é¾„ç›¸å…³å…³é”®è¯
        words = jieba.cut(description_zh)

        for word in words:
            word_lower = word.lower()
            for age_group, keywords in age_mapping.items():
                if word_lower in [kw.lower() for kw in keywords]:
                    return age_group

        return ""

    def _match_gender(self, patient_gender: str, scenario_gender: str, scenario: ClinicalScenario = None) -> float:
        """
        æ€§åˆ«åŒ¹é…ï¼ˆæ”¯æŒåˆ«åï¼‰

        Args:
            patient_gender: æ‚£è€…æ€§åˆ«
            scenario_gender: åœºæ™¯æ€§åˆ«è¦æ±‚
            scenario: ä¸´åºŠåœºæ™¯å¯¹è±¡ï¼ˆå¯é€‰ï¼Œç”¨äºä»æè¿°ä¸­æå–æ€§åˆ«ï¼‰

        Returns:
            åŒ¹é…å¾—åˆ† (0-1)
        """
        if not patient_gender:
            return 0  # æ‚£è€…æ€§åˆ«ä¸ºç©ºæ—¶è¿”å›ä¸­ç­‰åˆ†æ•°

        # å¦‚æœscenario_genderä¸ºç©ºï¼Œå°è¯•ä»åœºæ™¯æè¿°ä¸­æå–
        if not scenario_gender and scenario and scenario.description_zh:
            scenario_gender = self._extract_gender_from_description(scenario.description_zh)

        # å¦‚æœæå–åä»ä¸ºç©ºï¼Œè¿”å›é»˜è®¤åˆ†æ•°
        if not scenario_gender:
            return 0

        # æ ‡å‡†åŒ–è¾“å…¥
        patient_gender_norm = patient_gender.strip().lower()
        scenario_gender_norm = scenario_gender.strip().lower()

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•åˆ«å
        for standard_gender, aliases in self.gender_mapping.items():
            # æ‚£è€…æ€§åˆ«åŒ¹é…
            patient_aliases_lower = [alias.lower() for alias in aliases]
            patient_match = patient_gender_norm in patient_aliases_lower

            # åœºæ™¯æ€§åˆ«è¦æ±‚åŒ¹é…
            scenario_aliases_lower = [alias.lower() for alias in aliases]
            scenario_match = scenario_gender_norm in scenario_aliases_lower

            if patient_match and scenario_match:
                return 1.0
            elif scenario_match and standard_gender == 'ä¸é™':
                return 1.0

        # æ¨¡ç³ŠåŒ¹é…ï¼šæ£€æŸ¥å­—ç¬¦ä¸²åŒ…å«å…³ç³»
        if patient_gender_norm in scenario_gender_norm or scenario_gender_norm in patient_gender_norm:
            return 0.8

        return 0.0

    def _extract_gender_from_description(self, description_zh: str) -> str:
        """
        ä»åœºæ™¯æè¿°ä¸­æå–æ€§åˆ«ä¿¡æ¯

        Args:
            description_zh: ä¸­æ–‡æè¿°

        Returns:
            æå–çš„æ€§åˆ«ä¿¡æ¯å­—ç¬¦ä¸²
        """
        import re
        import jieba

        if not description_zh:
            return ""

        # æ‰©å±•çš„æ€§åˆ«æ˜ å°„
        gender_mapping = {
            'ç”·æ€§': [
                'ç”·', 'ç”·æ€§', 'ç”·äºº', 'ç”·å£«', 'ç”·æ‚£è€…', 'ç”·ç«¥', 'ç”·å­©', 'ç”·ç”Ÿ', 'ç”·å©´', 'ç”·é’å¹´',
                'ç”·å­', 'ç”·ç—…äºº', 'ç”·ç§‘', 'é›„æ€§', 'å…¬', 'é›„', 'male', 'm', 'man', 'boy', 'gentleman'
            ],
            'å¥³æ€§': [
                'å¥³', 'å¥³æ€§', 'å¥³äºº', 'å¥³å£«', 'å¥³æ‚£è€…', 'å¥³ç«¥', 'å¥³å­©', 'å¥³ç”Ÿ', 'å¥³å©´', 'å¥³é’å¹´',
                'å¥³å­', 'å¥³ç—…äºº', 'å¦‡ç§‘', 'é›Œæ€§', 'æ¯', 'é›Œ', 'female', 'f', 'woman', 'girl', 'lady'
            ],
            'ä¸é™': [
                'ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'ä»»ä½•', 'å‡å¯', 'ç”·å¥³', 'ç”·å¥³å‡å¯', 'ç”·å¥³çš†å¯',
                'any', 'all', 'both', 'either', 'é€šç”¨', 'common', 'general',"æˆäºº","æˆå¹´äºº"
            ]
        }

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ˜æ˜¾çš„æ€§åˆ«ä¿¡æ¯
        gender_patterns = [
            r'([ç”·å¥³])æ€§?æ‚£è€…?',
            r'æ‚£è€…?([ç”·å¥³])',
            r'([ç”·å¥³])æ€§',
            r'([ç”·å¥³])å­',
            r'([ç”·å¥³])',
            r'(é›„æ€§|é›Œæ€§)',
            r'(ç”·æ€§|å¥³æ€§)',
            r'(ç”·ç§‘|å¦‡ç§‘)'
        ]

        for pattern in gender_patterns:
            matches = re.findall(pattern, description_zh)
            if matches:
                gender_char = matches[0]
                if gender_char in ['ç”·', 'ç”·æ€§', 'ç”·ç§‘', 'é›„æ€§']:
                    return 'ç”·æ€§'
                elif gender_char in ['å¥³', 'å¥³æ€§', 'å¦‡ç§‘', 'é›Œæ€§']:
                    return 'å¥³æ€§'

        # ä½¿ç”¨jiebaåˆ†è¯å¹¶æŸ¥æ‰¾æ€§åˆ«ç›¸å…³å…³é”®è¯
        words = jieba.cut(description_zh)

        # åˆ›å»ºå…³é”®è¯åˆ°æ ‡å‡†æ€§åˆ«çš„æ˜ å°„
        keyword_to_gender = {}
        for gender, keywords in gender_mapping.items():
            for keyword in keywords:
                keyword_to_gender[keyword.lower()] = gender

        # æ£€æŸ¥æ¯ä¸ªåˆ†è¯æ˜¯å¦åŒ¹é…æ€§åˆ«å…³é”®è¯
        for word in words:
            word_lower = word.lower()
            if word_lower in keyword_to_gender:
                return keyword_to_gender[word_lower]

        # æ£€æŸ¥æ•´ä¸ªæè¿°ä¸­æ˜¯å¦åŒ…å«æ€§åˆ«å…³é”®è¯ï¼ˆç”¨äºå¤„ç†æœªæ­£ç¡®åˆ†è¯çš„æƒ…å†µï¼‰
        description_lower = description_zh.lower()
        for gender, keywords in gender_mapping.items():
            for keyword in keywords:
                if keyword.lower() in description_lower:
                    return gender

        return ""

    def _match_pregnancy_status(self, patient_status: str, scenario_status: str,
                                scenario: ClinicalScenario = None) -> float:
        """
        å¦Šå¨ çŠ¶æ€åŒ¹é…ï¼ˆæ”¯æŒåˆ«åï¼‰

        Args:
            patient_status: æ‚£è€…å¦Šå¨ çŠ¶æ€
            scenario_status: åœºæ™¯å¦Šå¨ çŠ¶æ€è¦æ±‚
            scenario: ä¸´åºŠåœºæ™¯å¯¹è±¡ï¼ˆå¯é€‰ï¼Œç”¨äºä»æè¿°ä¸­æå–å¦Šå¨ çŠ¶æ€ï¼‰

        Returns:
            åŒ¹é…å¾—åˆ† (0-1)
        """
        if not patient_status:
            return 0  # æ‚£è€…å¦Šå¨ çŠ¶æ€ä¸ºç©ºæ—¶è¿”å›ä¸­ç­‰åˆ†æ•°

        # å¦‚æœscenario_statusä¸ºç©ºï¼Œå°è¯•ä»åœºæ™¯æè¿°ä¸­æå–
        if not scenario_status and scenario and scenario.description_zh:
            scenario_status = self._extract_pregnancy_status_from_description(scenario.description_zh)

        # å¦‚æœæå–åä»ä¸ºç©ºï¼Œè¿”å›é»˜è®¤åˆ†æ•°
        if not scenario_status:
            return 0

        # æ ‡å‡†åŒ–è¾“å…¥
        patient_status_norm = patient_status.strip().lower()
        scenario_status_norm = scenario_status.strip().lower()

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•åˆ«å
        for standard_status, aliases in self.pregnancy_mapping.items():
            # æ‚£è€…çŠ¶æ€åŒ¹é…
            patient_aliases_lower = [alias.lower() for alias in aliases]
            patient_match = patient_status_norm in patient_aliases_lower

            # åœºæ™¯çŠ¶æ€è¦æ±‚åŒ¹é…
            scenario_aliases_lower = [alias.lower() for alias in aliases]
            scenario_match = scenario_status_norm in scenario_aliases_lower

            if patient_match and scenario_match:
                return 1.0
            elif scenario_match and standard_status == 'ä¸é™':
                return 1.0

        # æ¨¡ç³ŠåŒ¹é…ï¼šæ£€æŸ¥å­—ç¬¦ä¸²åŒ…å«å…³ç³»
        if patient_status_norm in scenario_status_norm or scenario_status_norm in patient_status_norm:
            return 0.8

        return 0.0

    def _extract_pregnancy_status_from_description(self, description_zh: str) -> str:
        """
        ä»åœºæ™¯æè¿°ä¸­æå–å¦Šå¨ çŠ¶æ€ä¿¡æ¯

        Args:
            description_zh: ä¸­æ–‡æè¿°

        Returns:
            æå–çš„å¦Šå¨ çŠ¶æ€ä¿¡æ¯å­—ç¬¦ä¸²
        """
        import re
        import jieba

        if not description_zh:
            return ""

        # æ‰©å±•çš„å¦Šå¨ çŠ¶æ€æ˜ å°„
        pregnancy_mapping = {
            'å¦Šå¨ æœŸ': [
                'å¦Šå¨ ', 'æ€€å­•', 'å­•å¦‡', 'å­•æœŸ', 'å¦Šå¨ æœŸ', 'å­•äº§å¦‡', 'å­•äº§æœŸ', 'å­•å‘¨', 'å­•æ—©æœŸ',
                'å­•ä¸­æœŸ', 'å­•æ™šæœŸ', 'æ—©å­•', 'ä¸­å­•', 'æ™šå­•', 'æ€€å­•æœŸ', 'pregnancy', 'pregnant',
                'gestation', 'gestational', 'prenatal', 'antenatal'
            ],
            'éå¦Šå¨ æœŸ': [
                'éå¦Šå¨ ', 'éå­•å¦‡', 'æœªæ€€å­•', 'æœªå¦Šå¨ ', 'éå­•æœŸ', 'æœªå­•', 'éå­•', 'non-pregnancy',
                'not pregnant', 'non-pregnant', 'non-gestational'
            ],
            'å“ºä¹³æœŸ': [
                'å“ºä¹³', 'å“ºä¹³æœŸ', 'æ¯ä¹³å–‚å…»', 'æ¯ä¹³', 'å“ºä¹³æœŸå¦‡å¥³', 'å“ºä¹³æ¯äº²', 'lactation',
                'breastfeeding', 'nursing', 'lactating'
            ],
            'å¤‡å­•æœŸ': [
                'å¤‡å­•', 'å¤‡å­•æœŸ', 'è®¡åˆ’æ€€å­•', 'å‡†å¤‡æ€€å­•', 'preconception', 'trying to conceive',
                'fertility', 'pre-pregnancy'
            ],
            'äº§å': [
                'äº§å', 'åˆ†å¨©å', 'ç”Ÿäº§å', 'postpartum', 'postnatal', 'after delivery',
                'puerperium', 'post-partum'
            ],
            'ä¸å­•': [
                'ä¸å­•', 'ä¸å­•ç—‡', 'ä¸è‚²', 'ä¸è‚²ç—‡', 'infertility', 'infertile', 'sterility'
            ],
            'ä¸é™': [
                'ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'ä»»ä½•', 'å‡å¯', 'any', 'all', 'both', 'either',
                'é€šç”¨', 'common', 'general'
            ]
        }

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ˜æ˜¾çš„å¦Šå¨ çŠ¶æ€ä¿¡æ¯
        pregnancy_patterns = [
            r'(å¦Šå¨ |æ€€å­•|å­•å¦‡|å­•æœŸ|å­•å‘¨|å­•æ—©æœŸ|å­•ä¸­æœŸ|å­•æ™šæœŸ)',
            r'(éå¦Šå¨ |éå­•å¦‡|æœªæ€€å­•|æœªå¦Šå¨ |æœªå­•|éå­•)',
            r'(å“ºä¹³|å“ºä¹³æœŸ|æ¯ä¹³å–‚å…»)',
            r'(å¤‡å­•|å¤‡å­•æœŸ|è®¡åˆ’æ€€å­•)',
            r'(äº§å|åˆ†å¨©å|ç”Ÿäº§å)',
            r'(ä¸å­•|ä¸å­•ç—‡|ä¸è‚²|ä¸è‚²ç—‡)'
        ]

        for pattern in pregnancy_patterns:
            matches = re.findall(pattern, description_zh)
            if matches:
                status_char = matches[0]
                if status_char in ['å¦Šå¨ ', 'æ€€å­•', 'å­•å¦‡', 'å­•æœŸ', 'å­•å‘¨', 'å­•æ—©æœŸ', 'å­•ä¸­æœŸ', 'å­•æ™šæœŸ']:
                    return 'å¦Šå¨ æœŸ'
                elif status_char in ['éå¦Šå¨ ', 'éå­•å¦‡', 'æœªæ€€å­•', 'æœªå¦Šå¨ ', 'æœªå­•', 'éå­•']:
                    return 'éå¦Šå¨ æœŸ'
                elif status_char in ['å“ºä¹³', 'å“ºä¹³æœŸ', 'æ¯ä¹³å–‚å…»']:
                    return 'å“ºä¹³æœŸ'
                elif status_char in ['å¤‡å­•', 'å¤‡å­•æœŸ', 'è®¡åˆ’æ€€å­•']:
                    return 'å¤‡å­•æœŸ'
                elif status_char in ['äº§å', 'åˆ†å¨©å', 'ç”Ÿäº§å']:
                    return 'äº§å'
                elif status_char in ['ä¸å­•', 'ä¸å­•ç—‡', 'ä¸è‚²', 'ä¸è‚²ç—‡']:
                    return 'ä¸å­•'

        # ä½¿ç”¨jiebaåˆ†è¯å¹¶æŸ¥æ‰¾å¦Šå¨ çŠ¶æ€ç›¸å…³å…³é”®è¯
        words = jieba.cut(description_zh)

        # åˆ›å»ºå…³é”®è¯åˆ°æ ‡å‡†çŠ¶æ€çš„æ˜ å°„
        keyword_to_status = {}
        for status, keywords in pregnancy_mapping.items():
            for keyword in keywords:
                keyword_to_status[keyword.lower()] = status

        # æ£€æŸ¥æ¯ä¸ªåˆ†è¯æ˜¯å¦åŒ¹é…å¦Šå¨ çŠ¶æ€å…³é”®è¯
        for word in words:
            word_lower = word.lower()
            if word_lower in keyword_to_status:
                return keyword_to_status[word_lower]

        # æ£€æŸ¥æ•´ä¸ªæè¿°ä¸­æ˜¯å¦åŒ…å«å¦Šå¨ çŠ¶æ€å…³é”®è¯ï¼ˆç”¨äºå¤„ç†æœªæ­£ç¡®åˆ†è¯çš„æƒ…å†µï¼‰
        description_lower = description_zh.lower()
        for status, keywords in pregnancy_mapping.items():
            for keyword in keywords:
                if keyword.lower() in description_lower:
                    return status

        return ""

    def _calculate_priority(
            self,
            scenario: ClinicalScenario,
            clinical_context: ClinicalContext
    ) -> float:
        """
        è®¡ç®—ä¸´åºŠä¼˜å…ˆçº§å¾—åˆ†ï¼ˆæ”¯æŒç§‘å®¤åˆ«åï¼‰

        Args:
            scenario: ä¸´åºŠåœºæ™¯
            clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡

        Returns:
            ä¼˜å…ˆçº§å¾—åˆ† (0-1)
        """
        score = 0.0 # åŸºç¡€åˆ†
        count=0
        # ç§‘å®¤åŒ¹é…ï¼ˆæ”¯æŒåˆ«åå’Œæ¨¡ç³ŠåŒ¹é…ï¼‰
        if clinical_context.department and scenario.panel:
            panel_name = scenario.panel.name_zh if hasattr(scenario, 'panel') and scenario.panel else ''
            department_score = self._match_department(clinical_context.department, panel_name)
            score += department_score
            if department_score !=0:
               count+=1

        # ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦åŒ¹é…
        severity_score = self._match_urgency(clinical_context.symptom_severity, scenario.urgency_level,scenario)
        score += severity_score
        if severity_score !=0:
            count+=1

        if score ==0:
            return score

        return min(score//count, 1.0)

    def _match_department(self, patient_dept: str, scenario_dept: str) -> float:
        """
        ç§‘å®¤åŒ¹é…ï¼ˆæ”¯æŒåˆ«åå’Œæ¨¡ç³ŠåŒ¹é…ï¼‰

        Args:
            patient_dept: æ‚£è€…ç§‘å®¤
            scenario_dept: åœºæ™¯ç§‘å®¤

        Returns:
            åŒ¹é…å¾—åˆ† (0-1)
        """
        if not patient_dept or not scenario_dept:
            return 0.0

        patient_dept_norm = patient_dept.lower().strip()
        scenario_dept_norm = scenario_dept.lower().strip()

        # å®Œå…¨åŒ¹é…
        if patient_dept_norm == scenario_dept_norm:
            return 1.0

        # åŒ…å«å…³ç³»
        if patient_dept_norm in scenario_dept_norm or scenario_dept_norm in patient_dept_norm:
            return 0.8

        # å¸¸è§ç§‘å®¤åˆ«åæ˜ å°„
        for standard_dept, aliases in self.department_mapping.items():
            patient_aliases = [standard_dept] + aliases
            scenario_aliases = [standard_dept] + aliases

            patient_match = any(alias.lower() in patient_dept_norm for alias in patient_aliases)
            scenario_match = any(alias.lower() in scenario_dept_norm for alias in scenario_aliases)

            if patient_match and scenario_match:
                return 0.9

        return 0.0

    def _match_urgency(self, patient_urgency: str, scenario_urgency: str, scenario: ClinicalScenario = None) -> float:
        """
        ç´§æ€¥ç¨‹åº¦åŒ¹é…ï¼ˆæ”¯æŒåˆ«åï¼‰

        Args:
            patient_urgency: æ‚£è€…ç´§æ€¥ç¨‹åº¦
            scenario_urgency: åœºæ™¯ç´§æ€¥ç¨‹åº¦è¦æ±‚
            scenario: ä¸´åºŠåœºæ™¯å¯¹è±¡ï¼ˆå¯é€‰ï¼Œç”¨äºä»æè¿°ä¸­æå–ç´§æ€¥ç¨‹åº¦ï¼‰

        Returns:
            åŒ¹é…å¾—åˆ† (0-1)
        """
        if not patient_urgency:
            return 0

        # å¦‚æœscenario_urgencyä¸ºç©ºï¼Œå°è¯•ä»åœºæ™¯æè¿°ä¸­æå–
        if not scenario_urgency and scenario and scenario.description_zh:
            scenario_urgency = self._extract_urgency_from_description(scenario.description_zh)

        # å¦‚æœæå–åä»ä¸ºç©ºï¼Œè¿”å›é»˜è®¤åˆ†æ•°
        if not scenario_urgency:
            return 0

        # æ ‡å‡†åŒ–è¾“å…¥
        patient_urgency_norm = patient_urgency.strip().lower()
        scenario_urgency_norm = scenario_urgency.strip().lower()

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•åˆ«å
        for standard_urgency, aliases in self.urgency_mapping.items():
            # æ‚£è€…ç´§æ€¥ç¨‹åº¦åŒ¹é…
            patient_aliases_lower = [alias.lower() for alias in aliases]
            patient_match = patient_urgency_norm in patient_aliases_lower

            # åœºæ™¯ç´§æ€¥ç¨‹åº¦è¦æ±‚åŒ¹é…
            scenario_aliases_lower = [alias.lower() for alias in aliases]
            scenario_match = scenario_urgency_norm in scenario_aliases_lower

            if patient_match and scenario_match:
                return 1.0
            elif scenario_match and standard_urgency == 'ä¸é™':
                return 1.0

        # æ¨¡ç³ŠåŒ¹é…ï¼šæ£€æŸ¥å­—ç¬¦ä¸²åŒ…å«å…³ç³»
        if patient_urgency_norm in scenario_urgency_norm or scenario_urgency_norm in patient_urgency_norm:
            return 0.8

        return 0.0

    def _extract_urgency_from_description(self, description_zh: str) -> str:
        """
        ä»åœºæ™¯æè¿°ä¸­æå–ç´§æ€¥ç¨‹åº¦ä¿¡æ¯

        Args:
            description_zh: ä¸­æ–‡æè¿°

        Returns:
            æå–çš„ç´§æ€¥ç¨‹åº¦ä¿¡æ¯å­—ç¬¦ä¸²
        """
        import re
        import jieba

        if not description_zh:
            return ""

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ˜æ˜¾çš„ç´§æ€¥ç¨‹åº¦ä¿¡æ¯
        urgency_patterns = [
            r'(å±åŠç”Ÿå‘½|ç”Ÿå‘½å±é™©|life-threatening|critical condition)',
            r'(ç´§æ€¥|æ€¥è¯Š|æ€¥ç—‡|æ€¥æ€§|urgent|emergency|critical|acute)',
            r'(é‡åº¦|ä¸¥é‡|severe)',
            r'(ä¸­åº¦|ä¸­ç­‰|moderate|serious)',
            r'(äºšæ€¥æ€§|subacute)',
            r'(å¤å‘æ€§|å¤å‘|åå¤|recurrent|relapse)',
            r'(å¸¸è§„|æ…¢æ€§|å¸¸è§„æ£€æŸ¥|mild|chronic|routine)',
            r'(è½»å¾®|è½»åº¦|mild|minor)',
            r'(ä¸ç¨³å®š|unstable)',
            r'(ç¨³å®š|stable)',
            r'(æ‹©æœŸ|elective)',
            r'(é¢„é˜²æ€§|é¢„é˜²|preventive|prophylactic)',
            r'(ç­›æŸ¥|screening)',
            r'(éšè®¿|follow-up)',
            r'(åº·å¤|åº·å¤æœŸ|rehabilitation|recovery)',
            r'(ç»ˆæœ«æœŸ|æ™šæœŸ|æœ«æœŸ|end-stage|terminal)',
            r'(å§‘æ¯æ²»ç–—|å§‘æ¯|palliative)'
        ]

        for pattern in urgency_patterns:
            matches = re.findall(pattern, description_zh, re.IGNORECASE)
            if matches:
                urgency_char = matches[0]
                if urgency_char in ['å±åŠç”Ÿå‘½', 'ç”Ÿå‘½å±é™©', 'life-threatening', 'critical condition']:
                    return 'å±åŠç”Ÿå‘½'
                elif urgency_char in ['ç´§æ€¥', 'æ€¥è¯Š', 'æ€¥ç—‡', 'æ€¥æ€§', 'urgent', 'emergency', 'critical', 'acute']:
                    return 'ç´§æ€¥'
                elif urgency_char in ['é‡åº¦', 'ä¸¥é‡', 'severe']:
                    return 'é‡åº¦'
                elif urgency_char in ['ä¸­åº¦', 'ä¸­ç­‰', 'moderate', 'serious']:
                    return 'ä¸­åº¦'
                elif urgency_char in ['äºšæ€¥æ€§', 'subacute']:
                    return 'äºšæ€¥æ€§'
                elif urgency_char in ['å¤å‘æ€§', 'å¤å‘', 'åå¤', 'recurrent', 'relapse']:
                    return 'å¤å‘æ€§'
                elif urgency_char in ['å¸¸è§„', 'æ…¢æ€§', 'å¸¸è§„æ£€æŸ¥', 'mild', 'chronic', 'routine']:
                    return 'å¸¸è§„'
                elif urgency_char in ['è½»å¾®', 'è½»åº¦', 'mild', 'minor']:
                    return 'è½»å¾®'
                elif urgency_char in ['ä¸ç¨³å®š', 'unstable']:
                    return 'ä¸ç¨³å®š'
                elif urgency_char in ['ç¨³å®š', 'stable']:
                    return 'ç¨³å®š'
                elif urgency_char in ['æ‹©æœŸ', 'elective']:
                    return 'æ‹©æœŸ'
                elif urgency_char in ['é¢„é˜²æ€§', 'é¢„é˜²', 'preventive', 'prophylactic']:
                    return 'é¢„é˜²æ€§'
                elif urgency_char in ['ç­›æŸ¥', 'screening']:
                    return 'ç­›æŸ¥'
                elif urgency_char in ['éšè®¿', 'follow-up']:
                    return 'éšè®¿'
                elif urgency_char in ['åº·å¤', 'åº·å¤æœŸ', 'rehabilitation', 'recovery']:
                    return 'åº·å¤'
                elif urgency_char in ['ç»ˆæœ«æœŸ', 'æ™šæœŸ', 'æœ«æœŸ', 'end-stage', 'terminal']:
                    return 'ç»ˆæœ«æœŸ'
                elif urgency_char in ['å§‘æ¯æ²»ç–—', 'å§‘æ¯', 'palliative']:
                    return 'å§‘æ¯æ²»ç–—'

        # ä½¿ç”¨jiebaåˆ†è¯å¹¶æŸ¥æ‰¾ç´§æ€¥ç¨‹åº¦ç›¸å…³å…³é”®è¯
        words = jieba.cut(description_zh)

        urgency_keywords = {
            'å±åŠç”Ÿå‘½': ['å±åŠç”Ÿå‘½', 'ç”Ÿå‘½å±é™©', 'life-threatening', 'critical condition'],
            'ç´§æ€¥': ['ç´§æ€¥', 'æ€¥è¯Š', 'æ€¥ç—‡', 'æ€¥æ€§', 'urgent', 'emergency', 'critical', 'acute'],
            'é‡åº¦': ['é‡åº¦', 'ä¸¥é‡', 'severe'],
            'ä¸­åº¦': ['ä¸­åº¦', 'ä¸­ç­‰', 'moderate', 'serious'],
            'äºšæ€¥æ€§': ['äºšæ€¥æ€§', 'subacute'],
            'å¤å‘æ€§': ['å¤å‘æ€§', 'å¤å‘', 'åå¤', 'recurrent', 'relapse'],
            'å¸¸è§„': ['å¸¸è§„', 'æ…¢æ€§', 'å¸¸è§„æ£€æŸ¥', 'mild', 'chronic', 'routine'],
            'è½»å¾®': ['è½»å¾®', 'è½»åº¦', 'mild', 'minor'],
            'ä¸ç¨³å®š': ['ä¸ç¨³å®š', 'unstable'],
            'ç¨³å®š': ['ç¨³å®š', 'stable'],
            'æ‹©æœŸ': ['æ‹©æœŸ', 'elective'],
            'é¢„é˜²æ€§': ['é¢„é˜²æ€§', 'é¢„é˜²', 'preventive', 'prophylactic'],
            'ç­›æŸ¥': ['ç­›æŸ¥', 'screening'],
            'éšè®¿': ['éšè®¿', 'follow-up'],
            'åº·å¤': ['åº·å¤', 'åº·å¤æœŸ', 'rehabilitation', 'recovery'],
            'ç»ˆæœ«æœŸ': ['ç»ˆæœ«æœŸ', 'æ™šæœŸ', 'æœ«æœŸ', 'end-stage', 'terminal'],
            'å§‘æ¯æ²»ç–—': ['å§‘æ¯æ²»ç–—', 'å§‘æ¯', 'palliative'],
            'ä¸é™': ['ä¸é™', 'é€šç”¨', 'å…¨éƒ¨', 'æ‰€æœ‰', 'any', 'all', 'both']
        }

        for word in words:
            word_lower = word.lower()
            for urgency, keywords in urgency_keywords.items():
                if word_lower in [kw.lower() for kw in keywords]:
                    return urgency

        return ""
    
    async def hybrid_rank_scenarios(
        self,
        scenarios: List[Dict[str, Any]],
        patient_info: PatientInfo,
        clinical_context: ClinicalContext,
        top_k: int = 5,
        enable_llm: bool = False
    ) -> List[Dict[str, Any]]:
        """
        æ··åˆé‡æ’ï¼šLLMæ™ºèƒ½é€‰æ‹© + è§„åˆ™æ‰“åˆ†èåˆ
        
        Args:
            scenarios: å€™é€‰åœºæ™¯åˆ—è¡¨ï¼ˆæ¥è‡ªæ··åˆæ£€ç´¢çš„16æ¡ï¼‰
            patient_info: æ‚£è€…åŸºæœ¬ä¿¡æ¯
            clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡
            top_k: è¿”å›çš„åœºæ™¯æ•°é‡
            enable_llm: æ˜¯å¦å¯ç”¨LLMé€‰æ‹©
            
        Returns:
            æ··åˆæ’åºåçš„åœºæ™¯åˆ—è¡¨
        """
        llm_results=None
        rule_results=None

        llm_top_k = (top_k + 1) // 2  # å‘ä¸Šå–æ•´
        rule_top_k = top_k // 2  # å‘ä¸‹å–æ•´
        if not scenarios:
            logger.warning("è¾“å…¥åœºæ™¯ä¸ºç©º")
            return []
        if len(scenarios)<top_k:
            top_k=len(scenarios)
        # æ·±æ‹·è´scenariosï¼Œé˜²æ­¢å¹¶è¡Œå¤„ç†æ—¶äº§ç”Ÿæ•°æ®å†²çª
        # æ³¨æ„ï¼šscenarioå¯¹è±¡æœ¬èº«ä¸æ‹·è´ï¼ˆæ•°æ®åº“å¯¹è±¡ï¼‰ï¼Œåªæ‹·è´å¤–å±‚å­—å…¸ç»“æ„
        scenarios_for_llm = copy.deepcopy(scenarios)
        scenarios_for_rule = copy.deepcopy(scenarios)

        
        # å¹¶è¡Œæ‰§è¡ŒLLMå’Œè§„åˆ™æ’åº
        if enable_llm:
            logger.info("ğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡ŒLLMæ’åºå’Œè§„åˆ™æ’åº...")
            llm_task = self.llm_rank_scenarios(
                scenarios_for_llm, patient_info, clinical_context, llm_top_k
            )
            rule_task = self.rule_rank_scenarios(
                scenarios_for_rule, patient_info, clinical_context, rule_top_k
            )

            llm_results, rule_results = await asyncio.gather(
                llm_task, rule_task, return_exceptions=True
            )

            # å¼‚å¸¸å¤„ç†
            if isinstance(llm_results, Exception):
                logger.warning(f"âš ï¸ LLMæ’åºå¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™æ’åº: {llm_results}")
                llm_results = []
            if isinstance(rule_results, Exception):
                logger.error(f"âŒ è§„åˆ™æ’åºå¤±è´¥: {rule_results}")
                rule_results = []

        logger.info("ğŸ”§ ä»…ä½¿ç”¨è§„åˆ™æ’åº")
        rule_results = await self.rule_rank_scenarios(
                scenarios, patient_info, clinical_context, top_k
            )
        
        # å»é‡åˆå¹¶é€»è¾‘
        final_scenarios = []
        seen_ids = set()
        
        # # 1. ä¼˜å…ˆé€‰æ‹©LLMç»“æœ
        if llm_results:
            for item in llm_results:
                scenario_id = item['scenario'].id
                if scenario_id not in seen_ids:
                    final_scenarios.append(item)
                    seen_ids.add(scenario_id)
            logger.info(f"âœ… LLMè´¡çŒ® {len(llm_results)} ä¸ªåœºæ™¯")
        
        # 2. è¡¥å……è§„åˆ™æ’åºç»“æœï¼ˆå»é‡ï¼‰
        if rule_results:
            for item in rule_results:
                scenario_id = item['scenario'].id
                if scenario_id not in seen_ids and len(final_scenarios) < top_k:
                    final_scenarios.append(item)
                    seen_ids.add(scenario_id)
            llm_nums=len(llm_results) if llm_results else 0
            logger.info(f"ğŸ”§ è§„åˆ™è¡¥å…… {len(final_scenarios) -llm_nums} ä¸ªåœºæ™¯")
        
        # ç»Ÿè®¡ä¿¡æ¯
        llm_count = len([s for s in final_scenarios if s.get('selection_source_by_llm') == 'LLM'])
        rule_count = len([s for s in final_scenarios if s.get('selection_source_by_rule') == 'Rule'])
        
        logger.info(
            f"ğŸ¯ æ··åˆæ’åºå®Œæˆ: æ€»æ•°{len(final_scenarios)}, LLM({llm_count}), è§„åˆ™({rule_count})"
        )
        
        return final_scenarios[:top_k]

    async def llm_rank_all_scenarios(
            self,
            all_scenarios: List[Dict[str, Any]],
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            strategy: RerankingStrategy,
            min_rating: int = 5,
            max_scenarios: int = 3,
            max_recommendations_per_scenario: int = 2
    ) -> List[Dict[str, Any]]:
        """
        æ ¹æ®ç­–ç•¥æšä¸¾æ‰§è¡Œä¸åŒçš„åœºæ™¯å’Œæ¨èé¡¹ç›®å¤„ç†é€»è¾‘
        """
        if not all_scenarios:
            logger.warning("è¾“å…¥åœºæ™¯ä¸ºç©º")
            return []

        try:
            # æ ¹æ®ç­–ç•¥æ‰§è¡Œä¸åŒçš„å¤„ç†é€»è¾‘
            if strategy == RerankingStrategy.NONE:
                return await self._handle_none_strategy(all_scenarios, max_scenarios)
            elif strategy == RerankingStrategy.RULE_ONLY:
                return await self._handle_rule_only_strategy(
                    all_scenarios, patient_info, clinical_context,
                    min_rating, max_scenarios, max_recommendations_per_scenario
                )
            elif strategy == RerankingStrategy.LLM_SCENARIO_ONLY:
                return await self._handle_llm_scenario_only_strategy(
                    all_scenarios, patient_info, clinical_context,
                    min_rating, max_scenarios, max_recommendations_per_scenario
                )
            elif strategy == RerankingStrategy.LLM_RECOMMENDATION_ONLY:
                return await self._handle_llm_recommendation_only_strategy(
                    all_scenarios, patient_info, clinical_context,
                    min_rating, max_scenarios, max_recommendations_per_scenario
                )
            elif strategy == RerankingStrategy.RULE_AND_LLM_SCENARIO:
                return await self._handle_rule_and_llm_scenario_strategy(
                    all_scenarios, patient_info, clinical_context,
                    min_rating, max_scenarios, max_recommendations_per_scenario
                )
            elif strategy == RerankingStrategy.RULE_AND_LLM_RECOMMENDATION:
                return await self._handle_rule_and_llm_recommendation_strategy(
                    all_scenarios, patient_info, clinical_context,
                    min_rating, max_scenarios, max_recommendations_per_scenario
                )
            elif strategy == RerankingStrategy.LLM_SCENARIO_AND_RECOMMENDATION:
                return await self._handle_llm_scenario_and_recommendation_strategy(
                    all_scenarios, patient_info, clinical_context,
                    min_rating, max_scenarios, max_recommendations_per_scenario
                )
            elif strategy == RerankingStrategy.ALL:
                return await self._handle_all_strategy(
                    all_scenarios, patient_info, clinical_context,
                    min_rating, max_scenarios, max_recommendations_per_scenario
                )
            else:
                logger.warning(f"æœªçŸ¥ç­–ç•¥: {strategy}ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†")
                return all_scenarios[:max_scenarios]

        except Exception as e:
            logger.error(f"å¤„ç†ç­–ç•¥ {strategy} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []

    # ========== å…«ç§ç­–ç•¥çš„å…·ä½“å®ç° ==========

    async def _handle_none_strategy(self, all_scenarios, max_scenarios):
        """ç­–ç•¥1: æ— é‡æ’åºï¼Œç›´æ¥è¿”å›"""
        logger.info(f"ç­–ç•¥1-NONE: ç›´æ¥è¿”å›å‰{max_scenarios}ä¸ªåœºæ™¯")
        return all_scenarios[:max_scenarios]

    async def _handle_rule_only_strategy(self, all_scenarios, patient_info, clinical_context,
                                         min_rating, max_scenarios, max_recommendations_per_scenario):
        """ç­–ç•¥2: ä»…è§„åˆ™é‡æ’åº"""
        logger.info(f"ç­–ç•¥2-RULE_ONLY: è§„åˆ™é‡æ’åº{max_scenarios}ä¸ªåœºæ™¯")

        # åº”ç”¨è§„åˆ™é‡æ’åº
        scenario_with_recommendations = await self.get_scenarios_with_recommends(
            all_scenarios, max_scenarios, max_recommendations_per_scenario, min_rating
        )
        filter_scenario_with_recommendations = [scenario_with_recommendation for scenario_with_recommendation in
                                                scenario_with_recommendations if
                                                scenario_with_recommendation["recommendations"]]
        rule_ranked_scenarios = await self.hybrid_rank_scenarios(
            scenarios=filter_scenario_with_recommendations,
            patient_info=patient_info,
            clinical_context=clinical_context,
            top_k=max_scenarios,
            enable_llm=False
        )

        # è·å–æ¨èé¡¹ç›®ï¼ˆåŸºäºACRè¯„åˆ†ï¼‰

        # final_scenario_with_recommendations = self._handel_filter_scenario_with_recommendations(
        #     scenario_with_recommendations,
        #     filter_scenario_with_recommendations,
        #     max_scenarios
        # )
        return assemble_database_results( rule_ranked_scenarios,patient_info, clinical_context, max_scenarios, max_recommendations_per_scenario)

    async def _handle_llm_scenario_only_strategy(self, all_scenarios, patient_info, clinical_context,
                                                 min_rating, max_scenarios, max_recommendations_per_scenario):
        """ç­–ç•¥3: ä»…LLMåœºæ™¯é‡æ’åº"""
        logger.info(f"ç­–ç•¥3-LLM_SCENARIO_ONLY: LLMé‡æ’åº{max_scenarios}ä¸ªåœºæ™¯")

        # LLMåœºæ™¯é‡æ’åº
        scenario_with_recommendations = await self.get_scenarios_with_recommends(
            all_scenarios, max_scenarios, max_recommendations_per_scenario, min_rating
        )
        filter_scenario_with_recommendations = [scenario_with_recommendation for scenario_with_recommendation in
                                                scenario_with_recommendations if
                                                scenario_with_recommendation["recommendations"]]
        llm_ranked_scenarios = await self.llm_rank_scenarios(
            filter_scenario_with_recommendations, patient_info, clinical_context, max_scenarios
        )

        # è·å–æ¨èé¡¹ç›®ï¼ˆåŸºäºACRè¯„åˆ†ï¼‰

        # final_scenario_with_recommendations = self._handel_filter_scenario_with_recommendations(
        #     scenario_with_recommendations,
        #     filter_scenario_with_recommendations,
        #     max_scenarios
        # )
        return assemble_database_results(llm_ranked_scenarios,patient_info, clinical_context, max_scenarios, max_recommendations_per_scenario)


    def select_scenarios_for_production(self, all_scenarios, max_scenarios,
                                        patient_id=None):
        """
        ç”Ÿäº§ç¯å¢ƒé€‰æ‹©ç­–ç•¥
        - å¦‚æœæä¾›äº†æ‚£è€…IDï¼ŒåŸºäºæ‚£è€…IDç”Ÿæˆç§å­ï¼ˆä¿è¯åŒä¸€æ‚£è€…ç»“æœä¸€è‡´ï¼‰
        - å¦åˆ™å®Œå…¨éšæœºï¼ˆå¢åŠ å¤šæ ·æ€§ï¼‰
        """
        top_k_scenarios = all_scenarios

        if len(top_k_scenarios) <= max_scenarios:
            return top_k_scenarios

        if patient_id:
            # åŸºäºæ‚£è€…IDç”Ÿæˆç¡®å®šæ€§ä½†ä¸ªæ€§åŒ–çš„éšæœº
            seed = self._generate_seed_from_patient(patient_id)
            random.seed(seed)
            return random.sample(top_k_scenarios, max_scenarios)
        else:
            # å®Œå…¨éšæœºï¼Œå¢åŠ ç»“æœå¤šæ ·æ€§
            return random.sample(top_k_scenarios, max_scenarios)

    def _generate_seed_from_patient(self, patient_id):
        """ä»æ‚£è€…IDç”Ÿæˆç§å­"""
        return hash(patient_id) % 10000
    async def _handle_llm_recommendation_only_strategy(self, all_scenarios, patient_info, clinical_context,
                                                       min_rating, max_scenarios, max_recommendations_per_scenario):
        """ç­–ç•¥4: ä»…LLMæ¨èé¡¹ç›®é‡æ’åº"""
        logger.info(f"ç­–ç•¥4-LLM_RECOMMENDATION_ONLY: å¯¹å‰{max_scenarios}ä¸ªåœºæ™¯è¿›è¡ŒLLMæ¨èé¡¹ç›®é‡æ’åº")

        # å…ˆé€‰æ‹©å‰max_scenariosä¸ªåœºæ™¯
        ranked_scenarios=all_scenarios[:max_scenarios*3]
        # è·å–è¿™äº›åœºæ™¯çš„æ¨èé¡¹ç›®
        scenario_with_recommendations = await self.get_scenarios_with_recommends(
            ranked_scenarios, max_scenarios, max_recommendations_per_scenario, min_rating
        )
        filter_scenario_with_recommendations = [scenario_with_recommendation for scenario_with_recommendation in
                                                scenario_with_recommendations if
                                                scenario_with_recommendation["recommendations"]]
        final_scenario_with_recommendations = self._handel_filter_scenario_with_recommendations(
            scenario_with_recommendations,
            filter_scenario_with_recommendations,
            max_scenarios
        )
        # ä½¿ç”¨è‡ªé€‚åº”å¼•æ“è¿›è¡ŒLLMæ¨èé¡¹ç›®é‡æ’åº
        recommendations = await self.adaptive_recommendation_engine_service.get_recommendations(
            final_scenario_with_recommendations, patient_info, clinical_context,
            max_recommendations_per_scenario, use_adaptive=True
        )

        return recommendations

    async def _handle_rule_and_llm_scenario_strategy(self, all_scenarios, patient_info, clinical_context,
                                                     min_rating, max_scenarios, max_recommendations_per_scenario):
        """ç­–ç•¥5: è§„åˆ™+LLMåœºæ™¯é‡æ’åº"""
        logger.info(f"ç­–ç•¥5-RULE_AND_LLM_SCENARIO: è§„åˆ™é‡æ’åºåLLMé‡æ’åº{max_scenarios}ä¸ªåœºæ™¯")

        scenario_with_recommendations = await self.get_scenarios_with_recommends(
            all_scenarios, max_scenarios, max_recommendations_per_scenario, min_rating
        )
        filter_scenario_with_recommendations = [scenario_with_recommendation for scenario_with_recommendation in
                                                scenario_with_recommendations if
                                                scenario_with_recommendation["recommendations"]]


        ranked_scenarios = await self.hybrid_rank_scenarios(
            scenarios=filter_scenario_with_recommendations,
            patient_info=patient_info,
            clinical_context=clinical_context,
            top_k=max_scenarios,
            enable_llm=True
        )

        # ç¬¬äºŒæ­¥ï¼šLLMåœºæ™¯é‡æ’åº
        # llm_ranked_scenarios = await self.llm_rank_scenarios(
        #     rule_ranked_scenarios, patient_info, clinical_context, max_scenarios
        # )

        # è·å–æ¨èé¡¹ç›®ï¼ˆåŸºäºACRè¯„åˆ†ï¼‰

        # final_scenario_with_recommendations = self._handel_filter_scenario_with_recommendations(
        #     scenario_with_recommendations,
        #     filter_scenario_with_recommendations,
        #     max_scenarios
        # )
        return assemble_database_results(ranked_scenarios, patient_info, clinical_context,
                                         max_scenarios, max_recommendations_per_scenario)

    async def _handle_rule_and_llm_recommendation_strategy(self, all_scenarios, patient_info, clinical_context,
                                                           min_rating, max_scenarios, max_recommendations_per_scenario):
        """ç­–ç•¥6: è§„åˆ™+LLMæ¨èé¡¹ç›®é‡æ’åº"""
        logger.info(f"ç­–ç•¥6-RULE_AND_LLM_RECOMMENDATION: è§„åˆ™é‡æ’åºåLLMæ¨èé¡¹ç›®é‡æ’åº")

        # ç¬¬ä¸€æ­¥ï¼šè§„åˆ™é‡æ’åº
        # è·å–è¿™äº›åœºæ™¯çš„æ¨èé¡¹ç›®
        scenario_with_recommendations = await self.get_scenarios_with_recommends(
            all_scenarios, max_scenarios, max_recommendations_per_scenario, min_rating
        )

        filter_scenario_with_recommendations = [scenario_with_recommendation for scenario_with_recommendation in
                                                scenario_with_recommendations if
                                                scenario_with_recommendation["recommendations"]]
        rule_ranked_scenarios = await self.hybrid_rank_scenarios(
            scenarios=filter_scenario_with_recommendations,
            patient_info=patient_info,
            clinical_context=clinical_context,
            top_k=max_scenarios,
            enable_llm=False
        )



        # ç¬¬äºŒæ­¥ï¼šLLMæ¨èé¡¹ç›®é‡æ’åº
        recommendations = await self.adaptive_recommendation_engine_service.get_recommendations(
            rule_ranked_scenarios, patient_info, clinical_context,
            max_recommendations_per_scenario, use_adaptive=True
        )

        return recommendations

    async def _handle_llm_scenario_and_recommendation_strategy(self, all_scenarios, patient_info, clinical_context,
                                                               min_rating, max_scenarios,
                                                               max_recommendations_per_scenario):
        """ç­–ç•¥7: LLMåœºæ™¯+æ¨èé¡¹ç›®é‡æ’åº"""
        logger.info(f"ç­–ç•¥7-LLM_SCENARIO_AND_RECOMMENDATION: LLMåœºæ™¯é‡æ’åº+æ¨èé¡¹ç›®é‡æ’åº")
        # å…ˆé€‰æ‹©å‰max_scenariosä¸ªåœºæ™¯
        ranked_scenarios = all_scenarios
        # è·å–æ‰€æœ‰åœºæ™¯çš„æ¨èé¡¹ç›®
        scenario_with_recommendations = await self.get_scenarios_with_recommends(
            ranked_scenarios, max_scenarios, max_recommendations_per_scenario, min_rating
        )

        filter_scenario_with_recommendations=[ scenario_with_recommendation for scenario_with_recommendation in scenario_with_recommendations if scenario_with_recommendation["recommendations"] ]

        # æ„å»ºæç¤ºè¯å¹¶æ£€æŸ¥tokenæ•°é‡
        prompt = self._build_comprehensive_prompt_with_grading(
            filter_scenario_with_recommendations, patient_info, clinical_context,
            max_scenarios, max_recommendations_per_scenario
        )

        token_nums = self.adaptive_recommendation_engine_service.estimate_tokens_with_tiktoken(prompt)
        threshold = self.adaptive_recommendation_engine_service.strategy.threshold_config["token_threshold"]

        if token_nums < threshold-200:
            logger.info(f"Tokenæ•°é‡({token_nums})å°äºé˜ˆå€¼({threshold})ï¼Œä½¿ç”¨å•æ¬¡LLMè°ƒç”¨")
            # å•æ¬¡LLMè°ƒç”¨åŒæ—¶å¤„ç†åœºæ™¯é€‰æ‹©å’Œæ¨èé¡¹ç›®åˆ†çº§
            return await self._llm_recommend_scenarios(
                filter_scenario_with_recommendations, prompt, patient_info,
                max_scenarios, max_recommendations_per_scenario
            )
        else:
            logger.info(f"Tokenæ•°é‡({token_nums})è¶…è¿‡é˜ˆå€¼({threshold})ï¼Œåˆ†å¼€å¤„ç†åœºæ™¯é€‰æ‹©å’Œæ¨èé¡¹ç›®")
            # åˆ†å¼€å¤„ç†ï¼šå…ˆLLMåœºæ™¯é‡æ’åºï¼Œå†LLMæ¨èé¡¹ç›®é‡æ’åº
            # ç¬¬ä¸€æ­¥ï¼šLLMåœºæ™¯é‡æ’åº
            llm_ranked_scenarios = await self.llm_rank_scenarios(
                filter_scenario_with_recommendations, patient_info, clinical_context, max_scenarios
            )

            # ç­›é€‰å‡ºå¯¹åº”çš„æ¨èæ•°æ®
            scenarios_id_set = {scenario["scenario_id"] for scenario in llm_ranked_scenarios}
            filtered_scenarios_with_recommends = [
                scenario_rec for scenario_rec in filter_scenario_with_recommendations
                if scenario_rec["scenario_id"] in scenarios_id_set
            ]

            # ç¬¬äºŒæ­¥ï¼šLLMæ¨èé¡¹ç›®é‡æ’åº
            recommendations = await self.adaptive_recommendation_engine_service.get_recommendations(
                filtered_scenarios_with_recommends, patient_info, clinical_context,
                max_recommendations_per_scenario, use_adaptive=True
            )

            return recommendations

    async def _handle_all_strategy(self, all_scenarios, patient_info, clinical_context,
                                   min_rating, max_scenarios, max_recommendations_per_scenario):
        """ç­–ç•¥8: å…¨éƒ¨å¯ç”¨ - è§„åˆ™é‡æ’åº + LLMåœºæ™¯é‡æ’åº + LLMæ¨èé¡¹ç›®é‡æ’åº"""
        logger.info(f"ç­–ç•¥8-ALL: è§„åˆ™é‡æ’åº + LLMåœºæ™¯é‡æ’åº + LLMæ¨èé¡¹ç›®é‡æ’åº")

        # ç¬¬ä¸€æ­¥ï¼šè§„åˆ™é‡æ’åºï¼ˆå®½æ¾ä¸€äº›ï¼‰
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ç­–ç•¥7çš„é€»è¾‘å¤„ç†LLMåœºæ™¯+æ¨èé¡¹ç›®é‡æ’åº
        scenario_with_recommendations = await self.get_scenarios_with_recommends(
            all_scenarios, max_scenarios, max_recommendations_per_scenario, min_rating
        )

        filter_scenario_with_recommendations = [scenario_with_recommendation for scenario_with_recommendation in
                                                scenario_with_recommendations if
                                                scenario_with_recommendation["recommendations"]]
        ranked_scenarios = await self.hybrid_rank_scenarios(
            scenarios=filter_scenario_with_recommendations,
            patient_info=patient_info,
            clinical_context=clinical_context,
            top_k=max_scenarios,
            enable_llm=True
        )

        # æ„å»ºæç¤ºè¯å¹¶æ£€æŸ¥tokenæ•°é‡
        # prompt = self._build_comprehensive_prompt_with_grading(
        #     final_scenario_with_recommendations, patient_info, clinical_context,
        #     max_scenarios, max_recommendations_per_scenario
        # )
        #
        # token_nums = self.adaptive_recommendation_engine_service.estimate_tokens_with_tiktoken(prompt)
        # threshold = self.adaptive_recommendation_engine_service.strategy.threshold_config["token_threshold"]

        # if token_nums < threshold:
        #     logger.info(f"Tokenæ•°é‡({token_nums})å°äºé˜ˆå€¼({threshold})ï¼Œä½¿ç”¨å•æ¬¡LLMè°ƒç”¨")
        #     # å•æ¬¡LLMè°ƒç”¨åŒæ—¶å¤„ç†åœºæ™¯é€‰æ‹©å’Œæ¨èé¡¹ç›®åˆ†çº§
        #     return await self._llm_recommend_scenarios(
        #         final_scenario_with_recommendations, prompt, patient_info,
        #         max_scenarios, max_recommendations_per_scenario
        #     )
        # else:
        # logger.info(f"Tokenæ•°é‡({token_nums})è¶…è¿‡é˜ˆå€¼({threshold})ï¼Œåˆ†å¼€å¤„ç†åœºæ™¯é€‰æ‹©å’Œæ¨èé¡¹ç›®")
            # åˆ†å¼€å¤„ç†ï¼šå…ˆLLMåœºæ™¯é‡æ’åºï¼Œå†LLMæ¨èé¡¹ç›®é‡æ’åº
            # ç¬¬ä¸€æ­¥ï¼šLLMåœºæ™¯é‡æ’åº
            # llm_ranked_scenarios = await self.llm_rank_scenarios(
            #     filter_scenario_with_recommendations, patient_info, clinical_context, max_scenarios
            # )
            #
            # # ç­›é€‰å‡ºå¯¹åº”çš„æ¨èæ•°æ®
            # scenarios_id_set = {scenario["scenario_id"] for scenario in llm_ranked_scenarios}
            # filtered_scenarios_with_recommends = [
            #     scenario_rec for scenario_rec in filter_scenario_with_recommendations
            #     if scenario_rec["scenario_id"] in scenarios_id_set
            # ]

            # ç¬¬äºŒæ­¥ï¼šLLMæ¨èé¡¹ç›®é‡æ’åº
        recommendations = await self.adaptive_recommendation_engine_service.get_recommendations(
                ranked_scenarios, patient_info, clinical_context,
                max_recommendations_per_scenario, use_adaptive=True
        )

        return recommendations









    # async def _llm_evaluate_single_scenario(
    #             self,
    #             scenario_data: Dict[str, Any],
    #             patient_info: PatientInfo,
    #             clinical_context: ClinicalContext,
    #             top_k: int = 3
    #     ) -> Dict[str, Any]:
    #         """
    #         ä½¿ç”¨LLMè¯„ä¼°å•ä¸ªåœºæ™¯ï¼ŒåŠ¨æ€é€‰æ‹©top_kä¸ªæœ€ä½³æ¨èå¹¶è®¡ç®—ç»¼åˆè¯„åˆ†
    #
    #         Args:
    #             scenario_data: å•ä¸ªåœºæ™¯æ•°æ®ï¼ˆåŒ…å«åœºæ™¯å’Œæ¨èåˆ—è¡¨ï¼‰
    #             patient_info: æ‚£è€…ä¿¡æ¯
    #             clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡
    #             top_k: éœ€è¦è¿”å›çš„æœ€ä½³æ¨èæ•°é‡
    #
    #         Returns:
    #             åŒ…å«åˆ†çº§æ¨èå’Œç»¼åˆè¯„åˆ†çš„ç»“æœ
    #         """
    #         scenario = scenario_data['scenario']
    #         recommendations = scenario_data.get('recommendations', [])
    #
    #         if not recommendations:
    #             logger.warning(f"åœºæ™¯{scenario.semantic_id}æ²¡æœ‰æ¨èé¡¹ç›®")
    #             return None
    #
    #         # åŠ¨æ€è°ƒæ•´top_kï¼Œç¡®ä¿ä¸è¶…è¿‡æ¨èé¡¹ç›®æ€»æ•°
    #         actual_top_k = min(top_k, len(recommendations))
    #
    #         # å®‰å…¨è·å–ç§‘å®¤åç§°
    #         try:
    #             panel_name = scenario.panel.name_zh if hasattr(scenario, 'panel') and scenario.panel else 'æœªçŸ¥'
    #         except Exception:
    #             panel_name = 'æœªçŸ¥'
    #
    #         # æ„å»ºæ¨èé¡¹ç›®åˆ—è¡¨æ–‡æœ¬
    #         recommendation_texts = []
    #         rec_index_map = {}  # {index: rec_data}
    #
    #         for idx, rec_data in enumerate(recommendations, 1):
    #             recommendation = rec_data['recommendation']
    #             procedure = rec_data['procedure']
    #
    #             rec_text = f"""æ¨èé¡¹ç›®{idx}:
    # - æ£€æŸ¥åç§°: {procedure.name_zh}
    # - æ£€æŸ¥æ–¹å¼: {procedure.modality or 'æœªçŸ¥'}
    # - æ£€æŸ¥éƒ¨ä½: {procedure.body_part or 'æœªçŸ¥'}
    # - ACRé€‚å®œæ€§è¯„åˆ†: {recommendation.appropriateness_rating}/9
    # - é€‚å®œæ€§ç±»åˆ«: {recommendation.appropriateness_category_zh or 'æœªçŸ¥'}
    # - æ˜¯å¦ä½¿ç”¨å¯¹æ¯”å‰‚: {'æ˜¯' if procedure.contrast_used else 'å¦'}
    # - è¾å°„ç­‰çº§: {procedure.radiation_level or 'æ— '}
    # - æ¨èç†ç”±: {recommendation.reasoning_zh[:100] if recommendation.reasoning_zh else 'æ— '}
    # - ç‰¹æ®Šè€ƒè™‘: {recommendation.special_considerations[:100] if recommendation.special_considerations else 'æ— '}
    # - å¦Šå¨ å®‰å…¨æ€§: {recommendation.pregnancy_safety or 'æœªçŸ¥'}
    # """
    #             recommendation_texts.append(rec_text)
    #             rec_index_map[idx] = rec_data
    #
    #         # æ„å»ºæ‚£è€…ä¿¡æ¯
    #         patient_text = f"""æ‚£è€…ä¿¡æ¯:
    # - å¹´é¾„: {patient_info.age}å²
    # - æ€§åˆ«: {patient_info.gender}
    # - å¦Šå¨ çŠ¶æ€: {patient_info.pregnancy_status or 'éå¦Šå¨ æœŸ'}
    # - è¿‡æ•å²: {', '.join(patient_info.allergies) if patient_info.allergies else 'æ— '}
    # - åˆå¹¶ç—‡: {', '.join(patient_info.comorbidities) if patient_info.comorbidities else 'æ— '}
    # - æ£€æŸ¥æŠ¥å‘Š: {patient_info.physical_examination or 'æ— '}
    #
    # ä¸´åºŠä¿¡æ¯:
    # - ç§‘å®¤: {clinical_context.department}
    # - ä¸»è¯‰: {clinical_context.chief_complaint}
    # - æ—¢å¾€ç—…å²: {clinical_context.medical_history or 'æ— '}
    # - ç°ç—…å²: {clinical_context.present_illness or 'æ— '}
    # - ä¸»è¯Šæ–­ç»“æœ: {clinical_context.diagnosis or 'å¾…è¯Šæ–­'}
    # - ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦: {clinical_context.symptom_severity or 'æœªçŸ¥'}
    # - ç—‡çŠ¶æŒç»­æ—¶é—´: {clinical_context.symptom_duration or 'æœªçŸ¥'}
    # """
    #
    #         # æ„å»ºåœºæ™¯ä¿¡æ¯
    #         scenario_text = f"""ä¸´åºŠåœºæ™¯:
    # - åœºæ™¯æè¿°: {scenario.description_zh}
    # - ç§‘å®¤: {panel_name}
    # - é€‚ç”¨äººç¾¤: {scenario.patient_population or 'æœªçŸ¥'}
    # - ä¸´åºŠèƒŒæ™¯: {scenario.clinical_context or 'æœªçŸ¥'}
    # """
    #         recommendation_text = "\n".join(recommendation_texts)
    #
    #         # æ„å»ºPrompt - ä¿®æ”¹ä¸ºåŠ¨æ€é€‰æ‹©top_k
    #         prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿã€‚è¯·æ ¹æ®ä»¥ä¸‹æ‚£è€…ä¿¡æ¯å’Œä¸´åºŠåœºæ™¯ï¼Œä»æ¨èé¡¹ç›®ä¸­é€‰æ‹©æœ€é€‚åˆçš„{actual_top_k}ä¸ªæ£€æŸ¥ã€‚
    #
    # {patient_text}
    #
    # {scenario_text}
    #
    # å¯é€‰æ¨èé¡¹ç›®ï¼š
    # {recommendation_text}
    #
    # è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
    #
    # 1. **é€‰æ‹©æœ€ä½³æ¨è**ï¼š
    #    - è¯·é€‰æ‹©æœ€é€‚åˆæ‚£è€…çš„{actual_top_k}ä¸ªæ£€æŸ¥ï¼ŒæŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½æ’åº
    #    - è€ƒè™‘å› ç´ ï¼šACRè¯„åˆ†ã€ä¸´åºŠéœ€æ±‚åŒ¹é…åº¦ã€æ‚£è€…å®‰å…¨æ€§ã€æ£€æŸ¥å¯è¡Œæ€§
    #
    # 2. **ç»¼åˆè¯„åˆ†** (0-100åˆ†)ï¼š
    #    - è¯„ä¼°è¯¥åœºæ™¯ä¸æ‚£è€…æƒ…å†µçš„æ€»ä½“åŒ¹é…åº¦
    #    - è€ƒè™‘å› ç´ ï¼šåœºæ™¯æè¿°åŒ¹é…ã€é€‚ç”¨äººç¾¤åŒ¹é…ã€ç§‘å®¤å¯¹åº”ã€æ¨èé¡¹ç›®è´¨é‡
    #
    # 3. **æ¨ç†è¯´æ˜**ï¼ˆä¸è¶…è¿‡150å­—ï¼‰ï¼š
    #    - ç®€è¦è¯´æ˜é€‰æ‹©ç†ç”±å’Œæ’åºä¾æ®
    #    - è§£é‡Šç»¼åˆè¯„åˆ†çš„ä¾æ®
    #
    # è¯·ç›´æ¥è¾“å‡ºJSONæ ¼å¼ç»“æœï¼Œè¿™æ˜¯ä¸€ä¸ªä¾‹å­ï¼š
    # {{
    #     "top_k_indices": [1, 3, 2],
    #     "comprehensive_score": è¿™é‡Œæ˜¯ç»¼åˆçš„åˆ†æ•°,
    #     "reasoning": "ç®€çŸ­è¯´æ˜ï¼Œä¸è¶…150å­—"
    # }}
    #
    # è¦æ±‚ï¼š
    # - å¿…é¡»é€‰æ‹©{actual_top_k}ä¸ªä¸åŒçš„æ¨èé¡¹ç›®ç´¢å¼•ï¼ŒæŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½æ’åˆ—
    # - ç»¼åˆè¯„åˆ†å¿…é¡»ä¸º0-100ä¹‹é—´çš„æ•´æ•°
    # - æ¨ç†è¯´æ˜å¿…é¡»ç®€æ´ï¼Œä¸¥æ ¼ä¸è¶…è¿‡150ä¸ªä¸­æ–‡å­—ç¬¦
    # - ä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæ–‡å­—ï¼Œåªè¾“å‡ºJSONï¼Œç¡®ä¿JSONå®Œæ•´
    # """
    #
    #         # è°ƒç”¨LLM
    #         response = await self.ai_service._call_llm(prompt)
    #
    #         # è§£æJSONç»“æœ
    #         import re
    #         import json
    #
    #         json_match = re.search(r'\{.*\}', response, re.DOTALL)
    #         if not json_match:
    #             logger.error(f"åœºæ™¯{scenario.semantic_id} LLMè¿”å›æ ¼å¼é”™è¯¯")
    #             return None
    #
    #         try:
    #             result = json.loads(json_match.group())
    #         except json.JSONDecodeError:
    #             logger.error(f"åœºæ™¯{scenario.semantic_id} LLMè¿”å›JSONè§£æé”™è¯¯")
    #             return None
    #
    #         # æå–ç»“æœ
    #         top_k_indices = result.get('top_k_indices', [])
    #         comprehensive_score = result.get('comprehensive_score', 0)
    #         reasoning = result.get('reasoning', '')
    #
    #         # éªŒè¯ç´¢å¼•æ•°é‡å’Œæœ‰æ•ˆæ€§
    #         if len(top_k_indices) < actual_top_k:
    #             logger.warning(f"åœºæ™¯{scenario.semantic_id} LLMè¿”å›çš„æ¨èæ•°é‡ä¸è¶³{actual_top_k}ä¸ª")
    #             # å¦‚æœè¿”å›æ•°é‡ä¸è¶³ï¼Œåªå–æœ‰æ•ˆçš„éƒ¨åˆ†
    #             valid_indices = [idx for idx in top_k_indices if idx in rec_index_map]
    #         else:
    #             valid_indices = top_k_indices[:actual_top_k]
    #
    #         if not valid_indices:
    #             logger.warning(f"åœºæ™¯{scenario.semantic_id} LLMæœªè¿”å›æœ‰æ•ˆçš„æ¨èé¡¹ç›®")
    #             return None
    #
    #         # æ„å»ºtop_kæ¨èåˆ—è¡¨
    #         top_k_recommendations = []
    #         for idx in valid_indices:
    #             if idx in rec_index_map:
    #                 top_k_recommendations.append(rec_index_map[idx])
    #             else:
    #                 logger.warning(f"åœºæ™¯{scenario.semantic_id} æ— æ•ˆçš„æ¨èç´¢å¼•: {idx}")
    #
    #         # æ„å»ºè¿”å›ç»“æœ - ä¿®æ”¹ä¸ºåŠ¨æ€çš„top_kç»“æ„
    #         return {
    #             'comprehensive_score': comprehensive_score,
    #             'reasoning': reasoning,
    #             'top_k_recommendations': top_k_recommendations,
    #             'recommendation_count': len(top_k_recommendations),
    #             'requested_top_k': actual_top_k,
    #             'scenario_metadata': {
    #                 'scenario_id': scenario.semantic_id,
    #                 'description': scenario.description_zh,
    #                 'llm_rank': scenario_data.get('llm_rank'),
    #                 'selection_source': scenario_data.get('selection_source_by_llm') or scenario_data.get(
    #                     'selection_source_by_rule'),
    #                 'panel': panel_name
    #             }
    #         }
    async def _llm_evaluate_single_scenario(
        self,
        scenario_data: Dict[str, Any],
        patient_info: PatientInfo,
        clinical_context: ClinicalContext,
        top_k: int = 3
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMè¯„ä¼°å•ä¸ªåœºæ™¯ï¼Œé€‰æ‹©åˆ†çº§æ¨èå¹¶è®¡ç®—ç»¼åˆè¯„åˆ†

        Args:
            scenario_data: å•ä¸ªåœºæ™¯æ•°æ®ï¼ˆåŒ…å«åœºæ™¯å’Œæ¨èåˆ—è¡¨ï¼‰
            patient_info: æ‚£è€…ä¿¡æ¯
            clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡

        Returns:
            åŒ…å«åˆ†çº§æ¨èå’Œç»¼åˆè¯„åˆ†çš„ç»“æœ
        """
        scenario = scenario_data['scenario']
        recommendations = scenario_data.get('recommendations', [])

        if not recommendations:
            logger.warning(f"åœºæ™¯{scenario.semantic_id}æ²¡æœ‰æ¨èé¡¹ç›®")
            return None

        # å®‰å…¨è·å–ç§‘å®¤åç§°
        try:
            panel_name = scenario.panel.name_zh if hasattr(scenario, 'panel') and scenario.panel else 'æœªçŸ¥'
        except Exception:
            panel_name = 'æœªçŸ¥'

        # æ„å»ºæ¨èé¡¹ç›®åˆ—è¡¨æ–‡æœ¬
        recommendation_texts = []
        rec_index_map = {}  # {index: rec_data}

        for idx, rec_data in enumerate(recommendations, 1):
            recommendation = rec_data['recommendation']
            procedure = rec_data['procedure']

            rec_text = f"""æ¨èé¡¹ç›®{idx}:
- æ£€æŸ¥åç§°: {procedure.name_zh}
- æ£€æŸ¥æ–¹å¼: {procedure.modality or 'æœªçŸ¥'}
- æ£€æŸ¥éƒ¨ä½: {procedure.body_part or 'æœªçŸ¥'}
- ACRé€‚å®œæ€§è¯„åˆ†: {recommendation.appropriateness_rating}/9
- é€‚å®œæ€§ç±»åˆ«: {recommendation.appropriateness_category_zh or 'æœªçŸ¥'}
- æ˜¯å¦ä½¿ç”¨å¯¹æ¯”å‰‚: {'æ˜¯' if procedure.contrast_used else 'å¦'}
- è¾å°„ç­‰çº§: {procedure.radiation_level or 'æ— '}
- æ¨èç†ç”±: {recommendation.reasoning_zh[:100] if recommendation.reasoning_zh else 'æ— '}
- ç‰¹æ®Šè€ƒè™‘: {recommendation.special_considerations[:100] if recommendation.special_considerations else 'æ— '}
- å¦Šå¨ å®‰å…¨æ€§: {recommendation.pregnancy_safety or 'æœªçŸ¥'}
"""
            recommendation_texts.append(rec_text)
            rec_index_map[idx] = rec_data

        # æ„å»ºæ‚£è€…ä¿¡æ¯
        patient_text = f"""æ‚£è€…ä¿¡æ¯:
- å¹´é¾„: {patient_info.age}å²
- æ€§åˆ«: {patient_info.gender}
- å¦Šå¨ çŠ¶æ€: {patient_info.pregnancy_status or 'éå¦Šå¨ æœŸ'}
- è¿‡æ•å²: {', '.join(patient_info.allergies) if patient_info.allergies else 'æ— '}
- åˆå¹¶ç—‡: {', '.join(patient_info.comorbidities) if patient_info.comorbidities else 'æ— '}
- æ£€æŸ¥æŠ¥å‘Š: {patient_info.physical_examination or 'æ— '}

ä¸´åºŠä¿¡æ¯:
- ç§‘å®¤: {clinical_context.department}
- ä¸»è¯‰: {clinical_context.chief_complaint}
- æ—¢å¾€ç—…å²: {clinical_context.medical_history or 'æ— '}
- ç°ç—…å²: {clinical_context.present_illness or 'æ— '}
- ä¸»è¯Šæ–­ç»“æœ: {clinical_context.diagnosis or 'å¾…è¯Šæ–­'}
- ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦: {clinical_context.symptom_severity or 'æœªçŸ¥'}
- ç—‡çŠ¶æŒç»­æ—¶é—´: {clinical_context.symptom_duration or 'æœªçŸ¥'}
"""

        # æ„å»ºåœºæ™¯ä¿¡æ¯
        scenario_text = f"""ä¸´åºŠåœºæ™¯:
- åœºæ™¯æè¿°: {scenario.description_zh}
- ç§‘å®¤: {panel_name}
- é€‚ç”¨äººç¾¤: {scenario.patient_population or 'æœªçŸ¥'}
- ä¸´åºŠèƒŒæ™¯: {scenario.clinical_context or 'æœªçŸ¥'}
"""
        recommendation_text="\n".join(recommendation_texts)
        # æ„å»ºPrompt
        prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿã€‚è¯·æ ¹æ®ä»¥ä¸‹æ‚£è€…ä¿¡æ¯å’Œä¸´åºŠåœºæ™¯ï¼Œä»æ¨èé¡¹ç›®ä¸­é€‰æ‹©æœ€é€‚åˆçš„æ£€æŸ¥ã€‚

{patient_text}

{scenario_text}

å¯é€‰æ¨èé¡¹ç›®ï¼š
{recommendation_text}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. **é€‰æ‹©åˆ†çº§æ¨è**ï¼š
   - æå…¶æ¨èï¼šé€‰æ‹©1é¡¹æœ€é€‚åˆæ‚£è€…çš„æ£€æŸ¥ï¼ˆè€ƒè™‘ACRè¯„åˆ†ã€å®‰å…¨æ€§ã€ä¸´åºŠéœ€æ±‚ï¼‰
   - æ¨èï¼šé€‰æ‹©1é¡¹æ¬¡ä¼˜é€‰çš„æ£€æŸ¥
   - æ…é‡è€ƒè™‘ï¼šé€‰æ‹©1é¡¹éœ€è°¨æ…è€ƒè™‘çš„æ£€æŸ¥ï¼ˆå¦‚æœ‰é£é™©ä½†å¯èƒ½æœ‰ç”¨ï¼‰

2. **ç»¼åˆè¯„åˆ†** (0-100åˆ†)ï¼š
   - è¯„ä¼°è¯¥åœºæ™¯ä¸æ‚£è€…æƒ…å†µçš„æ€»ä½“åŒ¹é…åº¦
   - è€ƒè™‘å› ç´ ï¼šåœºæ™¯æè¿°åŒ¹é…ã€é€‚ç”¨äººç¾¤åŒ¹é…ã€ç§‘å®¤å¯¹åº”ã€æ¨èé¡¹ç›®è´¨é‡

3. **æ¨ç†è¯´æ˜**ï¼ˆä¸è¶…è¿‡150å­—ï¼‰ï¼š
   - ç®€è¦è¯´æ˜é€‰æ‹©ç†ç”±
   - è§£é‡Šç»¼åˆè¯„åˆ†çš„ä¾æ®

è¯·ç›´æ¥è¾“å‡ºJSONæ ¼å¼ç»“æœï¼Œè¿™æ˜¯ä¸€ä¸ªä¾‹å­ï¼š
{{
    "highly_recommended_index": 1,
    "recommended_index": 3,
    "cautiously_considered_index": 5,
    "comprehensive_score": 85,
    "reasoning": "ç®€çŸ­è¯´æ˜ï¼Œä¸è¶…150å­—"
}}

è¦æ±‚ï¼š
- å¿…é¡»é€‰æ‹©3ä¸ªä¸åŒçš„æ¨èé¡¹ç›®ç´¢å¼•
- ç»¼åˆè¯„åˆ†å¿…é¡»ä¸º0-100ä¹‹é—´çš„æ•´æ•°
- æ¨ç†è¯´æ˜å¿…é¡»ç®€æ´ï¼Œä¸¥æ ¼ä¸è¶…è¿‡150ä¸ªä¸­æ–‡å­—ç¬¦
- ä¸è¦è¾“å‡ºå…¶ä»–è§£é‡Šæ–‡å­—ï¼Œåªè¾“å‡ºJSONï¼Œç¡®ä¿JSONå®Œæ•´
"""

        # è°ƒç”¨LLM
        response = await self.ai_service._call_llm(prompt)

        # è§£æJSONç»“æœ
        import re
        import json

        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if not json_match:
            logger.error(f"åœºæ™¯{scenario.semantic_id} LLMè¿”å›æ ¼å¼é”™è¯¯")
            return None

        result = json.loads(json_match.group())

        # æå–ç»“æœ
        highly_recommended_idx = result.get('highly_recommended_index')
        recommended_idx = result.get('recommended_index')
        cautiously_idx = result.get('cautiously_considered_index')
        comprehensive_score = result.get('comprehensive_score', 0)
        reasoning = result.get('reasoning', '')

        # éªŒè¯ç´¢å¼•
        if not all([highly_recommended_idx, recommended_idx, cautiously_idx]):
            logger.warning(f"åœºæ™¯{scenario.semantic_id} LLMæœªè¿”å›å®Œæ•´çš„æ¨èé¡¹ç›®")
            return None

        # æ„å»ºè¿”å›ç»“æœ
        return {
            'comprehensive_score': comprehensive_score,
            'reasoning': reasoning,
            'recommendations_by_level': {
                'highly_recommended': [rec_index_map.get(highly_recommended_idx)] if highly_recommended_idx in rec_index_map else [],
                'recommended': [rec_index_map.get(recommended_idx)] if recommended_idx in rec_index_map else [],
                'cautiously_considered': [rec_index_map.get(cautiously_idx)] if cautiously_idx in rec_index_map else []
            },
            'scenario_metadata': {
                'scenario_id': scenario.semantic_id,
                'description': scenario.description_zh,
                'llm_rank': scenario_data.get('llm_rank'),
                'selection_source': scenario_data.get('selection_source_by_llm') or scenario_data.get('selection_source_by_rule'),
                'panel': panel_name
            }
        }
    

    
    def _select_best_from_category(
        self,
        category_recommendations: List[Dict],
        patient_info: PatientInfo,
        clinical_context: ClinicalContext,
        top_n: int = 1
    ) -> List[Dict[str, Any]]:
        """
        ä»æŸä¸ªç­‰çº§çš„æ¨èä¸­é€‰æ‹©æœ€ä½³çš„Né¡¹
        
        é€‰æ‹©é€»è¾‘ï¼š
        1. è¿‡æ»¤ä¸å®‰å…¨çš„æ£€æŸ¥ï¼ˆå¦Šå¨ +è¾å°„ã€è¿‡æ•+é€ å½±å‰‚ï¼‰
        2. æŒ‰ACRè¯„åˆ†æ’åº
        3. è¿”å›top_n
        """
        if not category_recommendations:
            return []
        
        safe_recommendations = []
        
        for rec in category_recommendations:
            # å®‰å…¨æ€§æ£€æŸ¥
            is_safe = True
            
            # å¦Šå¨ å¦‡å¥³é¿å…è¾å°„
            if patient_info.pregnancy_status and 'å¦Š' in patient_info.pregnancy_status:
                if rec['radiation'] and rec['radiation'] != 'æ— ' and rec['radiation'] != 'ä½':
                    is_safe = False
            
            # è¿‡æ•å²é¿å…é€ å½±å‰‚
            if patient_info.allergies and 'é€ å½±å‰‚' in str(patient_info.allergies):
                if rec['contrast'] == 'æ˜¯':
                    is_safe = False
            
            if is_safe:
                safe_recommendations.append(rec)
        
        # å¦‚æœæ‰€æœ‰æ¨èéƒ½è¢«è¿‡æ»¤ï¼Œè¿”å›åŸå§‹åˆ—è¡¨
        if not safe_recommendations:
            safe_recommendations = category_recommendations
        
        # æŒ‰è¯„åˆ†æ’åº
        safe_recommendations.sort(key=lambda x: x['rating'], reverse=True)
        
        # è¿”å›top_nçš„å®Œæ•´æ•°æ®
        return [rec['rec_data'] for rec in safe_recommendations[:top_n]]

    async def get_scenarios_with_recommends(
            self,
            all_scenarios: List[Dict[str, Any]],
            max_scenarios: int,
            max_recommendations_per_scenario: int,
            min_rating: int = None
    ):
        semaphore = asyncio.Semaphore(8)
        # è®¾ç½®å•ä¸ªä»»åŠ¡çš„è¶…æ—¶æ—¶é—´ï¼ˆä¾‹å¦‚30ç§’ï¼‰
        timeout_duration = 30

        async def get_recommendations_with_semaphore(scenario_data):
            async with semaphore:
                try:
                    scenario = scenario_data['scenario']
                    buffer_multiplier = 2
                    candidate_cap = max(
                        max_recommendations_per_scenario * (max_scenarios + buffer_multiplier),
                        max_recommendations_per_scenario * 2
                    )
                    top_k = min(candidate_cap, 50)

                    # ä½¿ç”¨è¶…æ—¶åŒ…è£…
                    try:
                        recommendations = await asyncio.wait_for(
                            self.get_scenario_recommendations(
                                scenario_id=scenario.semantic_id,
                                top_k=top_k,
                                min_rating=min_rating or 5
                            ),
                            timeout=timeout_duration
                        )
                        return scenario_data, recommendations
                    except asyncio.TimeoutError:
                        logger.error(f"è·å–åœºæ™¯ {scenario.semantic_id} æ¨èè¶…æ—¶ï¼Œè¶…è¿‡ {timeout_duration} ç§’")
                        return scenario_data, []

                except Exception as e:
                    logger.error(
                        f"è·å–åœºæ™¯ {scenario_data.get('scenario', {}).get('semantic_id', 'unknown')} æ¨èæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    return scenario_data, []

        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [get_recommendations_with_semaphore(scenario_data) for scenario_data in all_scenarios]

        # å¹¶å‘æ‰§è¡Œï¼Œæ•è·æ‰€æœ‰å¼‚å¸¸
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ç»“æœï¼Œåˆ†ç¦»æ­£å¸¸ç»“æœå’Œå¼‚å¸¸
        scenarios_with_recommendations = []
        successful_count = 0
        failed_count = 0

        for result in results:
            if isinstance(result, Exception):
                # å¤„ç†å¼‚å¸¸æƒ…å†µ
                failed_count += 1
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {result}")
                continue

            scenario_data, recommendations = result
            scenario = scenario_data['scenario']

            scenarios_with_recommendations.append({
                'scenario': scenario,
                'scenario_id':scenario.id,
                'semantic_id': scenario.semantic_id,
                'scenario_description': scenario.description_zh,
                'patient_population': scenario.patient_population,
                'clinical_context': scenario.clinical_context,

                'final_score': scenario_data.get('final_score', 0),
                'semantic_score': scenario_data.get('semantic_score', 0),
                'keyword_score': scenario_data.get('jieba_score', 0),
                'rule_score': scenario_data.get('rule_score', 0),
                'llm_rank': scenario_data.get('llm_rank', None),
                'selection_source': scenario_data.get('selection_source_by_llm', 'Unknown') or scenario_data.get(
                        'selection_source_by_rule', 'Unknown'),

                'llm_reasoning': scenario_data.get('llm_reasoning', ''),
                'recommendations': recommendations,
                'recommendation_count': len(recommendations)
            })
            successful_count += 1

        total_recommendations = sum(len(s['recommendations']) for s in scenarios_with_recommendations)
        logger.info(
            f"ğŸ“Š å…±è·å– {total_recommendations} æ¡æ¨èé¡¹ç›®ï¼ˆæ¥è‡ª{successful_count}ä¸ªæˆåŠŸåœºæ™¯ï¼Œ{failed_count}ä¸ªå¤±è´¥åœºæ™¯ï¼‰")

        return scenarios_with_recommendations


    async def _llm_recommend_scenarios(self, all_scenarios, prompt,patient_info,max_scenarios,
                                       max_recommendations_per_scenarios):
           # scenario_with_recommendations = await self.get_screnarios_with_recommends(all_scenarios,max_scenarios,max_recommendations_per_scenario, min_rating)
           #å¼€å§‹è®©llmæ ¹æ®ç—…ç—‡åšæ¨è
           # prompt=self._build_comprehensive_prompt_with_grading(scenario_with_recommendations, patient_info, clinical_context,max_scenarios,max_recommendations_per_scenario)
           try:
               # å•æ¬¡LLMè°ƒç”¨
               response = await self.ai_service._call_llm(prompt)

               # è§£æJSONç»“æœ
               import re
               import json

               json_match = re.search(r'\{.*\}', response, re.DOTALL)
               if not json_match:
                   logger.error("LLMè¿”å›æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                   return self._fallback_comprehensive_selection_with_grading(all_scenarios, max_scenarios, patient_info)

               try:
                   result = json.loads(json_match.group())
               except json.JSONDecodeError as e:
                   logger.error(f"JSONè§£æé”™è¯¯: {e}")
                   return self._fallback_comprehensive_selection_with_grading(all_scenarios, max_scenarios, patient_info)

               # å¤„ç†é€‰ä¸­çš„åœºæ™¯å’Œåˆ†çº§æ¨è
               selected_scenarios_data = result.get('selected_scenarios', [])
               final_results = []

               for selected_data in selected_scenarios_data:
                   scenario_index = selected_data.get('scenario_index')
                   scenario_id = selected_data.get('scenario_id')
                   grading_data = selected_data.get('recommendation_grades', {})

                   # éªŒè¯åœºæ™¯ç´¢å¼•
                   if not (1 <= scenario_index <= len(all_scenarios)):
                       logger.warning(f"æ— æ•ˆçš„åœºæ™¯ç´¢å¼•: {scenario_index}")
                       continue

                   original_scenario_data = all_scenarios[scenario_index - 1]
                   original_recommendations = original_scenario_data.get('recommendations', [])
                   scenario = original_scenario_data['scenario']

                   # æŒ‰æ¨èç­‰çº§ç»„ç»‡æ¨èé¡¹ç›®
                   graded_recommendations = {
                       "highly_recommended": [],
                       "recommended": [],
                       "less_recommended": []
                   }

                   # å¤„ç†å„ç­‰çº§æ¨èé¡¹ç›®
                   recommendation_levels = [
                       ('highly_recommended', 'æå…¶æ¨è'),
                       ('recommended', 'æ¨è'),
                       ('less_recommended', 'ä¸å¤ªæ¨è')
                   ]

                   for level_key, level_zh in recommendation_levels:
                       for rec_idx in grading_data.get(level_key, []):
                           if 1 <= rec_idx <= len(original_recommendations):
                               rec_data = original_recommendations[rec_idx - 1].copy()
                               rec_data['recommendation_level'] = level_key
                               rec_data['recommendation_level_zh'] = level_zh

                               # æ·»åŠ å®Œæ•´çš„æ£€æŸ¥é¡¹ç›®ä¿¡æ¯
                               procedure = rec_data['procedure']
                               recommendation = rec_data['recommendation']

                               # æ„å»ºè¯¦ç»†çš„æ£€æŸ¥é¡¹ç›®ä¿¡æ¯
                               rec_data['procedure_details'] = {
                                   'semantic_id': procedure.semantic_id,
                                   'name_zh': procedure.name_zh,
                                   'name_en': procedure.name_en,
                                   'modality': procedure.modality,
                                   'body_part': procedure.body_part,
                                   'contrast_used': procedure.contrast_used,
                                   'radiation_level': procedure.radiation_level,
                                   'exam_duration': procedure.exam_duration,
                                   'preparation_required': procedure.preparation_required,
                                   'standard_code': procedure.standard_code,
                                   'description_zh': procedure.description_zh
                               }

                               # æ„å»ºè¯¦ç»†çš„æ¨èä¿¡æ¯
                               rec_data['recommendation_details'] = {
                                   'appropriateness_rating': recommendation.appropriateness_rating,
                                   'appropriateness_category_zh': recommendation.appropriateness_category_zh,
                                   'evidence_level': recommendation.evidence_level,
                                   'consensus_level': recommendation.consensus_level,
                                   'adult_radiation_dose': recommendation.adult_radiation_dose,
                                   'pediatric_radiation_dose': recommendation.pediatric_radiation_dose,
                                   'pregnancy_safety': recommendation.pregnancy_safety,
                                   'contraindications': recommendation.contraindications,
                                   'reasoning_zh': recommendation.reasoning_zh,
                                   'special_considerations': recommendation.special_considerations
                               }

                               graded_recommendations[level_key].append(rec_data)
                           else:
                               logger.warning(f"åœºæ™¯{scenario_index}çš„æ— æ•ˆ{level_zh}ç´¢å¼•: {rec_idx}")

                   # æ„å»ºè¿”å›ç»“æœ
                   final_results.append({
                       'comprehensive_score': selected_data.get('comprehensive_score', 0),
                       'scenario_reasoning': selected_data.get('scenario_reasoning', ''),
                       'grading_reasoning': selected_data.get('grading_reasoning', ''),
                       'overall_reasoning': result.get('overall_reasoning', ''),
                       'graded_recommendations': graded_recommendations,
                       'recommendation_summary': {
                           'highly_recommended_count': len(graded_recommendations['highly_recommended']),
                           'recommended_count': len(graded_recommendations['recommended']),
                           'less_recommended_count': len(graded_recommendations['less_recommended']),
                           'total_recommendations': len(original_recommendations)
                       },
                       'scenario_metadata': {
                           'scenario_id': scenario_id or scenario.semantic_id,
                           'description': scenario.description_zh,
                           'panel': scenario.panel.name_zh if hasattr(scenario, 'panel') else 'æœªçŸ¥',
                           'patient_population': scenario.patient_population,
                           'clinical_context': scenario.clinical_context,
                           'original_index': scenario_index
                       }
                   })

               # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
               final_results.sort(key=lambda x: x['comprehensive_score'], reverse=True)

               # è®°å½•è¯¦ç»†çš„åˆ†çº§ç»Ÿè®¡
               logger.info(f"âœ… å•æ¬¡LLMè°ƒç”¨å®Œæˆï¼Œé€‰å‡º{len(final_results)}ä¸ªæœ€ä½³åœºæ™¯")
               for idx, result in enumerate(final_results, 1):
                   summary = result['recommendation_summary']
                   metadata = result['scenario_metadata']
                   logger.info(
                       f"  åœºæ™¯#{idx}: {metadata['description'][:50]}... | "
                       f"è¯„åˆ†={result['comprehensive_score']} | "
                       f"åˆ†çº§[æå…¶:{summary['highly_recommended_count']}/"
                       f"æ¨è:{summary['recommended_count']}/"
                       f"ä¸å¤ª:{summary['less_recommended_count']}]"
                   )

               return final_results

           except Exception as e:
            logger.error(f"âŒ ç»¼åˆåœºæ™¯åˆ†çº§ç­›é€‰å¤±è´¥: {str(e)}", exc_info=True)
            return self._fallback_comprehensive_selection_with_grading(all_scenarios, max_scenarios, patient_info)

    def _fallback_comprehensive_selection_with_grading(
            self,
            all_scenarios: List[Dict[str, Any]],
            max_scenarios: int,
            patient_info: PatientInfo
    ) -> List[Dict[str, Any]]:
        """é™çº§æ–¹æ¡ˆï¼šåŸºäºå®Œæ•´å­—æ®µä¿¡æ¯è¿›è¡Œæ™ºèƒ½åˆ†çº§"""

        scored_scenarios = []

        for scenario_data in all_scenarios:
            recommendations = scenario_data.get('recommendations', [])
            if not recommendations:
                continue

            scenario = scenario_data['scenario']

            # æ™ºèƒ½åˆ†çº§ï¼šè€ƒè™‘ACRè¯„åˆ† + å®‰å…¨æ€§ + ä¸´åºŠåŒ¹é…åº¦
            highly_recommended = []
            recommended = []
            less_recommended = []

            for rec_data in recommendations:
                recommendation = rec_data['recommendation']
                procedure = rec_data['procedure']
                acr_rating = recommendation.appropriateness_rating

                # å®‰å…¨æ€§æ£€æŸ¥
                safety_issues = []

                # å¦Šå¨ å®‰å…¨æ€§æ£€æŸ¥
                if patient_info.pregnancy_status and patient_info.pregnancy_status != 'éå¦Šå¨ æœŸ':
                    if recommendation.pregnancy_safety and 'ç¦å¿Œ' in recommendation.pregnancy_safety:
                        safety_issues.append("å¦Šå¨ ç¦å¿Œ")

                # è¾å°„å®‰å…¨æ€§è€ƒè™‘
                if procedure.radiation_level and procedure.radiation_level in ['é«˜', 'ä¸­']:
                    safety_issues.append(f"è¾å°„{procedure.radiation_level}")

                # ç¦å¿Œç—‡æ£€æŸ¥
                if recommendation.contraindications:
                    safety_issues.append("å­˜åœ¨ç¦å¿Œç—‡")

                # åŸºäºACRè¯„åˆ†å’Œå®‰å…¨é—®é¢˜çš„åˆ†çº§é€»è¾‘
                if acr_rating >= 7 and not safety_issues:
                    level = 'highly_recommended'
                    level_zh = 'æå…¶æ¨è'
                    highly_recommended.append(rec_data)
                elif acr_rating >= 4 and len(safety_issues) <= 1:
                    level = 'recommended'
                    level_zh = 'æ¨è'
                    recommended.append(rec_data)
                else:
                    level = 'less_recommended'
                    level_zh = 'ä¸å¤ªæ¨è'
                    less_recommended.append(rec_data)

                # æ·»åŠ åˆ†çº§ä¿¡æ¯åˆ°å‰¯æœ¬
                rec_data_copy = rec_data.copy()
                rec_data_copy['recommendation_level'] = level
                rec_data_copy['recommendation_level_zh'] = level_zh
                rec_data_copy['safety_issues'] = safety_issues

            # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆåŸºäºé«˜æ¨èé¡¹ç›®æ¯”ä¾‹å’ŒACRå¹³å‡åˆ†ï¼‰
            if recommendations:
                highly_ratio = len(highly_recommended) / len(recommendations)
                avg_acr = sum(rec['recommendation'].appropriateness_rating for rec in recommendations) / len(
                    recommendations)
                comprehensive_score = int((highly_ratio * 0.7 + avg_acr / 9 * 0.3) * 100)
            else:
                comprehensive_score = 0

            scored_scenarios.append({
                'comprehensive_score': comprehensive_score,
                'scenario_reasoning': 'åŸºäºACRè¯„åˆ†å’Œå®‰å…¨æ€§çš„é™çº§åˆ†çº§',
                'grading_reasoning': f'ACRâ‰¥7ä¸”æ— å®‰å…¨é—®é¢˜:æå…¶æ¨è; ACR4-6ä¸”å®‰å…¨å•é¡Œâ‰¤1:æ¨è; å…¶ä»–:ä¸å¤ªæ¨è',
                'overall_reasoning': 'LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½é™çº§åˆ†çº§æ–¹æ¡ˆ',
                'graded_recommendations': {
                    'highly_recommended': highly_recommended,
                    'recommended': recommended,
                    'less_recommended': less_recommended
                },
                'recommendation_summary': {
                    'highly_recommended_count': len(highly_recommended),
                    'recommended_count': len(recommended),
                    'less_recommended_count': len(less_recommended),
                    'total_recommendations': len(recommendations)
                },
                'scenario_metadata': {
                    'scenario_id': scenario.semantic_id,
                    'description': scenario.description_zh,
                    'panel': getattr(scenario.panel, 'name_zh', 'æœªçŸ¥'),
                    'patient_population': scenario.patient_population,
                    'fallback_used': True
                }
            })

        # æŒ‰è¯„åˆ†æ’åº
        scored_scenarios.sort(key=lambda x: x['comprehensive_score'], reverse=True)
        return scored_scenarios[:max_scenarios]
















    def build_patient_context(self,patient_info: PatientInfo) -> str:
            """æ„å»ºæ‚£è€…ä¿¡æ¯"""
            # æ‚£è€…å’Œä¸´åºŠä¿¡æ¯
            patient_context = f"""
             ## æ‚£è€…åŸºæœ¬ä¿¡æ¯
             - **å¹´é¾„**: {patient_info.age}å²
             - **æ€§åˆ«**: {patient_info.gender}
             - **å¦Šå¨ çŠ¶æ€**: {patient_info.pregnancy_status or 'éå¦Šå¨ æœŸ'}
             - **è¿‡æ•å²**: {', '.join(patient_info.allergies) if patient_info.allergies else 'æ— '}
             - **åˆå¹¶ç—‡**: {', '.join(patient_info.comorbidities) if patient_info.comorbidities else 'æ— '}
             - **ä½“æ ¼æ£€æŸ¥**: {patient_info.physical_examination or 'æ— '}"""
            return patient_context
    def build_clinical_context(self,clinical_context: ClinicalContext) -> str:
             """æ„å»ºä¸´åºŠä¿¡æ¯"""
             ## ä¸´åºŠä¸Šä¸‹æ–‡
             clinical_context_content=f"""
             ### ä¸´åºŠä¿¡æ¯
             - **å°±è¯Šç§‘å®¤**: {clinical_context.department}
             - **ä¸»è¯‰**: {clinical_context.chief_complaint}
             - **æ—¢å¾€ç—…å²**: {clinical_context.medical_history or 'æ— '}
             - **ç°ç—…å²**: {clinical_context.present_illness or 'æ— '}
             - **ä¸»è¯Šæ–­**: {clinical_context.diagnosis or 'å¾…è¯Šæ–­'}
             - **ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦**: {clinical_context.symptom_severity or 'æœªçŸ¥'}
             - **ç—‡çŠ¶æŒç»­æ—¶é—´**: {clinical_context.symptom_duration or 'æœªçŸ¥'}
             """
             return clinical_context_content

    def build_scenarios_with_recommend(self,all_scenarios:List[Dict[str, Any]]):
        # æ‰€æœ‰åœºæ™¯å’Œæ¨èé¡¹ç›®ï¼ˆåˆ©ç”¨å®Œæ•´å­—æ®µä¿¡æ¯ï¼‰
        scenarios_text = "## å¯é€‰ä¸´åºŠåœºæ™¯åŠæ¨èé¡¹ç›®\n\n"

        for scenario_idx, scenario_data in enumerate(all_scenarios, 1):
            scenario = scenario_data['scenario']
            recommendations = scenario_data.get('recommendations', [])

            scenarios_text += f"### åœºæ™¯{scenario_idx}: {scenario.description_zh}\n"
            scenarios_text += f"- **åœºæ™¯ID**: {scenario.semantic_id}\n"
            scenarios_text += f"- **é€‚ç”¨ç§‘å®¤**: {scenario.panel.name_zh if hasattr(scenario, 'panel') else 'æœªçŸ¥'}\n"
            scenarios_text += f"- **é€‚ç”¨äººç¾¤**: {scenario.patient_population or 'æœªçŸ¥'}\n"
            scenarios_text += f"- **ä¸´åºŠèƒŒæ™¯**: {scenario.clinical_context or 'æ— '}\n\n"

            if not recommendations:
                scenarios_text += "  æš‚æ— æ¨èé¡¹ç›®\n\n"
                continue

            scenarios_text += "#### æ¨èé¡¹ç›®æ¸…å•:\n"
            for rec_idx, rec_data in enumerate(recommendations, 1):
                recommendation = rec_data['recommendation']
                procedure = rec_data['procedure']

                # æ£€æŸ¥é¡¹ç›®åŸºæœ¬ä¿¡æ¯
                scenarios_text += f"{rec_idx}. **{procedure.name_zh}** ({procedure.name_en})\n"

                # æ£€æŸ¥æŠ€æœ¯ç»†èŠ‚
                tech_details = []
                if procedure.modality:
                    tech_details.append(f"æ£€æŸ¥æ–¹å¼: {procedure.modality}")
                if procedure.body_part:
                    tech_details.append(f"æ£€æŸ¥éƒ¨ä½: {procedure.body_part}")
                if procedure.exam_duration:
                    tech_details.append(f"æ£€æŸ¥æ—¶é•¿: {procedure.exam_duration}åˆ†é’Ÿ")
                # if tech_details:
                #     scenarios_text += f"   - æŠ€æœ¯ç»†èŠ‚: {', '.join(tech_details)}\n"

                # å®‰å…¨æ€§å’Œå‡†å¤‡ä¿¡æ¯
                safety_info = []
                if procedure.contrast_used:
                    safety_info.append("ä½¿ç”¨å¯¹æ¯”å‰‚")
                if procedure.radiation_level:
                    safety_info.append(f"è¾å°„ç­‰çº§: {procedure.radiation_level}")
                if procedure.preparation_required:
                    safety_info.append("éœ€è¦å‡†å¤‡")
                if safety_info:
                    scenarios_text += f"   - å®‰å…¨ä¿¡æ¯: {', '.join(safety_info)}\n"

                # ACRæ¨èä¿¡æ¯
                scenarios_text += f"   - **ACRé€‚å®œæ€§è¯„åˆ†**: {recommendation.appropriateness_rating}/9\n"
                if recommendation.appropriateness_category_zh:
                    scenarios_text += f"   - é€‚å®œæ€§ç±»åˆ«: {recommendation.appropriateness_category_zh}\n"

                # è¯æ®å’Œå…±è¯†
                evidence_info = []
                if recommendation.evidence_level:
                    evidence_info.append(f"è¯æ®å¼ºåº¦: {recommendation.evidence_level}")
                # if recommendation.consensus_level:
                #     evidence_info.append(f"å…±è¯†æ°´å¹³: {recommendation.consensus_level}")
                # if recommendation.median_rating:
                #     evidence_info.append(f"ä¸­ä½æ•°è¯„åˆ†: {recommendation.median_rating}")
                # if evidence_info:
                #     scenarios_text += f"   - è¯æ®è´¨é‡: {', '.join(evidence_info)}\n"

                # è¾å°„å‰‚é‡ä¿¡æ¯
                dose_info = []
                if recommendation.adult_radiation_dose:
                    dose_info.append(f"æˆäººå‰‚é‡: {recommendation.adult_radiation_dose}")
                if recommendation.pediatric_radiation_dose:
                    dose_info.append(f"å„¿ç«¥å‰‚é‡: {recommendation.pediatric_radiation_dose}")
                if dose_info:
                    scenarios_text += f"   - è¾å°„å‰‚é‡: {', '.join(dose_info)}\n"

                # å®‰å…¨æ€§ä¿¡æ¯
                safety_info = []
                if recommendation.pregnancy_safety:
                    safety_info.append(f"å¦Šå¨ å®‰å…¨: {recommendation.pregnancy_safety}")
                if recommendation.contraindications:
                    contra = recommendation.contraindications[:80] + "..." if len(
                        recommendation.contraindications) > 80 else recommendation.contraindications
                    safety_info.append(f"ç¦å¿Œç—‡: {contra}")
                if safety_info:
                    scenarios_text += f"   - å®‰å…¨è€ƒè™‘: {', '.join(safety_info)}\n"

                # æ¨èç†ç”±
                if recommendation.reasoning_zh:
                    reasoning = recommendation.reasoning_zh[:50] + "..." if len(
                        recommendation.reasoning_zh) > 50 else recommendation.reasoning_zh
                    scenarios_text += f"   - æ¨èç†ç”±: {reasoning}\n"
                #
                # # ç‰¹æ®Šè€ƒè™‘
                if recommendation.special_considerations:
                    special = recommendation.special_considerations[:80] + "..." if len(
                        recommendation.special_considerations) > 80 else recommendation.special_considerations
                    scenarios_text += f"   - ç‰¹æ®Šè€ƒè™‘: {special}\n"
                #
                # # æ ‡å‡†ç¼–ç ï¼ˆå¦‚æœ‰ï¼‰
                # code_info = []
                # if procedure.standard_code:
                #     code_info.append(f"æ ‡å‡†ç : {procedure.standard_code}")
                # if procedure.icd10_code:
                #     code_info.append(f"ICD10: {procedure.icd10_code}")
                # if procedure.cpt_code:
                #     code_info.append(f"CPT: {procedure.cpt_code}")
                # if code_info:
                #     scenarios_text += f"   - æ ‡å‡†ç¼–ç : {', '.join(code_info)}\n"

                scenarios_text += "\n"

            scenarios_text += "---\n\n"
        return scenarios_text
    def build_task_instruction(self,**kwargs):
        # ä»»åŠ¡æŒ‡ä»¤
        all_scenarios=kwargs.get('all_scenarios')
        max_scenarios = kwargs.get('max_scenarios')
        max_recommendations_per_scenario=kwargs.get('max_recommendations_per_scenario')
        task_instruction = f"""
            ## ä»»åŠ¡è¯´æ˜

            ä½œä¸ºç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿï¼Œè¯·æ ¹æ®æ‚£è€…ä¿¡æ¯å’Œä¸´åºŠä¸Šä¸‹æ–‡ï¼Œå®Œæˆä»¥ä¸‹**ä¸¤çº§æ™ºèƒ½ç­›é€‰**ï¼š

            ### ç¬¬ä¸€çº§ï¼šåœºæ™¯ç­›é€‰
            ä»{len(all_scenarios)}ä¸ªä¸´åºŠåœºæ™¯ä¸­é€‰æ‹©æœ€ç›¸å…³çš„**{max_scenarios}ä¸ªåœºæ™¯**ï¼ŒæŒ‰ä¸´åºŠä¼˜å…ˆçº§æ’åºã€‚

            ### ç¬¬äºŒçº§ï¼šæ¨èé¡¹ç›®ä¸‰çº§åˆ†çº§è¯„ä¼°
            å¯¹æ¯ä¸ªé€‰ä¸­åœºæ™¯çš„æ‰€æœ‰æ¨èé¡¹ç›®ï¼Œè¿›è¡Œ**ä¸‰çº§æ¨èç­‰çº§åˆ’åˆ†**ï¼š

            - **æå…¶æ¨è (Highly Recommended)**: è¯„åˆ†é«˜ï¼Œè¯æ®å……åˆ†ï¼Œä¸æ‚£è€…æƒ…å†µå®Œç¾åŒ¹é…ï¼Œå®‰å…¨æ€§å’Œè¯Šæ–­ä»·å€¼ä¿±ä½³ï¼Œæ— æ˜æ˜¾ç¦å¿Œ
            - **æ¨è (Recommended)**: è¯„åˆ†ä¸­ç­‰ï¼Œä¸´åºŠé€‚ç”¨æ€§è‰¯å¥½ï¼Œé£é™©æ”¶ç›Šæ¯”åˆç†ï¼Œå¯èƒ½å­˜åœ¨è½»å¾®é™åˆ¶
            - **ä¸å¤ªæ¨è (Less Recommended)**: è¯„åˆ†ä½ï¼Œæˆ–å­˜åœ¨å®‰å…¨éšæ‚£ï¼Œæˆ–æœ‰æ˜ç¡®ç¦å¿Œç—‡ï¼Œæˆ–ä¸å½“å‰ä¸´åºŠéœ€æ±‚åŒ¹é…åº¦ä¸é«˜
            ##æ³¨æ„
              - æ¯ä¸ªåœºæ™¯çš„æ¨èé¡¹ç›®ä¸èƒ½è¶…è¿‡{max_recommendations_per_scenario}ä¸ªã€‚
            ## è¾“å‡ºæ ¼å¼
            è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦é¢å¤–è§£é‡Šï¼š

            ```json
            {{
                "selected_scenarios": [
                  {{
                      "scenario_index": è¿™é‡Œæ˜¯ç´¢å¼•id(ä¾‹å¦‚ï¼š1),
                      "scenario_id": "åœºæ™¯è¯­ä¹‰ID",
                      "comprehensive_score": "0-100ç»¼åˆè¯„åˆ†",
                      "scenario_reasoning": "åœºæ™¯åŒ¹é…åº¦åˆ†æ",
                      "recommendation_grades": {{
                          "highly_recommended": [1, 3],
                          "recommended": [2, 4],
                          "less_recommended": [5]
                      }},
                      "grading_reasoning": "åˆ†çº§ä¸´åºŠç†ç”±"
                  }},
                  {{
                      "scenario_index": è¿™é‡Œæ˜¯ç´¢å¼•id(ä¾‹å¦‚ï¼š2),
                      "scenario_id": "åœºæ™¯è¯­ä¹‰ID",
                      "comprehensive_score": "0-100ç»¼åˆè¯„åˆ†",
                      "scenario_reasoning": "åœºæ™¯åŒ¹é…åº¦åˆ†æ",
                      "recommendation_grades": {{
                          "highly_recommended": [1, 3],
                          "recommended": [2, 4],
                          "less_recommended": [5]
                      }},
                      "grading_reasoning": "åˆ†çº§ä¸´åºŠç†ç”±"
                  }},
              ],
                "overall_reasoning": "æ€»ä½“é€‰æ‹©ç­–ç•¥è¯´æ˜ï¼Œä¸è¶…è¿‡200å­—"
            }}"""
        return task_instruction



    def _build_comprehensive_prompt_with_grading(
            self,
            all_scenarios: List[Dict[str, Any]],
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            max_scenarios: int,
            max_recommendations_per_scenario: int
    ) -> str:
         patient_info_content=self.build_patient_context(patient_info)
         clinical_context_content=self.build_clinical_context(clinical_context)
         scenarios_content=self.build_scenarios_with_recommend(all_scenarios)
         task_instruction=self.build_task_instruction(all_scenarios=all_scenarios,max_scenarios=max_scenarios,max_recommendations_per_scenario=max_recommendations_per_scenario)


         return patient_info_content + "\n" + clinical_context_content + "\n" +scenarios_content+"\n"+ task_instruction

    def _handel_filter_scenario_with_recommendations(self, scenario_with_recommendations:List,
                                                     filter_scenario_with_recommendations:List,max_scenarios):

        # æ–°å¢ï¼šå¦‚æœè¿‡æ»¤åçš„åœºæ™¯æ•°é‡ä¸è¶³ï¼Œä»åŸå§‹åœºæ™¯ä¸­è¡¥å……
        if len(filter_scenario_with_recommendations) < max_scenarios:
            # ä»åŸå§‹åœºæ™¯ä¸­æ‰¾å‡ºä¸åœ¨è¿‡æ»¤åˆ—è¡¨ä¸­çš„åœºæ™¯
            filtered_scenario_ids = {scenario["scenario_id"] for scenario in filter_scenario_with_recommendations}
            additional_scenarios = [scenario for scenario in scenario_with_recommendations
                                    if scenario["scenario_id"] not in filtered_scenario_ids]

            # æŒ‰åŸå§‹æ’åºè¡¥å……åˆ°max_scenariosä¸ª
            needed_count = max_scenarios - len(filter_scenario_with_recommendations)
            additional_to_add = additional_scenarios[:needed_count]

            # åˆå¹¶åˆ—è¡¨ï¼ˆè¿‡æ»¤åœºæ™¯åœ¨å‰ï¼Œè¡¥å……åœºæ™¯åœ¨åï¼‰
            final_scenarios = filter_scenario_with_recommendations + additional_to_add
            logger.info(
                f"è¿‡æ»¤åœºæ™¯æ•°é‡({len(filter_scenario_with_recommendations)})ä¸è¶³ï¼Œè¡¥å……äº†{len(additional_to_add)}ä¸ªåœºæ™¯")
        else:
            # å¦‚æœè¶³å¤Ÿï¼Œç›´æ¥æˆªå–å‰max_scenariosä¸ª
            final_scenarios = filter_scenario_with_recommendations[:max_scenarios]
            logger.info(f"è¿‡æ»¤åœºæ™¯æ•°é‡({len(filter_scenario_with_recommendations)})å……è¶³ï¼Œæˆªå–å‰{max_scenarios}ä¸ª")
        return final_scenarios


























