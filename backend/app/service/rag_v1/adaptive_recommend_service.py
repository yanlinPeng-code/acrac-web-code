import asyncio
import json
import re
import time
import logging
from typing import List, Dict, Any, Tuple, Optional

from app.schema.IntelligentRecommendation_schemas import PatientInfo, ClinicalContext
from app.service.rag_v1.ai_service import AiService
from app.service.rag_v1.model_service import ModelService
from app.utils.helper.helper import safe_parse_llm_response, safe_process_recommendation_grades

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)




class AdaptiveThresholdStrategy:
    """åŸºç¡€é˜ˆå€¼ç­–ç•¥"""

    def __init__(self):
        self.threshold_config = {
            'token_threshold':  4096,
            'max_scenarios_single_call': 5,
            'max_total_recommendations': 30,
            'max_avg_recommendations_per_scenario': 8
        }

        self.weights = {
            'token_ratio': 0.5,
            'scenario_ratio': 0.2,
            'total_recommendations_ratio': 0.2,
            'avg_recommendations_ratio': 0.1
        }

    def should_use_concurrent(
            self,
            confirmed_scenarios: List[Dict[str, Any]],
            estimated_tokens: int
    ) -> Tuple[bool, Dict[str, Any]]:
        """å†³å®šæ˜¯å¦ä½¿ç”¨å¹¶å‘å¤„ç†"""

        scenario_count = len(confirmed_scenarios)
        total_recommendations = sum(
            len(scenario.get('recommendations', []))
            for scenario in confirmed_scenarios
        )
        avg_recommendations = total_recommendations / max(scenario_count, 1)

        # è®¡ç®—å„ç»´åº¦æ¯”ç‡
        token_ratio = estimated_tokens / self.threshold_config['token_threshold']
        scenario_ratio = scenario_count / self.threshold_config['max_scenarios_single_call']
        total_rec_ratio = total_recommendations / self.threshold_config['max_total_recommendations']
        avg_rec_ratio = avg_recommendations / self.threshold_config['max_avg_recommendations_per_scenario']

        # è®¡ç®—ç»¼åˆè¯„åˆ†
        composite_score = (
                token_ratio * self.weights['token_ratio'] +
                scenario_ratio * self.weights['scenario_ratio'] +
                total_rec_ratio * self.weights['total_recommendations_ratio'] +
                avg_rec_ratio * self.weights['avg_recommendations_ratio']
        )

        # ç¡¬æ€§æ¡ä»¶
        hard_conditions = [
            token_ratio > 1.0,
            scenario_ratio > 1.5,
            total_rec_ratio > 2.0,
            avg_rec_ratio > 1.8
        ]

        use_concurrent = composite_score > 1.0 or any(hard_conditions)

        decision_metrics = {
            'composite_score': composite_score,
            'dimensions': {
                'tokens': {
                    'value': estimated_tokens,
                    'threshold': self.threshold_config['token_threshold'],
                    'ratio': token_ratio
                },
                'scenarios': {
                    'value': scenario_count,
                    'threshold': self.threshold_config['max_scenarios_single_call'],
                    'ratio': scenario_ratio
                },
                'total_recommendations': {
                    'value': total_recommendations,
                    'threshold': self.threshold_config['max_total_recommendations'],
                    'ratio': total_rec_ratio
                },
                'avg_recommendations': {
                    'value': avg_recommendations,
                    'threshold': self.threshold_config['max_avg_recommendations_per_scenario'],
                    'ratio': avg_rec_ratio
                }
            },
            'hard_conditions_triggered': [
                'token_exceeded' if token_ratio > 1.0 else None,
                'scenarios_exceeded' if scenario_ratio > 1.5 else None,
                'total_recommendations_exceeded' if total_rec_ratio > 2.0 else None,
                'avg_recommendations_exceeded' if avg_rec_ratio > 1.8 else None
            ],
            'decision_reason': self._get_decision_reason(composite_score, hard_conditions)
        }

        return use_concurrent, decision_metrics

    def _get_decision_reason(self, composite_score: float, hard_conditions: List[bool]) -> str:
        """ç”Ÿæˆå†³ç­–ç†ç”±"""
        if composite_score > 1.0:
            return f"ç»¼åˆè¯„åˆ†{composite_score:.2f}è¶…è¿‡é˜ˆå€¼1.0"

        triggered = [cond for cond in hard_conditions if cond]
        if triggered:
            return f"è§¦å‘{len(triggered)}ä¸ªç¡¬æ€§æ¡ä»¶"

        return f"ç»¼åˆè¯„åˆ†{composite_score:.2f}æœªè¶…è¿‡é˜ˆå€¼"


class LearningThresholdStrategy(AdaptiveThresholdStrategy):
    """åŸºäºå†å²æ€§èƒ½å­¦ä¹ çš„é˜ˆå€¼ç­–ç•¥"""

    def __init__(self):
        super().__init__()
        self.performance_history = []
        self.learning_enabled = True

    def update_based_on_performance(
            self,
            decision_metrics: Dict[str, Any],
            actual_processing_time: float,
            success: bool,
            strategy_used: str
    ):
        """æ ¹æ®å®é™…æ€§èƒ½æ›´æ–°é˜ˆå€¼"""
        if not self.learning_enabled:
            return

        record = {
            'decision_metrics': decision_metrics,
            'processing_time': actual_processing_time,
            'success': success,
            'strategy_used': strategy_used,
            'timestamp': time.time()
        }

        self.performance_history.append(record)

        # ä¿ç•™æœ€è¿‘100æ¡è®°å½•
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]

        # å®šæœŸè°ƒæ•´é˜ˆå€¼
        if len(self.performance_history) % 20 == 0:
            self._adjust_thresholds_based_on_history()

    def _adjust_thresholds_based_on_history(self):
        """åŸºäºå†å²æ€§èƒ½è°ƒæ•´é˜ˆå€¼"""
        single_call_records = [r for r in self.performance_history if r['strategy_used'] == 'single']
        concurrent_records = [r for r in self.performance_history if r['strategy_used'] == 'concurrent']

        if len(single_call_records) < 5 or len(concurrent_records) < 5:
            return

        # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
        try:
            avg_single_time = sum(r['processing_time'] for r in single_call_records) / len(single_call_records)
            avg_concurrent_time = sum(r['processing_time'] for r in concurrent_records) / len(concurrent_records)

            # è®¡ç®—æˆåŠŸç‡
            single_success_rate = sum(1 for r in single_call_records if r['success']) / len(single_call_records)
            concurrent_success_rate = sum(1 for r in concurrent_records if r['success']) / len(concurrent_records)

            # æ ¹æ®æ€§èƒ½å·®å¼‚è°ƒæ•´é˜ˆå€¼
            time_ratio = avg_single_time / avg_concurrent_time if avg_concurrent_time > 0 else 1.0
            success_ratio = single_success_rate / concurrent_success_rate if concurrent_success_rate > 0 else 1.0

            # å¦‚æœå•æ¬¡è°ƒç”¨æ€§èƒ½æ›´å¥½ï¼Œé€‚å½“æé«˜é˜ˆå€¼
            if time_ratio < 0.8 and success_ratio > 0.9:
                self.threshold_config['token_threshold'] = min(
                    self.threshold_config['token_threshold'] * 1.1,
                    8000
                )
                logger.info(f"ğŸ“ˆ åŸºäºæ€§èƒ½æ•°æ®æé«˜tokené˜ˆå€¼è‡³: {self.threshold_config['token_threshold']}")

            # å¦‚æœå¹¶å‘è°ƒç”¨æ€§èƒ½æ›´å¥½ï¼Œé€‚å½“é™ä½é˜ˆå€¼
            elif time_ratio > 1.2 or success_ratio < 0.8:
                self.threshold_config['token_threshold'] = max(
                    self.threshold_config['token_threshold'] * 0.9,
                    2000
                )
                logger.info(f"ğŸ“‰ åŸºäºæ€§èƒ½æ•°æ®é™ä½tokené˜ˆå€¼è‡³: {self.threshold_config['token_threshold']}")
        except Exception as e:
            logger.warning(f"è°ƒæ•´é˜ˆå€¼æ—¶å‡ºé”™: {e}")


class AdaptiveRecommendationEngineService:
    """è‡ªé€‚åº”æ¨èå¼•æ“"""

    def __init__(self, environment: str = "production", use_adaptive: bool = True):
        self.environment = environment
        self.use_adaptive = use_adaptive
        self.ai_service = AiService()

        # åˆå§‹åŒ–ç­–ç•¥
        if use_adaptive:
            self.strategy = LearningThresholdStrategy()
            logger.info("ğŸ”„ å¯ç”¨è‡ªé€‚åº”ç­–ç•¥")
        else:
            self.strategy = AdaptiveThresholdStrategy()
            logger.info("âš¡ ä½¿ç”¨å›ºå®šé˜ˆå€¼ç­–ç•¥")

        self._initialize_strategy()

    def _initialize_strategy(self):
        """åˆå§‹åŒ–ç­–ç•¥é…ç½®"""
        env_config = self.get_environment_specific_config(self.environment)
        self.strategy.threshold_config.update(env_config)
        logger.info(f"âœ… ç­–ç•¥åˆå§‹åŒ–å®Œæˆï¼Œç¯å¢ƒ: {self.environment}")

    def get_environment_specific_config(self, environment: str) -> Dict[str, Any]:
        """è·å–ç¯å¢ƒç‰¹å®šé…ç½®"""
        configs = {
            'development': {
                'token_threshold': 2000,
                'max_scenarios_single_call': 3,
                'max_total_recommendations': 20,
                'max_avg_recommendations_per_scenario': 6,
            },
            'production': {
                'token_threshold': 4096,
                'max_scenarios_single_call': 8,
                'max_total_recommendations': 50,
                'max_avg_recommendations_per_scenario': 10,
            },
            'local-qwen': {
                'token_threshold': 4096,
                'max_scenarios_single_call': 4,
                'max_total_recommendations': 25,
                'max_avg_recommendations_per_scenario': 7,
            }
        }
        return configs.get(environment, configs['production'])

    def estimate_tokens_with_tiktoken(self, text: str, model_name: str = "cl100k_base") -> int:
        """ä½¿ç”¨tiktokenè®¡ç®—tokenæ•°é‡"""
        try:
            import tiktoken
            import qwen_token_counter
            try:
                return qwen_token_counter.get_token_count(text)
            except KeyError:
                encoding = tiktoken.get_encoding("cl100k_base")
            return len(encoding.encode(text))
        except ImportError:
            logger.warning("tiktokenæœªå®‰è£…ï¼Œä½¿ç”¨å›é€€ä¼°ç®—æ–¹æ³•")
            return self._estimate_tokens_fallback(text)

    def _estimate_tokens_fallback(self, text: str) -> int:
        """tiktokenä¸å¯ç”¨æ—¶çš„å›é€€ä¼°ç®—æ–¹æ³•"""
        import re
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        english_words = len(re.findall(r'\b[a-zA-Z]+\b', text))
        numbers = len(re.findall(r'\d+', text))
        punctuation = len(re.findall(r'[^\w\s\u4e00-\u9fff]', text))
        spaces = len(re.findall(r'\s', text))

        estimated_tokens = (
                chinese_chars * 2.3 +
                english_words * 1.3 +
                numbers * 0.8 +
                punctuation * 0.5 +
                spaces * 0.1
        )
        return int(estimated_tokens)

    def _build_single_call_prompt(
            self,
            confirmed_scenarios: List[Dict[str, Any]],
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            max_recommendations_per_scenario: int
    ) -> str:
        """æ„å»ºå•æ¬¡è°ƒç”¨æç¤ºè¯"""
        patient_info_content = self.build_patient_context(patient_info)
        clinical_context_content = self.build_clinical_context(clinical_context)
        scenarios_content = self._build_optimized_scenarios_content(confirmed_scenarios)
        task_instruction = self._build_optimized_task_instruction(
            len(confirmed_scenarios), max_recommendations_per_scenario
        )

        return f"{patient_info_content}\n{clinical_context_content}\n{scenarios_content}\n{task_instruction}"

    def build_patient_context(self, patient_info: PatientInfo) -> str:
          """æ„å»ºæ‚£è€…ä¿¡æ¯"""
          # æ‚£è€…å’Œä¸´åºŠä¿¡æ¯
          patient_context = f"""
             ## æ‚£è€…åŸºæœ¬ä¿¡æ¯
             - **å¹´é¾„**: {patient_info.age}å²
             - **æ€§åˆ«**: {patient_info.gender}
             - **å¦Šå¨ çŠ¶æ€**: {patient_info.pregnancy_status or 'éå¦Šå¨ æœŸ'}
             - **è¿‡æ•å²**: {', '.join(patient_info.allergies) if patient_info.allergies else 'æ— '}
             - **åˆå¹¶ç—‡**: {', '.join(patient_info.comorbidities) if patient_info.comorbidities else 'æ— '}
            """
          return patient_context

    def build_clinical_context(self, clinical_context: ClinicalContext) -> str:
        """æ„å»ºä¸´åºŠä¸Šä¸‹æ–‡ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        ## ä¸´åºŠä¸Šä¸‹æ–‡
        clinical_context_content = f"""
                   ### ä¸´åºŠä¿¡æ¯
                   - **å°±è¯Šç§‘å®¤**: {clinical_context.department}
                   - **ä¸»è¯‰**: {clinical_context.chief_complaint}
                   - **æ—¢å¾€ç—…å²**: {clinical_context.medical_history or 'æ— '}
                   - **ç°ç—…å²**: {clinical_context.present_illness or 'æ— '}
                   - **ä¸»è¯Šæ–­**: {clinical_context.diagnosis or 'å¾…è¯Šæ–­'}
                   - **ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦**: {clinical_context.symptom_severity or 'æœªçŸ¥'}
                   - **ç—‡çŠ¶æŒç»­æ—¶é—´**: {clinical_context.symptom_duration or 'æœªçŸ¥'}
                   """
        return clinical_context_content

    def _build_optimized_scenarios_content(self, confirmed_scenarios: List[Dict[str, Any]]) -> str:
        """æ„å»ºä¼˜åŒ–çš„åœºæ™¯å†…å®¹"""
        # æ‰€æœ‰åœºæ™¯å’Œæ¨èé¡¹ç›®ï¼ˆåˆ©ç”¨å®Œæ•´å­—æ®µä¿¡æ¯ï¼‰
        scenarios_text = "## å¯é€‰ä¸´åºŠåœºæ™¯åŠæ¨èé¡¹ç›®\n\n"

        for scenario_idx, scenario_data in enumerate(confirmed_scenarios, 1):
            scenario = scenario_data['scenario']
            recommendations = scenario_data.get('recommendations', [])

            scenarios_text += f"### åœºæ™¯{scenario_idx}: {scenario.description_zh}\n"
            scenarios_text += f"- **åœºæ™¯ID**: {scenario.semantic_id}\n"
            scenarios_text += f"- **é€‚ç”¨ç§‘å®¤**: {scenario.panel.name_zh if hasattr(scenario, 'panel') else 'æœªçŸ¥'}\n"
            scenarios_text += f"- **é€‚ç”¨äººç¾¤**: {scenario.patient_population or 'æœªçŸ¥'}\n"
            scenarios_text += f"- **ä¸´åºŠèƒŒæ™¯**: {scenario.clinical_context or 'æ— '}\n\n"

            if not recommendations:
                scenarios_text += "  æš‚æ— æ¨èé¡¹ç›®\n\n"
                continue

            scenarios_text += "#### æ¨èé¡¹ç›®æ¸…å•:\n"
            for rec_idx, rec_data in enumerate(recommendations, 1):
                recommendation = rec_data['recommendation']
                procedure = rec_data['procedure']

                # æ£€æŸ¥é¡¹ç›®åŸºæœ¬ä¿¡æ¯
                scenarios_text += f"{rec_idx}. **{procedure.name_zh}** ({procedure.name_en})\n"

                # æ£€æŸ¥æŠ€æœ¯ç»†èŠ‚
                tech_details = []
                if procedure.modality:
                    tech_details.append(f"æ£€æŸ¥æ–¹å¼: {procedure.modality}")
                if procedure.body_part:
                    tech_details.append(f"æ£€æŸ¥éƒ¨ä½: {procedure.body_part}")
                # if procedure.exam_duration:
                #     tech_details.append(f"æ£€æŸ¥æ—¶é•¿: {procedure.exam_duration}åˆ†é’Ÿ")
                # if tech_details:
                #     scenarios_text += f"   - æŠ€æœ¯ç»†èŠ‚: {', '.join(tech_details)}\n"

                # å®‰å…¨æ€§å’Œå‡†å¤‡ä¿¡æ¯
                safety_info = []
                if procedure.contrast_used:
                    safety_info.append("ä½¿ç”¨å¯¹æ¯”å‰‚")
                if procedure.radiation_level:
                    safety_info.append(f"è¾å°„ç­‰çº§: {procedure.radiation_level}")
                # if procedure.preparation_required:
                #     safety_info.append("éœ€è¦å‡†å¤‡")
                if safety_info:
                    scenarios_text += f"   - å®‰å…¨ä¿¡æ¯: {', '.join(safety_info)}\n"

                # ACRæ¨èä¿¡æ¯
                scenarios_text += f"   - **ACRé€‚å®œæ€§è¯„åˆ†**: {recommendation.appropriateness_rating}/9\n"
                if recommendation.appropriateness_category_zh:
                    scenarios_text += f"   - é€‚å®œæ€§ç±»åˆ«: {recommendation.appropriateness_category_zh}\n"

                # è¯æ®å’Œå…±è¯†
                evidence_info = []
                if recommendation.evidence_level:
                    evidence_info.append(f"è¯æ®å¼ºåº¦: {recommendation.evidence_level}")
                # if recommendation.consensus_level:
                #     evidence_info.append(f"å…±è¯†æ°´å¹³: {recommendation.consensus_level}")
                # if recommendation.median_rating:
                #     evidence_info.append(f"ä¸­ä½æ•°è¯„åˆ†: {recommendation.median_rating}")
                # if evidence_info:
                #     scenarios_text += f"   - è¯æ®è´¨é‡: {', '.join(evidence_info)}\n"

                # è¾å°„å‰‚é‡ä¿¡æ¯
                dose_info = []
                if recommendation.adult_radiation_dose:
                    dose_info.append(f"æˆäººå‰‚é‡: {recommendation.adult_radiation_dose}")
                if recommendation.pediatric_radiation_dose:
                    dose_info.append(f"å„¿ç«¥å‰‚é‡: {recommendation.pediatric_radiation_dose}")
                if dose_info:
                    scenarios_text += f"   - è¾å°„å‰‚é‡: {', '.join(dose_info)}\n"

                # å®‰å…¨æ€§ä¿¡æ¯
                safety_info = []
                if recommendation.pregnancy_safety:
                    safety_info.append(f"å¦Šå¨ å®‰å…¨: {recommendation.pregnancy_safety}")
                if recommendation.contraindications:
                    contra = recommendation.contraindications[:50] + "..." if len(
                        recommendation.contraindications) > 50 else recommendation.contraindications
                    safety_info.append(f"ç¦å¿Œç—‡: {contra}")
                if safety_info:
                    scenarios_text += f"   - å®‰å…¨è€ƒè™‘: {', '.join(safety_info)}\n"

                # æ¨èç†ç”±
                if recommendation.reasoning_zh:
                    reasoning = recommendation.reasoning_zh[:80] + "..." if len(
                        recommendation.reasoning_zh) > 80 else recommendation.reasoning_zh
                    scenarios_text += f"   - æ¨èç†ç”±: {reasoning}\n"


                if recommendation.special_considerations:
                    special = recommendation.special_considerations[:80] + "..." if len(
                        recommendation.special_considerations) > 80 else recommendation.special_considerations
                    scenarios_text += f"   - ç‰¹æ®Šè€ƒè™‘: {special}\n"

                # æ ‡å‡†ç¼–ç ï¼ˆå¦‚æœ‰ï¼‰
                # code_info = []
                # if procedure.standard_code:
                #     code_info.append(f"æ ‡å‡†ç : {procedure.standard_code}")
                # if procedure.icd10_code:
                #     code_info.append(f"ICD10: {procedure.icd10_code}")
                # if procedure.cpt_code:
                #     code_info.append(f"CPT: {procedure.cpt_code}")
                # if code_info:
                #     scenarios_text += f"   - æ ‡å‡†ç¼–ç : {', '.join(code_info)}\n"

                scenarios_text += "\n"

            scenarios_text += "---\n\n"
        return scenarios_text

    def _build_optimized_task_instruction(self, scenario_count: int, max_recommendations_per_scenario: int) -> str:
        """æ„å»ºä¼˜åŒ–çš„ä»»åŠ¡æŒ‡ä»¤"""


        return f"""
          ## ä»»åŠ¡è¯´æ˜

          åŸºäºæ‚£è€…ä¿¡æ¯å’Œä¸´åºŠä¸Šä¸‹æ–‡ï¼Œå¯¹{scenario_count}ä¸ªå·²ç¡®è®¤ä¸´åºŠåœºæ™¯çš„æ‰€æœ‰æ¨èé¡¹ç›®è¿›è¡Œ**ä¸‰çº§æ¨èç­‰çº§åˆ’åˆ†**ã€‚

          ### åˆ†çº§æ ‡å‡†
                  - **æå…¶æ¨è (Highly Recommended)**: è¯„åˆ†é«˜ï¼Œè¯æ®å……åˆ†ï¼Œä¸æ‚£è€…æƒ…å†µå®Œç¾åŒ¹é…ï¼Œå®‰å…¨æ€§å’Œè¯Šæ–­ä»·å€¼ä¿±ä½³ï¼Œæ— æ˜æ˜¾ç¦å¿Œ
                  - **æ¨è (Recommended)**: è¯„åˆ†ä¸­ç­‰ï¼Œä¸´åºŠé€‚ç”¨æ€§è‰¯å¥½ï¼Œé£é™©æ”¶ç›Šæ¯”åˆç†ï¼Œå¯èƒ½å­˜åœ¨è½»å¾®é™åˆ¶
                  - **ä¸å¤ªæ¨è (Less Recommended)**: è¯„åˆ†ä½ï¼Œæˆ–å­˜åœ¨å®‰å…¨éšæ‚£ï¼Œæˆ–æœ‰æ˜ç¡®ç¦å¿Œç—‡ï¼Œæˆ–ä¸å½“å‰ä¸´åºŠéœ€æ±‚åŒ¹é…åº¦ä¸é«˜
          ##æ³¨æ„
              - æ¯ä¸ªåœºæ™¯çš„æœ€ç»ˆæ¨èé¡¹ç›®å¿…é¡»ä¸º{max_recommendations_per_scenario}ä¸ªã€‚
              - æ¯ä¸ªåœºæ™¯ä½ éƒ½è¦åšæ¨èçš„è¯„çº§ï¼Œä¸èƒ½æ è¿‡ã€‚
          ### è¾“å‡ºæ ¼å¼
          {{
              "selected_scenarios": [
                  {{
                      "scenario_index": è¿™é‡Œæ˜¯ç´¢å¼•id(ä¾‹å¦‚ï¼š1),
                      "scenario_id": "åœºæ™¯è¯­ä¹‰ID",
                      "comprehensive_score": "0-100ç»¼åˆè¯„åˆ†",
                      "scenario_reasoning": "åœºæ™¯åŒ¹é…åº¦åˆ†æ",
                      "recommendation_grades": {{
                          "highly_recommended": [1, 3],
                          "recommended": [2, 4],
                          "less_recommended": [5]
                      }},
                      "final_choices":[è¯¥åœºæ™¯é¡¹ç›®æ¨èï¼Œæ³¨æ„ï¼å¡«æ¨èé¡¹ç›®çš„åå­—ï¼Œä¸”æ¨èé¡¹ç›®åå­—å¿…é¡»ä¸º{max_recommendations_per_scenario}ä¸ªï¼]
                      "grading_reasoning": "åˆ†çº§ä¸´åºŠç†ç”±"
                  }},
                  {{
                      "scenario_index": è¿™é‡Œæ˜¯ç´¢å¼•id(ä¾‹å¦‚ï¼š2),
                      "scenario_id": "åœºæ™¯è¯­ä¹‰ID",
                      "comprehensive_score": "0-100ç»¼åˆè¯„åˆ†",
                      "scenario_reasoning": "åœºæ™¯åŒ¹é…åº¦åˆ†æ",
                      "recommendation_grades": {{
                          "highly_recommended": [1, 3],
                          "recommended": [2, 4],
                          "less_recommended": [5]
                      }},
                      "final_choices":[è¯¥åœºæ™¯é¡¹ç›®æ¨èï¼Œæ³¨æ„ï¼å¡«æ¨èé¡¹ç›®çš„åå­—ï¼Œä¸”æ¨èé¡¹ç›®åå­—å¿…é¡»ä¸º{max_recommendations_per_scenario}ä¸ªï¼]
                      "grading_reasoning": "åˆ†çº§ä¸´åºŠç†ç”±"
                  }},
              ],
              "overall_reasoning": "æ€»ä½“ç­–ç•¥è¯´æ˜"
          }}
          **é‡è¦ï¼šè¯·åªè¾“å‡ºçº¯JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€è¯´æ˜æˆ–Markdownæ ‡è®°ï¼ç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®ã€‚**
          """

    async def get_recommendations(
            self,
            confirmed_scenarios: List[Dict[str, Any]],
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            max_recommendations_per_scenario: int = 10,
            max_concurrent: int = 3,
            model_name: str = "gpt-3.5-turbo",
            use_adaptive: Optional[bool] = None  # å¯è¦†ç›–åˆå§‹è®¾ç½®
    ) -> List[Dict[str, Any]]:
        """ä¸»å…¥å£å‡½æ•° - è·å–æ¨èç»“æœ"""

        # ç¡®å®šæ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”ç­–ç•¥
        adaptive_mode = use_adaptive if use_adaptive is not None else self.use_adaptive
        # 1. è®¡ç®—tokenæ•°
        single_prompt = self._build_single_call_prompt(
            confirmed_scenarios, patient_info, clinical_context, max_recommendations_per_scenario
        )
        if adaptive_mode:
            return await self._get_recommendations_adaptive(
                confirmed_scenarios, patient_info, clinical_context,
                max_recommendations_per_scenario, max_concurrent, model_name,single_prompt
            )
        else:
            # éè‡ªé€‚åº”æ¨¡å¼ï¼Œé»˜è®¤ä½¿ç”¨å•æ¬¡è°ƒç”¨
            return await self._get_recommendations_single_call(
                confirmed_scenarios, patient_info, clinical_context,
                max_recommendations_per_scenario, len(confirmed_scenarios),single_prompt
            )

    async def _get_recommendations_adaptive(
            self,
            confirmed_scenarios: List[Dict[str, Any]],
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            max_recommendations_per_scenario: int,
            max_concurrent: int,
            model_name: str,
            single_prompt: str
    ) -> List[Dict[str, Any]]:
        """è‡ªé€‚åº”æ¨¡å¼å¤„ç†"""

        start_time = time.time()


        estimated_tokens = self.estimate_tokens_with_tiktoken(single_prompt)

        # 2. ä½¿ç”¨ç­–ç•¥å†³ç­–
        use_concurrent, decision_metrics = self.strategy.should_use_concurrent(
            confirmed_scenarios, estimated_tokens
        )

        # 3. è®°å½•å†³ç­–è¯¦æƒ…
        self._log_decision_metrics(decision_metrics, estimated_tokens)

        # 4. æ‰§è¡Œç›¸åº”ç­–ç•¥å¹¶è®°å½•æ€§èƒ½
        try:
            if use_concurrent:
                logger.info("âš¡ ä½¿ç”¨å¹¶å‘å¤„ç†ç­–ç•¥")
                results = await self._get_recommendations_for_confirmed_scenarios_concurrent(
                    confirmed_scenarios, patient_info, clinical_context,
                    max_recommendations_per_scenario, max_concurrent
                )
                strategy_used = 'concurrent'
            else:
                logger.info("ğŸ”„ ä½¿ç”¨å•æ¬¡è°ƒç”¨ç­–ç•¥")
                results = await self._get_recommendations_single_call(
                    confirmed_scenarios, patient_info, clinical_context,
                    max_recommendations_per_scenario, len(confirmed_scenarios),single_prompt
                )
                strategy_used = 'single'

            processing_time = time.time() - start_time
            success = True

        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
            processing_time = time.time() - start_time
            results = self._fallback_for_confirmed_scenarios(confirmed_scenarios)
            success = False
            strategy_used = 'single' if not use_concurrent else 'concurrent'

        # 5. å¦‚æœæ˜¯å­¦ä¹ ç­–ç•¥ï¼Œæ›´æ–°æ€§èƒ½æ•°æ®
        if isinstance(self.strategy, LearningThresholdStrategy):
            self.strategy.update_based_on_performance(
                decision_metrics=decision_metrics,
                actual_processing_time=processing_time,
                success=success,
                strategy_used=strategy_used
            )

        return results

    def _log_decision_metrics(self, decision_metrics: Dict[str, Any], estimated_tokens: int):
        """è®°å½•å†³ç­–æŒ‡æ ‡"""
        metrics = decision_metrics['dimensions']

        logger.info("ğŸ“Š å†³ç­–åˆ†æ:")
        logger.info(
            f"  Tokenæ•°: {estimated_tokens}/{metrics['tokens']['threshold']} ({metrics['tokens']['ratio'] * 100:.1f}%)")
        logger.info(
            f"  åœºæ™¯æ•°: {metrics['scenarios']['value']}/{metrics['scenarios']['threshold']} ({metrics['scenarios']['ratio'] * 100:.1f}%)")
        logger.info(
            f"  æ€»æ¨èæ•°: {metrics['total_recommendations']['value']}/{metrics['total_recommendations']['threshold']} ({metrics['total_recommendations']['ratio'] * 100:.1f}%)")
        logger.info(
            f"  å¹³å‡æ¨èæ•°: {metrics['avg_recommendations']['value']:.1f}/{metrics['avg_recommendations']['threshold']} ({metrics['avg_recommendations']['ratio'] * 100:.1f}%)")
        logger.info(f"  ç»¼åˆè¯„åˆ†: {decision_metrics['composite_score']:.2f}")
        logger.info(f"  å†³ç­–ç†ç”±: {decision_metrics['decision_reason']}")

    async def _get_recommendations_single_call(
            self,
            confirmed_scenarios: List[Dict[str, Any]],
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            max_recommendations_per_scenario: int,
            expected_scenario_count: int,
            single_prompt: str
    ) -> List[Dict[str, Any]]:
        """å•æ¬¡è°ƒç”¨å¤„ç†"""
        # è¿™é‡Œå®ç°å•æ¬¡LLMè°ƒç”¨é€»è¾‘
        # è¿”å›æ ¼å¼åŒ–çš„ç»“æœ
        # 2. æ ¹æ®tokenæ•°é€‰æ‹©ç­–ç•¥
        return await self._get_recommendations_single_call_by_llm(
                confirmed_scenarios,single_prompt
            )

    async def _get_recommendations_for_confirmed_scenarios_concurrent(
            self,
            confirmed_scenarios: List[Dict[str, Any]],
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            max_recommendations_per_scenario: int,
            max_concurrent: int=3
    ) -> List[Dict[str, Any]]:
        """å¹¶å‘å¤„ç†"""
        """å¹¶å‘å¤„ç†å·²ç¡®è®¤åœºæ™¯çš„æ¨èé¡¹ç›®åˆ†çº§

            Args:
                confirmed_scenarios: å·²ç¡®è®¤çš„åœºæ™¯åˆ—è¡¨
                patient_info: æ‚£è€…ä¿¡æ¯
                clinical_context: ä¸´åºŠä¸Šä¸‹æ–‡
                max_recommendations_per_scenario: æ¯ä¸ªåœºæ™¯æœ€å¤§æ¨èé¡¹ç›®æ•°
                max_concurrent: æœ€å¤§å¹¶å‘æ•°

            Returns:
                æ ¼å¼åŒ–çš„æ¨èç»“æœï¼Œä¸åŸå‡½æ•°æ ¼å¼ç›¸åŒ
            """
        import asyncio
        from typing import List, Dict, Any

        async def process_single_scenario(scenario_data: Dict[str, Any], scenario_index: int) -> Dict[str, Any]:
            """å¤„ç†å•ä¸ªåœºæ™¯çš„æ¨èé¡¹ç›®åˆ†çº§"""
            try:
                # æ„å»ºå•ä¸ªåœºæ™¯çš„æç¤ºè¯
                prompt = self._build_single_scenario_prompt(
                    scenario_data,
                    scenario_index,
                    patient_info,
                    clinical_context,
                    max_recommendations_per_scenario
                )

                # è°ƒç”¨LLM
                response = await self.ai_service._call_llm(prompt)

                # è§£æJSONç»“æœ
                import re
                import json

                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if not json_match:
                    logger.error(f"åœºæ™¯{scenario_index} LLMè¿”å›æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                    return self._fallback_single_scenario(scenario_data, scenario_index)

                try:
                    result = json.loads(json_match.group())
                except json.JSONDecodeError as e:
                    logger.error(f"åœºæ™¯{scenario_index} JSONè§£æé”™è¯¯: {e}")
                    return self._fallback_single_scenario(scenario_data, scenario_index)

                # å¤„ç†åˆ†çº§æ¨èç»“æœ
                return self._process_single_scenario_result(result, scenario_data, scenario_index)

            except Exception as e:
                logger.error(f"å¤„ç†åœºæ™¯{scenario_index}æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                return self._fallback_single_scenario(scenario_data, scenario_index)

        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent)

        async def bounded_process(scenario_data, scenario_index):
            async with semaphore:
                return await process_single_scenario(scenario_data, scenario_index)

        # å¹¶å‘å¤„ç†æ‰€æœ‰åœºæ™¯
        tasks = [
            bounded_process(scenario_data, idx + 1)
            for idx, scenario_data in enumerate(confirmed_scenarios)
        ]

        single_scenario_results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ç»“æœ
        final_results = []
        for result in single_scenario_results:
            if isinstance(result, Exception):
                logger.error(f"åœºæ™¯å¤„ç†å¼‚å¸¸: {result}")
                continue
            if result:  # åªæ·»åŠ æœ‰æ•ˆç»“æœ
                final_results.append(result)

        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        final_results.sort(key=lambda x: x['comprehensive_score'], reverse=True)

        # ç”Ÿæˆæ€»ä½“æ¨ç†
        overall_reasoning = self._generate_overall_reasoning(final_results)

        # ä¸ºæ‰€æœ‰ç»“æœæ·»åŠ æ€»ä½“æ¨ç†
        for result in final_results:
            result['overall_reasoning'] = overall_reasoning

        # è®°å½•è¯¦ç»†çš„åˆ†çº§ç»Ÿè®¡
        logger.info(f"âœ… å¹¶å‘åœºæ™¯æ¨èåˆ†çº§å®Œæˆï¼Œå¤„ç†äº†{len(final_results)}ä¸ªåœºæ™¯")
        for idx, result in enumerate(final_results, 1):
            summary = result['recommendation_summary']
            metadata = result['scenario_metadata']
            logger.info(
                f"  åœºæ™¯#{idx}: {metadata['description'][:50]}... | "
                f"è¯„åˆ†={result['comprehensive_score']} | "
                f"åˆ†çº§[æå…¶:{summary['highly_recommended_count']}/"
                f"æ¨è:{summary['recommended_count']}/"
                f"ä¸å¤ª:{summary['less_recommended_count']}]"
            )

        return final_results

    def _build_single_scenario_prompt(
            self,
            scenario_data: Dict[str, Any],
            scenario_index: int,
            patient_info: PatientInfo,
            clinical_context: ClinicalContext,
            max_recommendations_per_scenario: int
    ) -> str:
        """ä¸ºå•ä¸ªåœºæ™¯æ„å»ºæç¤ºè¯"""

        scenario = scenario_data['scenario']
        recommendations = scenario_data.get('recommendations', [])

        patient_info_content = self.build_patient_context(patient_info)
        clinical_context_content = self.build_clinical_context(clinical_context)
        scenario_content = self._build_single_scenario_content(scenario_data, scenario_index)
        task_instruction = self._build_single_scenario_task_instruction(
            scenario_index,
            len(recommendations),
            max_recommendations_per_scenario
        )

        return f"""{patient_info_content}

        {clinical_context_content}

        {scenario_content}

        {task_instruction}"""

    def _build_single_scenario_content(self, scenario_data: Dict[str, Any], scenario_index: int) -> str:
        """æ„å»ºå•ä¸ªåœºæ™¯çš„å†…å®¹æè¿°"""
        scenario = scenario_data['scenario']
        recommendations = scenario_data.get('recommendations', [])

        content = f"""## åœºæ™¯ {scenario_index}: {scenario.description_zh}

        ### åœºæ™¯ä¿¡æ¯
        - **åœºæ™¯ID**: {scenario.semantic_id}
        - **é€‚ç”¨ç§‘å®¤**: {scenario.panel.name_zh if hasattr(scenario, 'panel') else 'æœªçŸ¥'}
        - **é€‚ç”¨äººç¾¤**: {scenario.patient_population or 'æœªçŸ¥'}
        - **ä¸´åºŠèƒŒæ™¯**: {scenario.clinical_context or 'æ— '}

        ### æ¨èé¡¹ç›®æ¸…å•
        """

        if not recommendations:
            content += "æš‚æ— æ¨èé¡¹ç›®\n"
            return content

        for rec_idx, rec_data in enumerate(recommendations, 1):
            recommendation = rec_data['recommendation']
            procedure = rec_data['procedure']

            # æ£€æŸ¥é¡¹ç›®åŸºæœ¬ä¿¡æ¯
            content += f"{rec_idx}. **{procedure.name_zh}** ({procedure.name_en})\n"

            # æ£€æŸ¥æŠ€æœ¯ç»†èŠ‚
            tech_details = []
            if procedure.modality:
                tech_details.append(f"æ£€æŸ¥æ–¹å¼: {procedure.modality}")
            if procedure.body_part:
                tech_details.append(f"æ£€æŸ¥éƒ¨ä½: {procedure.body_part}")
            if procedure.exam_duration:
                tech_details.append(f"æ£€æŸ¥æ—¶é•¿: {procedure.exam_duration}åˆ†é’Ÿ")
            if tech_details:
                content += f"   - æŠ€æœ¯ç»†èŠ‚: {', '.join(tech_details)}\n"

            # å®‰å…¨æ€§å’Œå‡†å¤‡ä¿¡æ¯
            safety_info = []
            if procedure.contrast_used:
                safety_info.append("ä½¿ç”¨å¯¹æ¯”å‰‚")
            if procedure.radiation_level:
                safety_info.append(f"è¾å°„ç­‰çº§: {procedure.radiation_level}")
            if procedure.preparation_required:
                safety_info.append("éœ€è¦å‡†å¤‡")
            if safety_info:
                content += f"   - å®‰å…¨ä¿¡æ¯: {', '.join(safety_info)}\n"

            # ACRæ¨èä¿¡æ¯
            content += f"   - **ACRé€‚å®œæ€§è¯„åˆ†**: {recommendation.appropriateness_rating}/9\n"
            if recommendation.appropriateness_category_zh:
                content += f"   - é€‚å®œæ€§ç±»åˆ«: {recommendation.appropriateness_category_zh}\n"

            # è¯æ®å’Œå…±è¯†
            evidence_info = []
            if recommendation.evidence_level:
                evidence_info.append(f"è¯æ®å¼ºåº¦: {recommendation.evidence_level}")
            if recommendation.consensus_level:
                evidence_info.append(f"å…±è¯†æ°´å¹³: {recommendation.consensus_level}")
            if evidence_info:
                content += f"   - è¯æ®è´¨é‡: {', '.join(evidence_info)}\n"

            # è¾å°„å‰‚é‡ä¿¡æ¯
            dose_info = []
            if recommendation.adult_radiation_dose:
                dose_info.append(f"æˆäººå‰‚é‡: {recommendation.adult_radiation_dose}")
            if recommendation.pediatric_radiation_dose:
                dose_info.append(f"å„¿ç«¥å‰‚é‡: {recommendation.pediatric_radiation_dose}")
            if dose_info:
                content += f"   - è¾å°„å‰‚é‡: {', '.join(dose_info)}\n"

            # å®‰å…¨æ€§ä¿¡æ¯
            safety_info = []
            if recommendation.pregnancy_safety:
                safety_info.append(f"å¦Šå¨ å®‰å…¨: {recommendation.pregnancy_safety}")
            if recommendation.contraindications:
                contra = recommendation.contraindications[:60] + "..." if len(
                    recommendation.contraindications) > 60 else recommendation.contraindications
                safety_info.append(f"ç¦å¿Œç—‡: {contra}")
            if safety_info:
                content += f"   - å®‰å…¨è€ƒè™‘: {', '.join(safety_info)}\n"

            # æ¨èç†ç”±
            if recommendation.reasoning_zh:
                reasoning = recommendation.reasoning_zh[:200] + "..." if len(
                    recommendation.reasoning_zh) > 200 else recommendation.reasoning_zh
                content += f"   - æ¨èç†ç”±: {reasoning}\n"

            content += "\n"

        return content

    def _build_single_scenario_task_instruction(
            self,
            scenario_index: int,
            recommendation_count: int,
            max_recommendations_per_scenario: int
    ) -> str:
        """ä¸ºå•ä¸ªåœºæ™¯æ„å»ºä»»åŠ¡æŒ‡ä»¤"""

        task_instruction = f"""
        ## ä»»åŠ¡è¯´æ˜

        ä½œä¸ºç»éªŒä¸°å¯Œçš„ä¸´åºŠåŒ»ç”Ÿï¼Œè¯·åŸºäºæ‚£è€…ä¿¡æ¯å’Œä¸´åºŠä¸Šä¸‹æ–‡ï¼Œå¯¹**åœºæ™¯{scenario_index}**çš„{recommendation_count}ä¸ªæ¨èé¡¹ç›®è¿›è¡Œ**ä¸‰çº§æ¨èç­‰çº§åˆ’åˆ†**ã€‚

        ### æ¨èé¡¹ç›®ä¸‰çº§åˆ†çº§è¯„ä¼°
        å¯¹è¯¥åœºæ™¯çš„æ‰€æœ‰æ¨èé¡¹ç›®ï¼Œè¿›è¡Œ**ä¸‰çº§æ¨èç­‰çº§åˆ’åˆ†**ï¼š

        - **æå…¶æ¨è (Highly Recommended)**: è¯„åˆ†é«˜ï¼Œè¯æ®å……åˆ†ï¼Œä¸æ‚£è€…æƒ…å†µå®Œç¾åŒ¹é…ï¼Œå®‰å…¨æ€§å’Œè¯Šæ–­ä»·å€¼ä¿±ä½³ï¼Œæ— æ˜æ˜¾ç¦å¿Œ
        - **æ¨è (Recommended)**: è¯„åˆ†ä¸­ç­‰ï¼Œä¸´åºŠé€‚ç”¨æ€§è‰¯å¥½ï¼Œé£é™©æ”¶ç›Šæ¯”åˆç†ï¼Œå¯èƒ½å­˜åœ¨è½»å¾®é™åˆ¶  
        - **ä¸å¤ªæ¨è (Less Recommended)**: è¯„åˆ†ä½ï¼Œæˆ–å­˜åœ¨å®‰å…¨éšæ‚£ï¼Œæˆ–æœ‰æ˜ç¡®ç¦å¿Œç—‡ï¼Œæˆ–ä¸å½“å‰ä¸´åºŠéœ€æ±‚åŒ¹é…åº¦ä¸é«˜

        ### è¯„ä¼°è¦ç‚¹
        1. **æ‚£è€…åŒ¹é…åº¦**: è€ƒè™‘æ‚£è€…å¹´é¾„ã€æ€§åˆ«ã€ç—‡çŠ¶ã€ç—…å²ç­‰
        2. **ä¸´åºŠç›¸å…³æ€§**: ä¸å½“å‰ä¸´åºŠè¡¨ç°å’Œè¯Šæ–­éœ€æ±‚çš„åŒ¹é…ç¨‹åº¦
        3. **å®‰å…¨æ€§**: è¾å°„å‰‚é‡ã€å¯¹æ¯”å‰‚ä½¿ç”¨ã€ç¦å¿Œç—‡ç­‰å®‰å…¨å› ç´ 
        4. **è¯æ®å¼ºåº¦**: ACRè¯„åˆ†ã€è¯æ®ç­‰çº§ã€å…±è¯†æ°´å¹³
        5. **å®ç”¨æ€§**: æ£€æŸ¥å¯è¡Œæ€§ã€å‡†å¤‡è¦æ±‚ã€æ—¶é•¿ç­‰

        ## è¾“å‡ºæ ¼å¼
        è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦é¢å¤–è§£é‡Šï¼š

        ```json
        {{
            "scenario_index": {scenario_index},
            "scenario_id": "å¡«å†™åœºæ™¯è¯­ä¹‰ID",
            "comprehensive_score": "æ ¹æ®æ¨èé¡¹ç›®è´¨é‡ç»™å‡ºçš„0-100ç»¼åˆè¯„åˆ†",
            "scenario_reasoning": "è¯¥åœºæ™¯ä¸æ‚£è€…æƒ…å†µçš„åŒ¹é…åº¦åˆ†æï¼ˆ100-150å­—ï¼‰",
            "recommendation_grades": {{
                "highly_recommended": [æ¨èé¡¹ç›®ç´¢å¼•åˆ—è¡¨, ä»1å¼€å§‹],
                "recommended": [æ¨èé¡¹ç›®ç´¢å¼•åˆ—è¡¨, ä»1å¼€å§‹],
                "less_recommended": [æ¨èé¡¹ç›®ç´¢å¼•åˆ—è¡¨, ä»1å¼€å§‹]
            }},
            "grading_reasoning": "å¯¹è¯¥åœºæ™¯æ¨èé¡¹ç›®åˆ†çº§çš„ä¸´åºŠç†ç”±ï¼ˆ150-200å­—ï¼‰ï¼Œé‡ç‚¹è¯´æ˜åˆ†çº§ä¾æ®"
        }}"""
        return task_instruction

    def _process_single_scenario_result(
            self,
            result: Dict[str, Any],
            scenario_data: Dict[str, Any],
            scenario_index: int
    ) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªåœºæ™¯çš„LLMè¿”å›ç»“æœ"""


        scenario = scenario_data['scenario']
        original_recommendations = scenario_data.get('recommendations', [])
        grading_data = result.get('recommendation_grades', {})

        # æŒ‰æ¨èç­‰çº§ç»„ç»‡æ¨èé¡¹ç›®
        graded_recommendations = {
            "highly_recommended": [],
            "recommended": [],
            "less_recommended": []
        }

        # å¤„ç†å„ç­‰çº§æ¨èé¡¹ç›®
        recommendation_levels = [
            ('highly_recommended', 'æå…¶æ¨è'),
            ('recommended', 'æ¨è'),
            ('less_recommended', 'ä¸å¤ªæ¨è')
        ]

        for level_key, level_zh in recommendation_levels:
            for rec_idx in grading_data.get(level_key, []):
                if 1 <= rec_idx <= len(original_recommendations):
                    rec_data = original_recommendations[rec_idx - 1].copy()
                    rec_data['recommendation_level'] = level_key
                    rec_data['recommendation_level_zh'] = level_zh

                    # æ·»åŠ å®Œæ•´çš„æ£€æŸ¥é¡¹ç›®ä¿¡æ¯
                    procedure = rec_data['procedure']
                    recommendation = rec_data['recommendation']

                    # æ„å»ºè¯¦ç»†çš„æ£€æŸ¥é¡¹ç›®ä¿¡æ¯
                    rec_data['procedure_details'] = {
                        'semantic_id': procedure.semantic_id,
                        'name_zh': procedure.name_zh,
                        'name_en': procedure.name_en,
                        'modality': procedure.modality,
                        'body_part': procedure.body_part,
                        'contrast_used': procedure.contrast_used,
                        'radiation_level': procedure.radiation_level,
                        'exam_duration': procedure.exam_duration,
                        'preparation_required': procedure.preparation_required,
                        'standard_code': procedure.standard_code,
                        'description_zh': procedure.description_zh
                    }

                    # æ„å»ºè¯¦ç»†çš„æ¨èä¿¡æ¯
                    rec_data['recommendation_details'] = {
                        'appropriateness_rating': recommendation.appropriateness_rating,
                        'appropriateness_category_zh': recommendation.appropriateness_category_zh,
                        'evidence_level': recommendation.evidence_level,
                        'consensus_level': recommendation.consensus_level,
                        'adult_radiation_dose': recommendation.adult_radiation_dose,
                        'pediatric_radiation_dose': recommendation.pediatric_radiation_dose,
                        'pregnancy_safety': recommendation.pregnancy_safety,
                        'contraindications': recommendation.contraindications,
                        'reasoning_zh': recommendation.reasoning_zh,
                        'special_considerations': recommendation.special_considerations
                    }

                    graded_recommendations[level_key].append(rec_data)
                else:
                    logger.warning(f"åœºæ™¯{scenario_index}çš„æ— æ•ˆ{level_zh}ç´¢å¼•: {rec_idx}")

        # æ„å»ºè¿”å›ç»“æœ
        return {
            'comprehensive_score': result.get('comprehensive_score', 0),
            'scenario_reasoning': result.get('scenario_reasoning', ''),
            'grading_reasoning': result.get('grading_reasoning', ''),
            'overall_reasoning': '',  # å°†åœ¨å¤–å±‚ç»Ÿä¸€è®¾ç½®
            'graded_recommendations': graded_recommendations,
            'recommendation_summary': {
                'highly_recommended_count': len(graded_recommendations['highly_recommended']),
                'recommended_count': len(graded_recommendations['recommended']),
                'less_recommended_count': len(graded_recommendations['less_recommended']),
                'total_recommendations': len(original_recommendations)
            },
            'scenario_metadata': {
                'scenario_id': result.get('scenario_id') or scenario.semantic_id,
                'description': scenario.description_zh,
                'panel': scenario.panel.name_zh if hasattr(scenario, 'panel') else 'æœªçŸ¥',
                'patient_population': scenario.patient_population,
                'clinical_context': scenario.clinical_context,
                'original_index': scenario_index
            }
        }

    def _fallback_single_scenario(self, scenario_data: Dict[str, Any], scenario_index: int) -> Dict[str, Any]:
        """å•ä¸ªåœºæ™¯çš„é™çº§æ–¹æ¡ˆ"""

        scenario = scenario_data['scenario']
        recommendations = scenario_data.get('recommendations', [])


        # ç®€å•çš„é»˜è®¤åˆ†çº§ç­–ç•¥ï¼šæŒ‰ACRè¯„åˆ†åˆ†çº§
        graded_recommendations = {
            "highly_recommended": [],
            "recommended": [],
            "less_recommended": []
        }

        for rec_idx, rec_data in enumerate(recommendations, 1):
            recommendation = rec_data['recommendation']
            procedure = rec_data['procedure']

            rec_data_copy = rec_data.copy()

            # æ ¹æ®ACRè¯„åˆ†ç®€å•åˆ†çº§
            if recommendation.appropriateness_rating >= 7:
                level_key = "highly_recommended"
                level_zh = "æå…¶æ¨è"
            elif recommendation.appropriateness_rating >= 4:
                level_key = "recommended"
                level_zh = "æ¨è"
            else:
                level_key = "less_recommended"
                level_zh = "ä¸å¤ªæ¨è"

            rec_data_copy['recommendation_level'] = level_key
            rec_data_copy['recommendation_level_zh'] = level_zh

            # æ·»åŠ è¯¦ç»†ä¿¡æ¯
            rec_data_copy['procedure_details'] = {
                'semantic_id': procedure.semantic_id,
                'name_zh': procedure.name_zh,
                'name_en': procedure.name_en,
                'modality': procedure.modality,
                'body_part': procedure.body_part,
                'contrast_used': procedure.contrast_used,
                'radiation_level': procedure.radiation_level,
                'exam_duration': procedure.exam_duration,
                'preparation_required': procedure.preparation_required,
                'standard_code': procedure.standard_code,
                'description_zh': procedure.description_zh
            }

            rec_data_copy['recommendation_details'] = {
                'appropriateness_rating': recommendation.appropriateness_rating,
                'appropriateness_category_zh': recommendation.appropriateness_category_zh,
                'evidence_level': recommendation.evidence_level,
                'consensus_level': recommendation.consensus_level,
                'adult_radiation_dose': recommendation.adult_radiation_dose,
                'pediatric_radiation_dose': recommendation.pediatric_radiation_dose,
                'pregnancy_safety': recommendation.pregnancy_safety,
                'contraindications': recommendation.contraindications,
                'reasoning_zh': recommendation.reasoning_zh,
                'special_considerations': recommendation.special_considerations
            }

            graded_recommendations[level_key].append(rec_data_copy)

        return {
            'comprehensive_score': 75,  # é»˜è®¤è¯„åˆ†
            'scenario_reasoning': f'åœºæ™¯{scenario_index}é™çº§æ–¹æ¡ˆï¼šåŸºäºACRè¯„åˆ†çš„è‡ªåŠ¨åˆ†çº§',
            'grading_reasoning': 'LLMè°ƒç”¨å¤±è´¥ï¼ŒæŒ‰ACRé€‚å®œæ€§è¯„åˆ†è‡ªåŠ¨åˆ†çº§ï¼šâ‰¥7åˆ†ä¸ºæå…¶æ¨èï¼Œ4-6åˆ†ä¸ºæ¨èï¼Œ<4åˆ†ä¸ºä¸å¤ªæ¨è',
            'overall_reasoning': '',
            'graded_recommendations': graded_recommendations,
            'recommendation_summary': {
                'highly_recommended_count': len(graded_recommendations['highly_recommended']),
                'recommended_count': len(graded_recommendations['recommended']),
                'less_recommended_count': len(graded_recommendations['less_recommended']),
                'total_recommendations': len(recommendations)
            },
            'scenario_metadata': {
                'scenario_id': scenario.semantic_id,
                'description': scenario.description_zh,
                'panel': scenario.panel.name_zh if hasattr(scenario, 'panel') else 'æœªçŸ¥',
                'patient_population': scenario.patient_population,
                'clinical_context': scenario.clinical_context,
                'original_index': scenario_index
            }
        }

    def _generate_overall_reasoning(self, final_results: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ€»ä½“æ¨ç†è¯´æ˜"""

        total_scenarios = len(final_results)
        total_recommendations = sum(
            result['recommendation_summary']['total_recommendations']
            for result in final_results
        )
        highly_recommended_total = sum(
            result['recommendation_summary']['highly_recommended_count']
            for result in final_results
        )

        return f"åŸºäºæ‚£è€…ä¸´åºŠä¿¡æ¯ï¼Œå¯¹{total_scenarios}ä¸ªç¡®è®¤åœºæ™¯è¿›è¡Œäº†å¹¶å‘åˆ†çº§è¯„ä¼°ï¼Œå…±åˆ†æ{total_recommendations}ä¸ªæ¨èé¡¹ç›®ï¼Œå…¶ä¸­{highly_recommended_total}ä¸ªé¡¹ç›®è¢«è¯„ä¸ºæå…¶æ¨èã€‚å„åœºæ™¯æŒ‰ç»¼åˆä¸´åºŠä»·å€¼æ’åºã€‚"


    def _fallback_for_confirmed_scenarios(self, confirmed_scenarios: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """é™çº§æ–¹æ¡ˆ"""
        logger.info("ä½¿ç”¨é™çº§æ–¹æ¡ˆ...")
        return []

    def get_strategy_status(self) -> Dict[str, Any]:
        """è·å–ç­–ç•¥çŠ¶æ€"""
        status = {
            'environment': self.environment,
            'use_adaptive': self.use_adaptive,
            'threshold_config': self.strategy.threshold_config,
            'strategy_type': self.strategy.__class__.__name__
        }

        if isinstance(self.strategy, LearningThresholdStrategy):
            status.update({
                'learning_enabled': self.strategy.learning_enabled,
                'history_size': len(self.strategy.performance_history)
            })

        return status

    def set_adaptive_mode(self, enabled: bool):
        """åŠ¨æ€è®¾ç½®è‡ªé€‚åº”æ¨¡å¼"""
        old_mode = self.use_adaptive
        self.use_adaptive = enabled

        if enabled and not isinstance(self.strategy, LearningThresholdStrategy):
            self.strategy = LearningThresholdStrategy()
            self._initialize_strategy()
            logger.info("ğŸ”„ åˆ‡æ¢åˆ°è‡ªé€‚åº”å­¦ä¹ æ¨¡å¼")
        elif not enabled and isinstance(self.strategy, LearningThresholdStrategy):
            self.strategy = AdaptiveThresholdStrategy()
            self._initialize_strategy()
            logger.info("âš¡ åˆ‡æ¢åˆ°å›ºå®šé˜ˆå€¼æ¨¡å¼")

        logger.info(f"ğŸ“ è‡ªé€‚åº”æ¨¡å¼ä» {old_mode} æ”¹ä¸º {enabled}")

    def enable_learning(self, enabled: bool = True):
        """å¯ç”¨/ç¦ç”¨å­¦ä¹ åŠŸèƒ½ï¼ˆä»…å¯¹å­¦ä¹ ç­–ç•¥æœ‰æ•ˆï¼‰"""
        if isinstance(self.strategy, LearningThresholdStrategy):
            self.strategy.learning_enabled = enabled
            status = "å¯ç”¨" if enabled else "ç¦ç”¨"
            logger.info(f"ğŸ“š å­¦ä¹ åŠŸèƒ½å·²{status}")
        else:
            logger.warning("å½“å‰ä¸æ˜¯å­¦ä¹ ç­–ç•¥ï¼Œæ— æ³•å¯ç”¨å­¦ä¹ åŠŸèƒ½")

    def reset_learning(self):
        """é‡ç½®å­¦ä¹ æ•°æ®"""
        if isinstance(self.strategy, LearningThresholdStrategy):
            self.strategy.performance_history = []
            logger.info("ğŸ”„ å­¦ä¹ æ•°æ®å·²é‡ç½®")
        else:
            logger.warning("å½“å‰ä¸æ˜¯å­¦ä¹ ç­–ç•¥ï¼Œæ— æ³•é‡ç½®å­¦ä¹ æ•°æ®")

    async def _get_recommendations_single_call_by_llm(self, confirmed_scenarios,
                                                       single_prompt):

            try:

                response = await self.ai_service._call_llm(single_prompt)
                # ä½¿ç”¨å¢å¼ºçš„JSONè§£æ
                result = safe_parse_llm_response(response=response, expected_scenario_count=len(confirmed_scenarios))

                if result is None:
                    logger.error("JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                    return self._fallback_for_confirmed_scenarios(confirmed_scenarios)

                # å¤„ç†é€‰ä¸­çš„åœºæ™¯æ•°æ®
                selected_scenarios_data = result.get('selected_scenarios', [])
                final_results = []

                for selected_data in selected_scenarios_data:
                    scenario_index = selected_data.get('scenario_index')
                    scenario_id = selected_data.get('scenario_id')
                    grading_data = selected_data.get('recommendation_grades', {})
                    final_choices=selected_data.get("final_choices",[])
                    # éªŒè¯åœºæ™¯ç´¢å¼•èŒƒå›´
                    if not (1 <= scenario_index <= len(confirmed_scenarios)):
                        logger.warning(f"æ— æ•ˆçš„åœºæ™¯ç´¢å¼•: {scenario_index}ï¼Œè·³è¿‡è¯¥åœºæ™¯")
                        continue

                    # è·å–åŸå§‹åœºæ™¯æ•°æ®
                    original_scenario_data = confirmed_scenarios[scenario_index - 1]
                    original_recommendations = original_scenario_data.get('recommendations', [])
                    scenario = original_scenario_data['scenario']

                    # å®‰å…¨å¤„ç†æ¨èåˆ†çº§
                    graded_recommendations = safe_process_recommendation_grades(
                        grading_data, original_recommendations, scenario_index
                    )

                    # æ„å»ºè¿”å›ç»“æœ
                    final_result = {
                        'comprehensive_score': selected_data.get('comprehensive_score', 0),
                        'scenario_reasoning': selected_data.get('scenario_reasoning', ''),
                        'grading_reasoning': selected_data.get('grading_reasoning', ''),
                        'overall_reasoning': result.get('overall_reasoning', ''),
                        'graded_recommendations': graded_recommendations,
                        'recommendation_summary': {
                            'highly_recommended_count': len(graded_recommendations['highly_recommended']),
                            'recommended_count': len(graded_recommendations['recommended']),
                            'less_recommended_count': len(graded_recommendations['less_recommended']),
                            'total_recommendations': len(original_recommendations)
                        },
                        "final_choices":final_choices,
                        'scenario_metadata': {
                            'scenario_id': scenario_id or scenario.semantic_id,
                            'description': scenario.description_zh,
                            'panel': scenario.panel.name_zh if hasattr(scenario, 'panel') else 'æœªçŸ¥',
                            'patient_population': scenario.patient_population,
                            'clinical_context': scenario.clinical_context,
                            'original_index': scenario_index
                        }
                    }

                    final_results.append(final_result)

                # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
                final_results.sort(key=lambda x: x['comprehensive_score'], reverse=True)

                logger.info(f"âœ… å•æ¬¡è°ƒç”¨å®Œæˆï¼ŒæˆåŠŸå¤„ç†{len(final_results)}ä¸ªåœºæ™¯")
                return final_results

            except Exception as e:
                logger.error(f"âŒ å•æ¬¡è°ƒç”¨å¤±è´¥: {str(e)}")
                return self._fallback_for_confirmed_scenarios(confirmed_scenarios)


